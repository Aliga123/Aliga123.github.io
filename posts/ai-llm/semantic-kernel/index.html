<!DOCTYPE html>
<html lang="zh" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Semantic Kernel | aliga&#39;s Blog</title>
<meta name="keywords" content="">
<meta name="description" content="Semantic Kernel Sematic Kernel 通过 Kernel 链接 LLM 与 Functions（功能）: Semantic Functions：通过 Prompt 实现的 LLM 能力 Native Functions: 编程语言原生的函数功能 在 SK 中，一组 Function 组成一个技能（Skill/Plugin）。要运行 Skill/Plugin，需要有一个配置和管理的单元，这个组织管理单元就是 Kernel。 Kernel 负责管理底层">
<meta name="author" content="aliga">
<link rel="canonical" href="https://Aliga123.github.io/posts/ai-llm/semantic-kernel/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.js" onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://Aliga123.github.io/img/Q.gif">
<link rel="icon" type="image/png" sizes="16x16" href="https://Aliga123.github.io/img/Q.gif">
<link rel="icon" type="image/png" sizes="32x32" href="https://Aliga123.github.io/img/Q.gif">
<link rel="apple-touch-icon" href="https://Aliga123.github.io/img/Q.gif">
<link rel="mask-icon" href="https://Aliga123.github.io/img/Q.gif">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="zh" href="https://Aliga123.github.io/posts/ai-llm/semantic-kernel/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script defer src="https://unpkg.com/mermaid@8.8.1/dist/mermaid.min.js"></script>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css">
<script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.3/dist/jquery.min.js"></script>



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = ""; 
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

  

<meta property="og:title" content="Semantic Kernel" />
<meta property="og:description" content="Semantic Kernel Sematic Kernel 通过 Kernel 链接 LLM 与 Functions（功能）: Semantic Functions：通过 Prompt 实现的 LLM 能力 Native Functions: 编程语言原生的函数功能 在 SK 中，一组 Function 组成一个技能（Skill/Plugin）。要运行 Skill/Plugin，需要有一个配置和管理的单元，这个组织管理单元就是 Kernel。 Kernel 负责管理底层" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://Aliga123.github.io/posts/ai-llm/semantic-kernel/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-07-28T00:18:23+08:00" />
<meta property="article:modified_time" content="2024-07-28T00:18:23+08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Semantic Kernel"/>
<meta name="twitter:description" content="Semantic Kernel Sematic Kernel 通过 Kernel 链接 LLM 与 Functions（功能）: Semantic Functions：通过 Prompt 实现的 LLM 能力 Native Functions: 编程语言原生的函数功能 在 SK 中，一组 Function 组成一个技能（Skill/Plugin）。要运行 Skill/Plugin，需要有一个配置和管理的单元，这个组织管理单元就是 Kernel。 Kernel 负责管理底层"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [

        {
          "@type": "ListItem",
          "position":  1 ,
          "name": "📚文章",
          "item": "https://Aliga123.github.io/posts/"
        },

        {
          "@type": "ListItem",
          "position":  2 ,
          "name": "🧱 AI大模型应用开发",
          "item": "https://Aliga123.github.io/posts/ai-llm/"
        }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "Semantic Kernel",
      "item": "https://Aliga123.github.io/posts/ai-llm/semantic-kernel/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Semantic Kernel",
  "name": "Semantic Kernel",
  "description": "Semantic Kernel Sematic Kernel 通过 Kernel 链接 LLM 与 Functions（功能）: Semantic Functions：通过 Prompt 实现的 LLM 能力 Native Functions: 编程语言原生的函数功能 在 SK 中，一组 Function 组成一个技能（Skill/Plugin）。要运行 Skill/Plugin，需要有一个配置和管理的单元，这个组织管理单元就是 Kernel。 Kernel 负责管理底层",
  "keywords": [
    ""
  ],
  "articleBody": "Semantic Kernel Sematic Kernel 通过 Kernel 链接 LLM 与 Functions（功能）:\nSemantic Functions：通过 Prompt 实现的 LLM 能力 Native Functions: 编程语言原生的函数功能 在 SK 中，一组 Function 组成一个技能（Skill/Plugin）。要运行 Skill/Plugin，需要有一个配置和管理的单元，这个组织管理单元就是 Kernel。\nKernel 负责管理底层接口与调用顺序，例如：OpenAI/Azure OpenAI 的授权信息、默认的 LLM 模型选择、对话上下文、技能参数的传递等等。\n导入常用的库 import os from dotenv import load_dotenv, find_dotenv import asyncio import logging from semantic_kernel import Kernel from semantic_kernel.functions import kernel_function from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion from semantic_kernel.connectors.ai.function_call_behavior import FunctionCallBehavior from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase from semantic_kernel.contents.chat_history import ChatHistory from semantic_kernel.functions.kernel_arguments import KernelArguments from semantic_kernel.connectors.ai.open_ai.prompt_execution_settings.azure_chat_prompt_execution_settings import ( AzureChatPromptExecutionSettings, ) from semantic_kernel.functions import kernel_function from typing import List from semantic_kernel.contents import ChatMessageContent, TextContent, ImageContent from semantic_kernel.contents.utils.author_role import AuthorRole 初始化kernel # Initialize the kernel kernel = Kernel() 添加LLM服务 # Add the Azure OpenAI chat completion service kernel.add_service(OpenAIChatCompletion( ai_model_id=\"gpt-3.5-turbo-1106\", api_key=os.getenv(\"OPENAI_API_KEY\") )) 设置企业服务 # Set the logging level for semantic_kernel.kernel to DEBUG. logging.basicConfig( format=\"[%(asctime)s - %(name)s:%(lineno)d - %(levelname)s] %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\", ) logging.getLogger(\"kernel\").setLevel(logging.DEBUG) 启动自动规划 # Enable planning execution_settings = AzureChatPromptExecutionSettings(tool_choice=\"auto\") execution_settings.function_call_behavior = FunctionCallBehavior.EnableFunctions(auto_invoke=True, filters={}) 自动规划循环\n如果不使用语义内核的函数调用会相对复杂。您需要编写一个循环来完成以下操作：\n为每个函数创建 JSON 架构 向 LLM 提供之前的聊天记录和功能模式 解析 LLM 的响应以确定它是要回复消息还是调用函数 如果 LLM 想要调用某个函数，你需要从 LLM 的响应中解析函数名称和参数 使用正确的参数调用函数 返回函数的结果，以便 LLM 可以确定下一步该做什么 重复步骤 2-6，直到 LLM 决定已完成任务或需要用户的帮助 函数调用的过程：\n1 序列化函数 内核中所有可用的函数（及其输入参数）都使用 JSON 模式序列化。 2 将消息和函数发送给模型 序列化的函数（和当前聊天记录）作为输入的一部分发送到模型。 3 模型处理输入 模型处理输入并生成响应。响应可以是聊天消息或函数调用 4 处理响应 如果响应是聊天消息，则返回给开发人员以将响应打印到屏幕上。但是，如果响应是函数调用，则 Semantic Kernel 会提取函数名称及其参数。 5 调用函数 提取的函数名和参数用于调用内核中的函数。 6 返回函数结果 然后，函数的结果将作为聊天历史记录的一部分发送回模型。然后重复步骤 2-6，直到模型发送终止信号 在 Semantic Kernel 中，我们通过为您自动执行此循环，让您可以轻松使用函数调用。这样您就可以专注于构建满足用户需求所需的插件。 要在语义内核中使用自动函数调用，您需要执行以下操作：\n向内核注册插件 创建一个执行设置对象，告诉 AI 自动调用函数 使用聊天历史记录和内核调用聊天完成服务 添加插件服务（Function Calling） 1.添加原生（Native）代码作为插件\nclass EmailPlugin: def __init__(self, name): self.name = name self.time = '2024-7' @kernel_function( name=\"send_email\", description=\"Sends an email to a recipient.\" ) async def send_email(self, recipient_emails: str|List[str], subject: str, body: str): # Add logic to send an email using the recipient_emails, subject, and body # For now, we'll just print out a success message to the console print(self.name + \"Email sent!\") ## ...可以多个函数 # Add a plugin (the EmailPlugin class is defined above) kernel.add_plugin( EmailPlugin('aliga'), plugin_name=\"Email\", ) 上述插件序列化函数后的JOSN如下：\n[ { \"type\": \"function\", \"function\": { \"name\": \"send_email\", \"description\": \"Sends an email to a recipient.\", \"parameters\": { \"type\": \"object\", \"properties\": { \"recipient_emails\": { \"type\": \"string\" }, \"subject\": { \"type\": \"string\", \"enum\": [\"请假\", \"工作文件\", \"报表\"] }, \"body\": { \"type\": \"string\" } }, \"required\": [\"recipient_emails\", \"subject\", \"body\"] } } } ] 2.添加逻辑应用作为插件（仅限C#）\n建立对话服务（确定上述服务后） # Build the kernel and retrieve services chat_completion : AzureChatCompletion = kernel.get_service(type=ChatCompletionClientBase) 创建历史对话，并设置prompt 方法一\n# Create a history of the conversation history = ChatHistory(system_message=\"\"\" You are a friendly assistant who likes to follow the rules. You will complete required steps and request approval before taking any consequential actions. If the user doesn't provide enough information for you to complete a task, you will keep asking questions until you have enough information to complete the task. \"\"\") 方法二\n# 添加system_message第二种方法 chat_history = ChatHistory() chat_history.add_system_message(\"You are a helpful assistant.\") 方法三\n# Add system message，第三种方法 history = ChatHistory() chat_history.add_message( ChatMessage( role=AuthorRole.System, content=\"You are a helpful assistant\" ) ) 添加用户输入记录 方法一：文本\nhistory.add_user_message(user_input) 方法二：文本\n# Add additional message from a different user，第二种方法，可以指定name chat_history.add_message( ChatMessageContent( role=AuthorRole.USER, name=\"Ema Vargova\", content=\"I'd like to have the first option, please.\" ) ) 方法三：添加图片\n# Add user message with an image chat_history.add_message( ChatMessageContent( role=AuthorRole.USER, name=\"Laimonis Dumins\", items=[ TextContent(text=\"What available on this menu\"), ImageContent(uri=\"https://example.com/menu.jpg\") ] ) ) 执行对话，获得回复 # Get the response from the AI result = (await chat_completion.get_chat_message_contents( chat_history=history, settings=execution_settings, kernel=kernel, arguments=KernelArguments(), ))[0] # Print the response print(\"Assistant \u003e \" + str(result)) 添加AI响应记录 方法一\nhistory.add_assistant_message(str(result)) 方法二\n# Add assistant message，第二种方法，可以指定name chat_history.add_message( ChatMessageContent( role=AuthorRole.ASSISTANT, name=\"Restaurant Assistant\", content=\"We have pizza, pasta, and salad available to order. What would you like to order?\" ) ) 使用SK实现RAG 参考：https://github.com/john0isaac/rag-semantic-kernel-mongodb-vcore/blob/main/rag-azure-openai-cosmosdb-notebook.ipynb 设置一些参数\n# collection name will be used multiple times in the code so we store it in a variable collection_name = 'VectorSearchCollection' # Vector search index parameters index_name = \"VectorSearchIndex\" vector_dimensions = 1536 # text-embedding-ada-002 uses a 1536-dimensional embedding vector num_lists = 1 similarity = \"COS\" # cosine distance 配置LLMChat、embedding模型\n1.Azure\nfrom semantic_kernel import Kernel import os from dotenv import load_dotenv, find_dotenv from semantic_kernel.connectors.ai.open_ai import ( AzureChatCompletion, AzureTextEmbedding, ) # Intialize the kernel kernel = Kernel() # adding azure openai chat service chat_model_deployment_name = os.environ.get(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\") endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\") api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\") kernel.add_service( AzureChatCompletion( service_id=\"chat_completion\", deployment_name=chat_model_deployment_name, endpoint=endpoint, api_key=api_key, # adding azure openai text embedding service embedding_model_deployment_name = os.environ.get(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT_NAME\") kernel.add_service( AzureTextEmbedding( service_id=\"text_embedding\", deployment_name=embedding_model_deployment_name, endpoint=endpoint, api_key=api_key, ) ) 2.openai\nfrom semantic_kernel import Kernel import os from dotenv import load_dotenv, find_dotenv from semantic_kernel.connectors.ai.open_ai import ( AzureChatCompletion, AzureTextEmbedding, OpenAIChatCompletion, OpenAITextEmbedding， ) # Intialize the kernel kernel = Kernel() openai_api_key = os.getenv(\"OPENAI_API_KEY\") # Add the OpenAI service kernel.add_service(OpenAIChatCompletion( ai_model_id=\"gpt-4o-mini-2024-07-18\", api_key=os.getenv(\"OPENAI_API_KEY\") )) kernel.add_service( embedding_gen = OpenAITextEmbedding( ai_model_id=\"text-embedding-3-small\", api_key = openai_api_key ) ) 配置向量数据库 semantic kernel的API中的支持本地数据库，云数据库常用Azure较多。 注意：暂不支持pinecone云数据库。\nfrom semantic_kernel.connectors.memory.azure_cosmosdb import ( AzureCosmosDBMemoryStore, ) print(\"Creating or updating Azure Cosmos DB Memory Store...\") # create azure cosmos db for mongo db vcore api store and collection with vector ivf # currently, semantic kernel only supports the ivf vector kind store = await AzureCosmosDBMemoryStore.create( cosmos_connstr=os.environ.get(\"AZCOSMOS_CONNSTR\"), cosmos_api=\"mongo-vcore\", database_name=os.environ.get(\"AZCOSMOS_DATABASE_NAME\"), collection_name=collection_name, index_name=index_name, vector_dimensions=vector_dimensions, num_lists=num_lists, similarity=similarity, ) print(\"Finished updating Azure Cosmos DB Memory Store...\") from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory from semantic_kernel.core_plugins.text_memory_plugin import TextMemoryPlugin memory = SemanticTextMemory(storage=store, embeddings_generator=kernel.get_service(\"text_embedding\")) kernel.add_plugin(TextMemoryPlugin(memory), \"TextMemoryPluginACDB\") print(\"Registered Azure Cosmos DB Memory Store...\") 生成嵌入并创建数据库记录\nimport json from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory from semantic_kernel.memory.memory_store_base import MemoryStoreBase async def upsert_data_to_memory_store(memory: SemanticTextMemory, store: MemoryStoreBase, data_file_path: str) -\u003e None: \"\"\" This asynchronous function takes two memory stores and a data file path as arguments. It is designed to upsert (update or insert) data into the memory stores from the data file. Args: memory (callable): A callable object that represents the semantic kernel memory. store (callable): A callable object that represents the memory store where data will be upserted. data_file_path (str): The path to the data file that contains the data to be upserted. Returns: None. The function performs an operation that modifies the memory stores in-place. \"\"\" with open(file=data_file_path, mode=\"r\", encoding=\"utf-8\") as f: data = json.load(f) n = 0 for item in data: n += 1 # check if the item already exists in the memory store # if the id doesn't exist, it throws an exception try: already_created = bool(await store.get(collection_name, item[\"id\"], with_embedding=True)) except Exception: already_created = False # if the record doesn't exist, we generate embeddings and save it to the database if not already_created: await memory.save_information( collection=collection_name, id=item[\"id\"], # the embedding is generated from the text field text=item[\"content\"], description=item[\"title\"], ) print( \"Generating embeddings and saving new item:\", n, \"/\", len(data), end=\"\\r\", ) else: print(\"Skipping item already exits:\", n, \"/\", len(data), end=\"\\r\") # cleaned-top-movies-chunked.json contains the top 344 movie from the IMDB movies dataset # You can also try the text-sample.json which contains 107 Azure Service. # Replace the file name cleaned-top-movies-chunked.json with text-sample.json #生成嵌入并创建数据库记录 print(\"Upserting data to Azure Cosmos DB Memory Store...\") await upsert_data_to_memory_store(memory, store, \"./src/data/cleaned-top-movies-chunked.json\") （可选）测试向量数据库\n# each time it calls the embedding model to generate embeddings from your query query_term = \"What do you know about the godfather?\" result = await memory.search(collection_name, query_term) print( f\"Result is: {result[0].text}\\nRelevance Score: {result[0].relevance}\\nFull Record: {result[0].additional_metadata}\" ) RAG flow\n# 1.设置prompt prompt = \"\"\" Give explicit answers from the provided context or say 'I don't know' if it does not have an answer. provided context: {{$db_record}} User: {{$query_term}} Chatbot:\"\"\" from semantic_kernel.connectors.ai.open_ai import OpenAITextPromptExecutionSettings # 2.指定kernel中的LLM，并设置参数 execution_settings = OpenAITextPromptExecutionSettings( service_id=\"chat_completion\", ai_model_id=chat_model_deployment_name, max_tokens=500, temperature=0.0, top_p=0.5 ) from semantic_kernel.prompt_template import PromptTemplateConfig from semantic_kernel.prompt_template.input_variable import InputVariable # 3.配置chat功能 chat_prompt_hist_template_config = PromptTemplateConfig( template=prompt, name=\"grounded_response_history\", template_format=\"semantic-kernel\", input_variables=[ InputVariable(name=\"db_record\", description=\"The database record\", is_required=True), InputVariable(name=\"query_term\", description=\"The user input\", is_required=True), InputVariable(name=\"history\", description=\"The chat histroy\", is_required=True), ], execution_settings=execution_settings, ) chat_history_function = kernel.add_function( function_name=\"ChatGPTFuncHist\", plugin_name=\"chatGPTPluginHist\", prompt_template_config=chat_prompt_hist_template_config ) # 4.调用 from semantic_kernel.functions import KernelArguments from semantic_kernel.contents import ChatHistory import time chat_history = ChatHistory() chat_history.add_system_message(\"You are a helpful chatbot who is good about giving movie recommendations.\") query_term = \"\" search_result = \"\" completions_result = \"\" while query_term != \"exit\": query_term = input(\"Enter a query: \") chat_history.add_user_message(query_term) search_result = await memory.search(collection_name, query_term) # vector search completions_result = await kernel.invoke( chat_history_function, KernelArguments(query_term=query_term, db_record=search_result[0].additional_metadata) ) chat_history.add_assistant_message(str(completions_result)) print(f\"Question:\\n{query_term}\\nResponse:\") print(str(completions_result), end=\"\") print(\"\\n\") time.sleep(5) ",
  "wordCount" : "2528",
  "inLanguage": "zh",
  "datePublished": "2024-07-28T00:18:23+08:00",
  "dateModified": "2024-07-28T00:18:23+08:00",
  "author":[{
    "@type": "Person",
    "name": "aliga"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://Aliga123.github.io/posts/ai-llm/semantic-kernel/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "aliga's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://Aliga123.github.io/img/Q.gif"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    (function () {
        let  arr,reg = new RegExp("(^| )"+"change-themes"+"=([^;]*)(;|$)");
        if(arr = document.cookie.match(reg)) {
        } else {
            if (new Date().getHours() >= 19 || new Date().getHours() < 6) {
                document.body.classList.add('dark');
                localStorage.setItem("pref-theme", 'dark');
            } else {
                document.body.classList.remove('dark');
                localStorage.setItem("pref-theme", 'light');
            }
        }
    })()

    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }
</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://Aliga123.github.io/" accesskey="h" title="Aliga&#39;s Blog (Alt + H)">
            <img src="https://Aliga123.github.io/img/Q.gif" alt="logo" aria-label="logo"
                 height="35">Aliga&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://Aliga123.github.io/search" title="🔍 搜索 (Alt &#43; /)" accesskey=/>
                <span>🔍 搜索</span>
                </a>
            </li>
            <li>
                <a href="https://Aliga123.github.io/" title="🏠 主页">
                <span>🏠 主页</span>
                </a>
            </li>
            <li>
                <a href="https://Aliga123.github.io/posts" title="📚 文章">
                <span>📚 文章</span>
                </a>
            </li>
            <li>
                <a href="https://Aliga123.github.io/tags" title="🧩 标签">
                <span>🧩 标签</span>
                </a>
            </li>
            <li>
                <a href="https://Aliga123.github.io/archives/" title="⏱️ 时间轴">
                <span>⏱️ 时间轴</span>
                </a>
            </li>
            <li>
                <a href="https://Aliga123.github.io/about" title="🙋🏻‍♂️ 关于">
                <span>🙋🏻‍♂️ 关于</span>
                </a>
            </li>
            <li>
                <a href="https://Aliga123.github.io/links" title="🤝 友链">
                <span>🤝 友链</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main page">
<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }
</style>

<article class="post-single">
    <div id="single-content">
        <header class="post-header">
            <div class="breadcrumbs"><a href="https://Aliga123.github.io/">🏠 主页</a>&nbsp;»&nbsp;<a href="https://Aliga123.github.io/posts/">📚文章</a>&nbsp;»&nbsp;<a href="https://Aliga123.github.io/posts/ai-llm/">🧱 AI大模型应用开发</a></div>
            <h1 class="post-title">
                Semantic Kernel
            </h1>
            <div class="post-meta">

<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }

    .parent-post-meta {
        display: flex;
        flex-wrap: wrap;
        opacity: 0.8;
    }
</style>

<span class="parent-post-meta">
    <span id="post_meta_style_1">
        <span class="fa fa-calendar-check-o"></span>
        <span>2024-07-28
            &nbsp;&nbsp;
        </span>
    </span>
    
    
    
    
    
    
    
    <span id="post_meta_style_3">
        <span class="fa fa-file-word-o"></span>
        <span>2528字
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_4">
        <span class="fa fa-clock-o"></span>
        <span>6分钟
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_5">
        <span class="fa fa-user-o"></span>
        <span>aliga
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_6">
        <span class="fa fa-tags" style="opacity: 0.8"></span>
        <span>
            <span class="post-tags-meta">
            </span>
        </span>
    </span>
</span>
<span style="opacity: 0.8;">
                    <span id="post_meta_style_7">
                        &nbsp;&nbsp;
                        <span class="fa fa-eye" ></span>
                        <span>
                            <span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv"></span></span>
                            &nbsp;&nbsp;
                        </span>
                    </span>
                    <span id="post_meta_style_8">
                        <span class="fa fa-commenting-o"></span>
                        <span>
                            <script src="https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js"></script>
                            <script>
                                let url = document.documentURI
                                
                                let dnsUrl = "https://Aliga123.github.io/"
                                let urlSplit = url.split(dnsUrl)
                                let finalUrl = urlSplit[1]
                                if (finalUrl[0] !== '/') {
                                    finalUrl = '/'+finalUrl
                                }
                                twikoo.getCommentsCount({
                                    envId:  null , 
                                region:  null , 
                                urls: [ 
                                    
                                    finalUrl,
                                ],
                                    includeReply: false 
                                }).then(function (res) {
                                    let count = res[0].count
                                    const obj = document.getElementById("comment_count");
                                    obj.innerText = count
                                    
                                    
                                    
                                }).catch(function (err) {
                                    
                                    console.error(err);
                                });
                            </script>
                            <span id="comment_count"></span>
                        </span>
                    </span>
                </span>

</div>
        </header> <aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">目录</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#semantic-kernel" aria-label="Semantic Kernel">Semantic Kernel</a><ul>
                        
                <li>
                    <a href="#%e5%af%bc%e5%85%a5%e5%b8%b8%e7%94%a8%e7%9a%84%e5%ba%93" aria-label="导入常用的库">导入常用的库</a></li>
                <li>
                    <a href="#%e5%88%9d%e5%a7%8b%e5%8c%96kernel" aria-label="初始化kernel">初始化kernel</a></li>
                <li>
                    <a href="#%e6%b7%bb%e5%8a%a0llm%e6%9c%8d%e5%8a%a1" aria-label="添加LLM服务">添加LLM服务</a></li>
                <li>
                    <a href="#%e8%ae%be%e7%bd%ae%e4%bc%81%e4%b8%9a%e6%9c%8d%e5%8a%a1" aria-label="设置企业服务">设置企业服务</a></li>
                <li>
                    <a href="#%e5%90%af%e5%8a%a8%e8%87%aa%e5%8a%a8%e8%a7%84%e5%88%92" aria-label="启动自动规划">启动自动规划</a></li>
                <li>
                    <a href="#%e6%b7%bb%e5%8a%a0%e6%8f%92%e4%bb%b6%e6%9c%8d%e5%8a%a1function-calling" aria-label="添加插件服务（Function Calling）">添加插件服务（Function Calling）</a></li>
                <li>
                    <a href="#%e5%bb%ba%e7%ab%8b%e5%af%b9%e8%af%9d%e6%9c%8d%e5%8a%a1%e7%a1%ae%e5%ae%9a%e4%b8%8a%e8%bf%b0%e6%9c%8d%e5%8a%a1%e5%90%8e" aria-label="建立对话服务（确定上述服务后）">建立对话服务（确定上述服务后）</a></li>
                <li>
                    <a href="#%e5%88%9b%e5%bb%ba%e5%8e%86%e5%8f%b2%e5%af%b9%e8%af%9d%e5%b9%b6%e8%ae%be%e7%bd%aeprompt" aria-label="创建历史对话，并设置prompt">创建历史对话，并设置prompt</a></li>
                <li>
                    <a href="#%e6%b7%bb%e5%8a%a0%e7%94%a8%e6%88%b7%e8%be%93%e5%85%a5%e8%ae%b0%e5%bd%95" aria-label="添加用户输入记录">添加用户输入记录</a></li>
                <li>
                    <a href="#%e6%89%a7%e8%a1%8c%e5%af%b9%e8%af%9d%e8%8e%b7%e5%be%97%e5%9b%9e%e5%a4%8d" aria-label="执行对话，获得回复">执行对话，获得回复</a></li>
                <li>
                    <a href="#%e6%b7%bb%e5%8a%a0ai%e5%93%8d%e5%ba%94%e8%ae%b0%e5%bd%95" aria-label="添加AI响应记录">添加AI响应记录</a></li>
                <li>
                    <a href="#%e4%bd%bf%e7%94%a8sk%e5%ae%9e%e7%8e%b0rag" aria-label="使用SK实现RAG">使用SK实现RAG</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
        
        activeElement = elements[0];
        const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
        document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
    }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        if (elements) {
            activeElement = Array.from(elements).find((element) => {
                if ((getOffsetTop(element) - window.pageYOffset) > 0 &&
                    (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                    return element;
                }
            }) || activeElement

            elements.forEach(element => {
                const id = encodeURI(element.getAttribute('id')).toLowerCase();
                if (element === activeElement){
                    document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
                } else {
                    document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
                }
            })
        }
    }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;
        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;
    }
</script>
        <div class="post-content"><h1 id="semantic-kernel">Semantic Kernel<a hidden class="anchor" aria-hidden="true" href="#semantic-kernel">#</a></h1>
<p>Sematic Kernel 通过 <strong>Kernel</strong> 链接 LLM 与 <strong>Functions</strong>（功能）:</p>
<ul>
<li>Semantic Functions：通过 Prompt 实现的 LLM 能力</li>
<li>Native Functions: 编程语言原生的函数功能</li>
</ul>
<p>在 SK 中，一组 Function 组成一个技能（Skill/Plugin）。要运行 Skill/Plugin，需要有一个配置和管理的单元，这个组织管理单元就是 Kernel。</p>
<p>Kernel 负责管理底层接口与调用顺序，例如：OpenAI/Azure OpenAI 的授权信息、默认的 LLM 模型选择、对话上下文、技能参数的传递等等。</p>
<h2 id="导入常用的库">导入常用的库<a hidden class="anchor" aria-hidden="true" href="#导入常用的库">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> dotenv <span style="color:#f92672">import</span> load_dotenv, find_dotenv
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> asyncio
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> logging
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel <span style="color:#f92672">import</span> Kernel
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.functions <span style="color:#f92672">import</span> kernel_function
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.connectors.ai.open_ai <span style="color:#f92672">import</span> AzureChatCompletion
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.connectors.ai.open_ai <span style="color:#f92672">import</span> OpenAIChatCompletion
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.connectors.ai.function_call_behavior <span style="color:#f92672">import</span> FunctionCallBehavior
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.connectors.ai.chat_completion_client_base <span style="color:#f92672">import</span> ChatCompletionClientBase
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.contents.chat_history <span style="color:#f92672">import</span> ChatHistory
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.functions.kernel_arguments <span style="color:#f92672">import</span> KernelArguments
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.connectors.ai.open_ai.prompt_execution_settings.azure_chat_prompt_execution_settings <span style="color:#f92672">import</span> (
</span></span><span style="display:flex;"><span>    AzureChatPromptExecutionSettings,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.functions <span style="color:#f92672">import</span> kernel_function
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> typing <span style="color:#f92672">import</span> List
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.contents <span style="color:#f92672">import</span> ChatMessageContent, TextContent, ImageContent
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.contents.utils.author_role <span style="color:#f92672">import</span> AuthorRole
</span></span></code></pre></div><h2 id="初始化kernel">初始化kernel<a hidden class="anchor" aria-hidden="true" href="#初始化kernel">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Initialize the kernel</span>
</span></span><span style="display:flex;"><span>kernel <span style="color:#f92672">=</span> Kernel()
</span></span></code></pre></div><h2 id="添加llm服务">添加LLM服务<a hidden class="anchor" aria-hidden="true" href="#添加llm服务">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Add the Azure OpenAI chat completion service</span>
</span></span><span style="display:flex;"><span>kernel<span style="color:#f92672">.</span>add_service(OpenAIChatCompletion(
</span></span><span style="display:flex;"><span>    ai_model_id<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;gpt-3.5-turbo-1106&#34;</span>,
</span></span><span style="display:flex;"><span>    api_key<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>getenv(<span style="color:#e6db74">&#34;OPENAI_API_KEY&#34;</span>)
</span></span><span style="display:flex;"><span>))
</span></span></code></pre></div><h2 id="设置企业服务">设置企业服务<a hidden class="anchor" aria-hidden="true" href="#设置企业服务">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Set the logging level for  semantic_kernel.kernel to DEBUG.</span>
</span></span><span style="display:flex;"><span>logging<span style="color:#f92672">.</span>basicConfig(
</span></span><span style="display:flex;"><span>    format<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;[</span><span style="color:#e6db74">%(asctime)s</span><span style="color:#e6db74"> - </span><span style="color:#e6db74">%(name)s</span><span style="color:#e6db74">:</span><span style="color:#e6db74">%(lineno)d</span><span style="color:#e6db74"> - </span><span style="color:#e6db74">%(levelname)s</span><span style="color:#e6db74">] </span><span style="color:#e6db74">%(message)s</span><span style="color:#e6db74">&#34;</span>,
</span></span><span style="display:flex;"><span>    datefmt<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;%Y-%m-</span><span style="color:#e6db74">%d</span><span style="color:#e6db74"> %H:%M:%S&#34;</span>,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>logging<span style="color:#f92672">.</span>getLogger(<span style="color:#e6db74">&#34;kernel&#34;</span>)<span style="color:#f92672">.</span>setLevel(logging<span style="color:#f92672">.</span>DEBUG)
</span></span></code></pre></div><h2 id="启动自动规划">启动自动规划<a hidden class="anchor" aria-hidden="true" href="#启动自动规划">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Enable planning</span>
</span></span><span style="display:flex;"><span>execution_settings <span style="color:#f92672">=</span> AzureChatPromptExecutionSettings(tool_choice<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;auto&#34;</span>)
</span></span><span style="display:flex;"><span>execution_settings<span style="color:#f92672">.</span>function_call_behavior <span style="color:#f92672">=</span> FunctionCallBehavior<span style="color:#f92672">.</span>EnableFunctions(auto_invoke<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, filters<span style="color:#f92672">=</span>{})
</span></span></code></pre></div><p><strong>自动规划循环</strong></p>
<p>如果不使用语义内核的函数调用会相对复杂。您需要编写一个循环来完成以下操作：</p>
<ol>
<li>为每个函数创建 JSON 架构</li>
<li>向 LLM 提供之前的聊天记录和功能模式</li>
<li>解析 LLM 的响应以确定它是要回复消息还是调用函数</li>
<li>如果 LLM 想要调用某个函数，你需要从 LLM 的响应中解析函数名称和参数</li>
<li>使用正确的参数调用函数</li>
<li>返回函数的结果，以便 LLM 可以确定下一步该做什么</li>
<li>重复步骤 2-6，直到 LLM 决定已完成任务或需要用户的帮助</li>
</ol>
<p>函数调用的过程：</p>
<p><img loading="lazy" src="https://learn.microsoft.com/en-us/semantic-kernel/media/functioncalling.png" alt="语义内核函数调用"  />
</p>
<table>
<thead>
<tr>
<th>1</th>
<th><a href="https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-python#1-serializing-the-functions"><strong>序列化函数</strong></a></th>
<th>内核中所有可用的函数（及其输入参数）都使用 JSON 模式序列化。</th>
</tr>
</thead>
<tbody>
<tr>
<td>2</td>
<td><a href="https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-python#2-sending-the-messages-and-functions-to-the-model"><strong>将消息和函数发送给模型</strong></a></td>
<td>序列化的函数（和当前聊天记录）作为输入的一部分发送到模型。</td>
</tr>
<tr>
<td>3</td>
<td><a href="https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-python#3-model-processes-the-input"><strong>模型处理输入</strong></a></td>
<td>模型处理输入并生成响应。响应可以是聊天消息或函数调用</td>
</tr>
<tr>
<td>4</td>
<td><a href="https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-python#4-handle-the-response"><strong>处理响应</strong></a></td>
<td>如果响应是聊天消息，则返回给开发人员以将响应打印到屏幕上。但是，如果响应是函数调用，则 Semantic Kernel 会提取函数名称及其参数。</td>
</tr>
<tr>
<td>5</td>
<td><a href="https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-python#5-invoke-the-function"><strong>调用函数</strong></a></td>
<td>提取的函数名和参数用于调用内核中的函数。</td>
</tr>
<tr>
<td>6</td>
<td><a href="https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling?pivots=programming-language-python#6-return-the-function-result"><strong>返回函数结果</strong></a></td>
<td>然后，函数的结果将作为聊天历史记录的一部分发送回模型。然后重复步骤 2-6，直到模型发送终止信号</td>
</tr>
</tbody>
</table>
<p>在 Semantic Kernel 中，我们通过为您自动执行此循环，让您可以轻松使用函数调用。这样您就可以专注于构建满足用户需求所需的插件。
要在语义内核中使用自动函数调用，您需要执行以下操作：</p>
<ol>
<li>向内核注册插件</li>
<li>创建一个执行设置对象，告诉 AI 自动调用函数</li>
<li>使用聊天历史记录和内核调用聊天完成服务</li>
</ol>
<h2 id="添加插件服务function-calling">添加插件服务（Function Calling）<a hidden class="anchor" aria-hidden="true" href="#添加插件服务function-calling">#</a></h2>
<p><strong>1.添加原生（Native）代码作为插件</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">EmailPlugin</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, name):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>name <span style="color:#f92672">=</span> name
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>time <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;2024-7&#39;</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">@kernel_function</span>(
</span></span><span style="display:flex;"><span>        name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;send_email&#34;</span>,
</span></span><span style="display:flex;"><span>        description<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Sends an email to a recipient.&#34;</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">async</span> <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">send_email</span>(self, recipient_emails: str<span style="color:#f92672">|</span>List[str], subject: str, body: str):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Add logic to send an email using the recipient_emails, subject, and body</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># For now, we&#39;ll just print out a success message to the console</span>
</span></span><span style="display:flex;"><span>        print(self<span style="color:#f92672">.</span>name <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;Email sent!&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">## ...可以多个函数</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Add a plugin (the EmailPlugin class is defined above)</span>
</span></span><span style="display:flex;"><span>kernel<span style="color:#f92672">.</span>add_plugin(
</span></span><span style="display:flex;"><span>    EmailPlugin(<span style="color:#e6db74">&#39;aliga&#39;</span>),
</span></span><span style="display:flex;"><span>    plugin_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Email&#34;</span>,
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p>上述插件序列化函数后的JOSN如下：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>[
</span></span><span style="display:flex;"><span>  {
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;function&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;function&#34;</span>: {
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;send_email&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;description&#34;</span>: <span style="color:#e6db74">&#34;Sends an email to a recipient.&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;parameters&#34;</span>: {
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;object&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;properties&#34;</span>: {
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;recipient_emails&#34;</span>: {
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;string&#34;</span>
</span></span><span style="display:flex;"><span>          },
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;subject&#34;</span>: {
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;string&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;enum&#34;</span>: [<span style="color:#e6db74">&#34;请假&#34;</span>, <span style="color:#e6db74">&#34;工作文件&#34;</span>, <span style="color:#e6db74">&#34;报表&#34;</span>]
</span></span><span style="display:flex;"><span>          },
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;body&#34;</span>: {
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;string&#34;</span>
</span></span><span style="display:flex;"><span>          }
</span></span><span style="display:flex;"><span>        },
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;required&#34;</span>: [<span style="color:#e6db74">&#34;recipient_emails&#34;</span>, <span style="color:#e6db74">&#34;subject&#34;</span>, <span style="color:#e6db74">&#34;body&#34;</span>]
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>]
</span></span></code></pre></div><p><strong>2.添加逻辑应用作为插件（仅限C#）</strong></p>
<h2 id="建立对话服务确定上述服务后">建立对话服务（确定上述服务后）<a hidden class="anchor" aria-hidden="true" href="#建立对话服务确定上述服务后">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Build the kernel and retrieve services</span>
</span></span><span style="display:flex;"><span>chat_completion : AzureChatCompletion <span style="color:#f92672">=</span> kernel<span style="color:#f92672">.</span>get_service(type<span style="color:#f92672">=</span>ChatCompletionClientBase)
</span></span></code></pre></div><h2 id="创建历史对话并设置prompt">创建历史对话，并设置prompt<a hidden class="anchor" aria-hidden="true" href="#创建历史对话并设置prompt">#</a></h2>
<p>方法一</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Create a history of the conversation</span>
</span></span><span style="display:flex;"><span>history <span style="color:#f92672">=</span> ChatHistory(system_message<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    You are a friendly assistant who likes to follow the rules. You will complete required steps
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    and request approval before taking any consequential actions. If the user doesn&#39;t provide
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    enough information for you to complete a task, you will keep asking questions until you have
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    enough information to complete the task.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>)
</span></span></code></pre></div><p>方法二</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 添加system_message第二种方法</span>
</span></span><span style="display:flex;"><span>chat_history <span style="color:#f92672">=</span> ChatHistory()
</span></span><span style="display:flex;"><span>chat_history<span style="color:#f92672">.</span>add_system_message(<span style="color:#e6db74">&#34;You are a helpful assistant.&#34;</span>)
</span></span></code></pre></div><p>方法三</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Add system message，第三种方法</span>
</span></span><span style="display:flex;"><span>history <span style="color:#f92672">=</span> ChatHistory()
</span></span><span style="display:flex;"><span>chat_history<span style="color:#f92672">.</span>add_message(
</span></span><span style="display:flex;"><span>    ChatMessage(
</span></span><span style="display:flex;"><span>        role<span style="color:#f92672">=</span>AuthorRole<span style="color:#f92672">.</span>System,
</span></span><span style="display:flex;"><span>        content<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;You are a helpful assistant&#34;</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><h2 id="添加用户输入记录">添加用户输入记录<a hidden class="anchor" aria-hidden="true" href="#添加用户输入记录">#</a></h2>
<p>方法一：文本</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>history<span style="color:#f92672">.</span>add_user_message(user_input)
</span></span></code></pre></div><p>方法二：文本</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Add additional message from a different user，第二种方法，可以指定name</span>
</span></span><span style="display:flex;"><span>chat_history<span style="color:#f92672">.</span>add_message(
</span></span><span style="display:flex;"><span>    ChatMessageContent(
</span></span><span style="display:flex;"><span>        role<span style="color:#f92672">=</span>AuthorRole<span style="color:#f92672">.</span>USER,
</span></span><span style="display:flex;"><span>        name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Ema Vargova&#34;</span>,
</span></span><span style="display:flex;"><span>        content<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;I&#39;d like to have the first option, please.&#34;</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p>方法三：添加图片</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Add user message with an image</span>
</span></span><span style="display:flex;"><span>chat_history<span style="color:#f92672">.</span>add_message(
</span></span><span style="display:flex;"><span>    ChatMessageContent(
</span></span><span style="display:flex;"><span>        role<span style="color:#f92672">=</span>AuthorRole<span style="color:#f92672">.</span>USER,
</span></span><span style="display:flex;"><span>        name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Laimonis Dumins&#34;</span>,
</span></span><span style="display:flex;"><span>        items<span style="color:#f92672">=</span>[
</span></span><span style="display:flex;"><span>            TextContent(text<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;What available on this menu&#34;</span>),
</span></span><span style="display:flex;"><span>            ImageContent(uri<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;https://example.com/menu.jpg&#34;</span>)
</span></span><span style="display:flex;"><span>        ]
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><h2 id="执行对话获得回复">执行对话，获得回复<a hidden class="anchor" aria-hidden="true" href="#执行对话获得回复">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Get the response from the AI</span>
</span></span><span style="display:flex;"><span>result <span style="color:#f92672">=</span> (<span style="color:#66d9ef">await</span> chat_completion<span style="color:#f92672">.</span>get_chat_message_contents(  
</span></span><span style="display:flex;"><span>    chat_history<span style="color:#f92672">=</span>history,
</span></span><span style="display:flex;"><span>    settings<span style="color:#f92672">=</span>execution_settings,
</span></span><span style="display:flex;"><span>    kernel<span style="color:#f92672">=</span>kernel,
</span></span><span style="display:flex;"><span>    arguments<span style="color:#f92672">=</span>KernelArguments(),
</span></span><span style="display:flex;"><span>))[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print the response</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Assistant &gt; &#34;</span> <span style="color:#f92672">+</span> str(result))
</span></span></code></pre></div><h2 id="添加ai响应记录">添加AI响应记录<a hidden class="anchor" aria-hidden="true" href="#添加ai响应记录">#</a></h2>
<p>方法一</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>history<span style="color:#f92672">.</span>add_assistant_message(str(result))
</span></span></code></pre></div><p>方法二</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Add assistant message，第二种方法，可以指定name</span>
</span></span><span style="display:flex;"><span>chat_history<span style="color:#f92672">.</span>add_message(
</span></span><span style="display:flex;"><span>    ChatMessageContent(
</span></span><span style="display:flex;"><span>        role<span style="color:#f92672">=</span>AuthorRole<span style="color:#f92672">.</span>ASSISTANT,
</span></span><span style="display:flex;"><span>        name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Restaurant Assistant&#34;</span>,
</span></span><span style="display:flex;"><span>        content<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;We have pizza, pasta, and salad available to order. What would you like to order?&#34;</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><h2 id="使用sk实现rag">使用SK实现RAG<a hidden class="anchor" aria-hidden="true" href="#使用sk实现rag">#</a></h2>
<p>参考：https://github.com/john0isaac/rag-semantic-kernel-mongodb-vcore/blob/main/rag-azure-openai-cosmosdb-notebook.ipynb
<strong>设置一些参数</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># collection name will be used multiple times in the code so we store it in a variable</span>
</span></span><span style="display:flex;"><span>collection_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;VectorSearchCollection&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Vector search index parameters</span>
</span></span><span style="display:flex;"><span>index_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;VectorSearchIndex&#34;</span>
</span></span><span style="display:flex;"><span>vector_dimensions <span style="color:#f92672">=</span> <span style="color:#ae81ff">1536</span>  <span style="color:#75715e"># text-embedding-ada-002 uses a 1536-dimensional embedding vector</span>
</span></span><span style="display:flex;"><span>num_lists <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>similarity <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;COS&#34;</span>  <span style="color:#75715e"># cosine distance</span>
</span></span></code></pre></div><p><strong>配置LLMChat、embedding模型</strong></p>
<p>1.Azure</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel <span style="color:#f92672">import</span> Kernel
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> dotenv <span style="color:#f92672">import</span> load_dotenv, find_dotenv
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.connectors.ai.open_ai <span style="color:#f92672">import</span> (
</span></span><span style="display:flex;"><span>    AzureChatCompletion,
</span></span><span style="display:flex;"><span>    AzureTextEmbedding,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Intialize the kernel</span>
</span></span><span style="display:flex;"><span>kernel <span style="color:#f92672">=</span> Kernel()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># adding azure openai chat service</span>
</span></span><span style="display:flex;"><span>chat_model_deployment_name <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>environ<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;AZURE_OPENAI_CHAT_DEPLOYMENT_NAME&#34;</span>)
</span></span><span style="display:flex;"><span>endpoint <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>environ<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;AZURE_OPENAI_ENDPOINT&#34;</span>)
</span></span><span style="display:flex;"><span>api_key <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>environ<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;AZURE_OPENAI_API_KEY&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kernel<span style="color:#f92672">.</span>add_service(
</span></span><span style="display:flex;"><span>    AzureChatCompletion(
</span></span><span style="display:flex;"><span>        service_id<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;chat_completion&#34;</span>,
</span></span><span style="display:flex;"><span>        deployment_name<span style="color:#f92672">=</span>chat_model_deployment_name,
</span></span><span style="display:flex;"><span>        endpoint<span style="color:#f92672">=</span>endpoint,
</span></span><span style="display:flex;"><span>        api_key<span style="color:#f92672">=</span>api_key,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span><span style="color:#75715e"># adding azure openai text embedding service</span>
</span></span><span style="display:flex;"><span>embedding_model_deployment_name <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>environ<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT_NAME&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kernel<span style="color:#f92672">.</span>add_service(
</span></span><span style="display:flex;"><span>    AzureTextEmbedding(
</span></span><span style="display:flex;"><span>        service_id<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;text_embedding&#34;</span>,
</span></span><span style="display:flex;"><span>        deployment_name<span style="color:#f92672">=</span>embedding_model_deployment_name,
</span></span><span style="display:flex;"><span>        endpoint<span style="color:#f92672">=</span>endpoint,
</span></span><span style="display:flex;"><span>        api_key<span style="color:#f92672">=</span>api_key,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p>2.openai</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel <span style="color:#f92672">import</span> Kernel
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> dotenv <span style="color:#f92672">import</span> load_dotenv, find_dotenv
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.connectors.ai.open_ai <span style="color:#f92672">import</span> (
</span></span><span style="display:flex;"><span>    AzureChatCompletion,
</span></span><span style="display:flex;"><span>    AzureTextEmbedding,
</span></span><span style="display:flex;"><span>    OpenAIChatCompletion,
</span></span><span style="display:flex;"><span>    OpenAITextEmbedding<span style="color:#960050;background-color:#1e0010">，</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Intialize the kernel</span>
</span></span><span style="display:flex;"><span>kernel <span style="color:#f92672">=</span> Kernel()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>openai_api_key <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>getenv(<span style="color:#e6db74">&#34;OPENAI_API_KEY&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Add the OpenAI service</span>
</span></span><span style="display:flex;"><span>kernel<span style="color:#f92672">.</span>add_service(OpenAIChatCompletion(
</span></span><span style="display:flex;"><span>    ai_model_id<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;gpt-4o-mini-2024-07-18&#34;</span>,
</span></span><span style="display:flex;"><span>    api_key<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>getenv(<span style="color:#e6db74">&#34;OPENAI_API_KEY&#34;</span>)
</span></span><span style="display:flex;"><span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kernel<span style="color:#f92672">.</span>add_service(
</span></span><span style="display:flex;"><span>    embedding_gen <span style="color:#f92672">=</span> OpenAITextEmbedding(
</span></span><span style="display:flex;"><span>        ai_model_id<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;text-embedding-3-small&#34;</span>,
</span></span><span style="display:flex;"><span>        api_key <span style="color:#f92672">=</span> openai_api_key
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p><strong>配置向量数据库</strong>
<a href="https://learn.microsoft.com/en-us/python/api/semantic-kernel/semantic_kernel.connectors.memory.chroma.chroma_memory_store.chromamemorystore?view=semantic-kernel-python">semantic kernel的API</a>中的支持本地数据库，云数据库常用Azure较多。
注意：暂不支持pinecone云数据库。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.connectors.memory.azure_cosmosdb <span style="color:#f92672">import</span> (
</span></span><span style="display:flex;"><span>    AzureCosmosDBMemoryStore,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Creating or updating Azure Cosmos DB Memory Store...&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># create azure cosmos db for mongo db vcore api store and collection with vector ivf</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># currently, semantic kernel only supports the ivf vector kind</span>
</span></span><span style="display:flex;"><span>store <span style="color:#f92672">=</span> <span style="color:#66d9ef">await</span> AzureCosmosDBMemoryStore<span style="color:#f92672">.</span>create(
</span></span><span style="display:flex;"><span>    cosmos_connstr<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>environ<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;AZCOSMOS_CONNSTR&#34;</span>),
</span></span><span style="display:flex;"><span>    cosmos_api<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;mongo-vcore&#34;</span>,
</span></span><span style="display:flex;"><span>    database_name<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>environ<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;AZCOSMOS_DATABASE_NAME&#34;</span>),
</span></span><span style="display:flex;"><span>    collection_name<span style="color:#f92672">=</span>collection_name,
</span></span><span style="display:flex;"><span>    index_name<span style="color:#f92672">=</span>index_name,
</span></span><span style="display:flex;"><span>    vector_dimensions<span style="color:#f92672">=</span>vector_dimensions,
</span></span><span style="display:flex;"><span>    num_lists<span style="color:#f92672">=</span>num_lists,
</span></span><span style="display:flex;"><span>    similarity<span style="color:#f92672">=</span>similarity,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Finished updating Azure Cosmos DB Memory Store...&#34;</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.memory.semantic_text_memory <span style="color:#f92672">import</span> SemanticTextMemory
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.core_plugins.text_memory_plugin <span style="color:#f92672">import</span> TextMemoryPlugin
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>memory <span style="color:#f92672">=</span> SemanticTextMemory(storage<span style="color:#f92672">=</span>store, embeddings_generator<span style="color:#f92672">=</span>kernel<span style="color:#f92672">.</span>get_service(<span style="color:#e6db74">&#34;text_embedding&#34;</span>))
</span></span><span style="display:flex;"><span>kernel<span style="color:#f92672">.</span>add_plugin(TextMemoryPlugin(memory), <span style="color:#e6db74">&#34;TextMemoryPluginACDB&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Registered Azure Cosmos DB Memory Store...&#34;</span>)
</span></span></code></pre></div><p><strong>生成嵌入并创建数据库记录</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> json
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.memory.semantic_text_memory <span style="color:#f92672">import</span> SemanticTextMemory
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.memory.memory_store_base <span style="color:#f92672">import</span> MemoryStoreBase
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">async</span> <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">upsert_data_to_memory_store</span>(memory: SemanticTextMemory, store: MemoryStoreBase, data_file_path: str) <span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    This asynchronous function takes two memory stores and a data file path as arguments.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    It is designed to upsert (update or insert) data into the memory stores from the data file.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        memory (callable): A callable object that represents the semantic kernel memory.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        store (callable): A callable object that represents the memory store where data will be upserted.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        data_file_path (str): The path to the data file that contains the data to be upserted.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        None. The function performs an operation that modifies the memory stores in-place.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> open(file<span style="color:#f92672">=</span>data_file_path, mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;r&#34;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;utf-8&#34;</span>) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>        data <span style="color:#f92672">=</span> json<span style="color:#f92672">.</span>load(f)
</span></span><span style="display:flex;"><span>        n <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> item <span style="color:#f92672">in</span> data:
</span></span><span style="display:flex;"><span>            n <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># check if the item already exists in the memory store</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># if the id doesn&#39;t exist, it throws an exception</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>                already_created <span style="color:#f92672">=</span> bool(<span style="color:#66d9ef">await</span> store<span style="color:#f92672">.</span>get(collection_name, item[<span style="color:#e6db74">&#34;id&#34;</span>], with_embedding<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>))
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span>:
</span></span><span style="display:flex;"><span>                already_created <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># if the record doesn&#39;t exist, we generate embeddings and save it to the database</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> already_created:
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">await</span> memory<span style="color:#f92672">.</span>save_information(
</span></span><span style="display:flex;"><span>                    collection<span style="color:#f92672">=</span>collection_name,
</span></span><span style="display:flex;"><span>                    id<span style="color:#f92672">=</span>item[<span style="color:#e6db74">&#34;id&#34;</span>],
</span></span><span style="display:flex;"><span>                    <span style="color:#75715e"># the embedding is generated from the text field</span>
</span></span><span style="display:flex;"><span>                    text<span style="color:#f92672">=</span>item[<span style="color:#e6db74">&#34;content&#34;</span>],
</span></span><span style="display:flex;"><span>                    description<span style="color:#f92672">=</span>item[<span style="color:#e6db74">&#34;title&#34;</span>],
</span></span><span style="display:flex;"><span>                )
</span></span><span style="display:flex;"><span>                print(
</span></span><span style="display:flex;"><span>                    <span style="color:#e6db74">&#34;Generating embeddings and saving new item:&#34;</span>,
</span></span><span style="display:flex;"><span>                    n,
</span></span><span style="display:flex;"><span>                    <span style="color:#e6db74">&#34;/&#34;</span>,
</span></span><span style="display:flex;"><span>                    len(data),
</span></span><span style="display:flex;"><span>                    end<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\r</span><span style="color:#e6db74">&#34;</span>,
</span></span><span style="display:flex;"><span>                )
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>                print(<span style="color:#e6db74">&#34;Skipping item already exits:&#34;</span>, n, <span style="color:#e6db74">&#34;/&#34;</span>, len(data), end<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\r</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># cleaned-top-movies-chunked.json contains the top 344 movie from the IMDB movies dataset</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># You can also try the text-sample.json which contains 107 Azure Service.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Replace the file name cleaned-top-movies-chunked.json with text-sample.json</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#生成嵌入并创建数据库记录</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Upserting data to Azure Cosmos DB Memory Store...&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">await</span> upsert_data_to_memory_store(memory, store, <span style="color:#e6db74">&#34;./src/data/cleaned-top-movies-chunked.json&#34;</span>)
</span></span></code></pre></div><p><strong>（可选）测试向量数据库</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># each time it calls the embedding model to generate embeddings from your query</span>
</span></span><span style="display:flex;"><span>query_term <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;What do you know about the godfather?&#34;</span>
</span></span><span style="display:flex;"><span>result <span style="color:#f92672">=</span> <span style="color:#66d9ef">await</span> memory<span style="color:#f92672">.</span>search(collection_name, query_term)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Result is: </span><span style="color:#e6db74">{</span>result[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>text<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Relevance Score: </span><span style="color:#e6db74">{</span>result[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>relevance<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Full Record: </span><span style="color:#e6db74">{</span>result[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>additional_metadata<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p><strong>RAG flow</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 1.设置prompt</span>
</span></span><span style="display:flex;"><span>prompt <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Give explicit answers from the provided context or say &#39;I don&#39;t know&#39; if it does not have an answer.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    provided context: {{$db_record}}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    User: {{$query_term}}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Chatbot:&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.connectors.ai.open_ai <span style="color:#f92672">import</span> OpenAITextPromptExecutionSettings
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 2.指定kernel中的LLM，并设置参数</span>
</span></span><span style="display:flex;"><span>execution_settings <span style="color:#f92672">=</span> OpenAITextPromptExecutionSettings(
</span></span><span style="display:flex;"><span>    service_id<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;chat_completion&#34;</span>, ai_model_id<span style="color:#f92672">=</span>chat_model_deployment_name, max_tokens<span style="color:#f92672">=</span><span style="color:#ae81ff">500</span>, temperature<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0</span>, top_p<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.prompt_template <span style="color:#f92672">import</span> PromptTemplateConfig
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.prompt_template.input_variable <span style="color:#f92672">import</span> InputVariable
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 3.配置chat功能</span>
</span></span><span style="display:flex;"><span>chat_prompt_hist_template_config <span style="color:#f92672">=</span> PromptTemplateConfig(
</span></span><span style="display:flex;"><span>    template<span style="color:#f92672">=</span>prompt,
</span></span><span style="display:flex;"><span>    name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;grounded_response_history&#34;</span>,
</span></span><span style="display:flex;"><span>    template_format<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;semantic-kernel&#34;</span>,
</span></span><span style="display:flex;"><span>    input_variables<span style="color:#f92672">=</span>[
</span></span><span style="display:flex;"><span>        InputVariable(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;db_record&#34;</span>, description<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;The database record&#34;</span>, is_required<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>        InputVariable(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;query_term&#34;</span>, description<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;The user input&#34;</span>, is_required<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>        InputVariable(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;history&#34;</span>, description<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;The chat histroy&#34;</span>, is_required<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>    ],
</span></span><span style="display:flex;"><span>    execution_settings<span style="color:#f92672">=</span>execution_settings,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>chat_history_function <span style="color:#f92672">=</span> kernel<span style="color:#f92672">.</span>add_function(
</span></span><span style="display:flex;"><span>    function_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;ChatGPTFuncHist&#34;</span>, plugin_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;chatGPTPluginHist&#34;</span>, prompt_template_config<span style="color:#f92672">=</span>chat_prompt_hist_template_config
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 4.调用</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.functions <span style="color:#f92672">import</span> KernelArguments
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> semantic_kernel.contents <span style="color:#f92672">import</span> ChatHistory
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> time
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>chat_history <span style="color:#f92672">=</span> ChatHistory()
</span></span><span style="display:flex;"><span>chat_history<span style="color:#f92672">.</span>add_system_message(<span style="color:#e6db74">&#34;You are a helpful chatbot who is good about giving movie recommendations.&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>query_term <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>search_result <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>completions_result <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">while</span> query_term <span style="color:#f92672">!=</span> <span style="color:#e6db74">&#34;exit&#34;</span>:
</span></span><span style="display:flex;"><span>    query_term <span style="color:#f92672">=</span> input(<span style="color:#e6db74">&#34;Enter a query: &#34;</span>)
</span></span><span style="display:flex;"><span>    chat_history<span style="color:#f92672">.</span>add_user_message(query_term)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    search_result <span style="color:#f92672">=</span> <span style="color:#66d9ef">await</span> memory<span style="color:#f92672">.</span>search(collection_name, query_term) <span style="color:#75715e"># vector search</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    completions_result <span style="color:#f92672">=</span> <span style="color:#66d9ef">await</span> kernel<span style="color:#f92672">.</span>invoke(
</span></span><span style="display:flex;"><span>        chat_history_function, KernelArguments(query_term<span style="color:#f92672">=</span>query_term, db_record<span style="color:#f92672">=</span>search_result[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>additional_metadata)
</span></span><span style="display:flex;"><span>    ) 
</span></span><span style="display:flex;"><span>    chat_history<span style="color:#f92672">.</span>add_assistant_message(str(completions_result))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Question:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">{</span>query_term<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Response:&#34;</span>)
</span></span><span style="display:flex;"><span>    print(str(completions_result), end<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&#34;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>    time<span style="color:#f92672">.</span>sleep(<span style="color:#ae81ff">5</span>)
</span></span></code></pre></div>

        </div>
        <div class="post-reward">
            <div style="padding: 0 0 0 0; margin: 0 0 0 0; width: 100%; font-size:16px; text-align: center;">
                <div id="QR" style="opacity: 0;">
                    <div id="wechat" style="display: inline-block">
                        <a class="fancybox" rel="group">
                            <img id="wechat_qr" src="https://Aliga123.github.io/img/wechat_pay.jpg" alt="wechat_pay"></a>
                        <p>微信</p>
                    </div>
                    <div id="alipay" style="display: inline-block">
                        <a class="fancybox" rel="group">
                            <img id="alipay_qr" src="https://Aliga123.github.io/img/alipay.jpg" alt="alipay"></a>
                        <p>支付宝</p>
                    </div>
                </div>
                <button id="rewardButton"
                        onclick="
                    var qr = document.getElementById('QR');
                    if (qr.style.opacity === '0') {
                        qr.style.opacity='1';
                    } else {
                        qr.style.opacity='0'
                    }"
                >
                    <span>🧧 鼓励</span>
                </button>
            </div>
        </div>

        <footer class="post-footer">
            
<nav class="paginav">
  <a class="prev" href="https://Aliga123.github.io/posts/ai-llm/rag/">
    <span class="title">« 上一页</span>
    <br>
    <span>RAG</span>
  </a>
  <a class="next" href="https://Aliga123.github.io/posts/ai-llm/%E4%BD%BF%E7%94%A8.env%E6%96%87%E4%BB%B6%E4%BF%9D%E5%AD%98key%E5%8F%98%E9%87%8F/">
    <span class="title">下一页 »</span>
    <br>
    <span>使用.env文件保存key变量</span>
  </a>
</nav>

        </footer>
    </div>

<style>
    .comments_details summary::marker {
        font-size: 20px;
        content: '👉展开评论';
        color: var(--content);
    }
    .comments_details[open] summary::marker{
        font-size: 20px;
        content: '👇关闭评论';
        color: var(--content);
    }
</style>


<div>
    <details class="comments_details">
        <summary style="cursor: pointer; margin: 50px 0 20px 0;width: 130px;">
            <span style="font-size: 20px;color: var(--content);">...</span>
        </summary>
        <div id="tcomment"></div>
    </details>
    <script src="https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js">
    </script>
    <script>
        twikoo.init({
            envId:  null ,
        el: "#tcomment",
            lang: 'zh-CN',
            region:  null ,
        path: window.TWIKOO_MAGIC_PATH||window.location.pathname,
        })
    </script>
</div>
</article>
</main>

<footer class="footer">
    <span>
        Copyright
        &copy;
        2020-2024
        <a href="https://Aliga123.github.io/" style="color:#939393;">aliga&#39;s Blog</a>
        All Rights Reserved
    </span>
    <a href="https://beian.miit.gov.cn/" target="_blank" style="color:#939393;">填写自己的备案号</a>&nbsp;
    <span>
        <a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=null"
           style="display:inline-block;text-decoration:none;height:20px;color:#939393;">
            <img src="%e5%a1%ab%e8%87%aa%e5%b7%b1%e7%9a%84%e5%85%ac%e5%ae%89%e5%9b%be%e6%a0%87%e9%93%be%e6%8e%a5" style="float:left;margin: 0px 5px 0px 0px;"/>
            填自己的公网安备
        </a>
    </span>
    <span id="busuanzi_container">
        <span class="fa fa-user"></span> <span id="busuanzi_value_site_uv"></span>
        <span class="fa fa-eye"></span> <span id="busuanzi_value_site_pv"></span>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <span class="topInner">
        <svg class="topSvg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z"/>
        </svg>
        <span id="read_progress"></span>
    </span>
</a>

<script>
    document.addEventListener('scroll', function (e) {
        const readProgress = document.getElementById("read_progress");
        const scrollHeight = document.documentElement.scrollHeight;
        const clientHeight = document.documentElement.clientHeight;
        const scrollTop = document.documentElement.scrollTop || document.body.scrollTop;
        readProgress.innerText = ((scrollTop / (scrollHeight - clientHeight)).toFixed(2) * 100).toFixed(0);
    })
</script>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });
</script>
<script>
    let mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 200 || document.documentElement.scrollTop > 200) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };
</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        (function() {
            document.cookie = "change-themes" + "="+ escape ("false");
        })()

        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    });
</script>

<script>
    document.body.addEventListener('copy', function (e) {
        if (window.getSelection().toString() && window.getSelection().toString().length > 50) {
            let clipboardData = e.clipboardData || window.clipboardData;
            if (clipboardData) {
                e.preventDefault();
                let htmlData = window.getSelection().toString() +
                    '\r\n\n————————————————\r\n' +
                    '版权声明：本文为「'+"aliga's Blog"+'」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。' +
                '\r\n原文链接：' + location.href;
                let textData = window.getSelection().toString() +
                    '\r\n\n————————————————\r\n' +
                    '版权声明：本文为「'+"aliga's Blog"+'」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。' +
                '\r\n原文链接：' + location.href;
                clipboardData.setData('text/html', htmlData);
                clipboardData.setData('text/plain', textData);
            }
        }
    });
</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;
        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = '复制';

        function copyingDone() {
            copybutton.innerText = '已复制！';
            setTimeout(() => {
                copybutton.innerText = '复制';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                let text = codeblock.textContent +
                    '\r\n————————————————\r\n' +
                    '版权声明：本文为「'+"aliga's Blog"+'」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。' +
                '\r\n原文链接：' + location.href;
                navigator.clipboard.writeText(text);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) {}
            selection.removeRange(range);
        });

        let language = codeblock.className.replaceAll("language-", "")
        let macTool = document.createElement("div")
        let macTool1 = document.createElement("div")
        let macTool2 = document.createElement("div")
        let macTool3 = document.createElement("div")
        let languageType = document.createElement("div")
        languageType.innerText = language
        macTool.setAttribute('class', 'mac-tool')
        macTool1.setAttribute('class', 'mac bb1')
        macTool2.setAttribute('class', 'mac bb2')
        macTool3.setAttribute('class', 'mac bb3')
        languageType.setAttribute('class', 'language-type')
        macTool.appendChild(macTool1)
        macTool.appendChild(macTool2)
        macTool.appendChild(macTool3)
        macTool.appendChild(languageType)

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
            container.appendChild(macTool)
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        }
    });
</script>
</body>

</html>
