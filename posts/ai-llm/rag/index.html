<!DOCTYPE html>
<html lang="zh" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>RAG | aliga&#39;s Blog</title>
<meta name="keywords" content="">
<meta name="description" content="elasticsearchï¼šå‚¨å­˜ä¸æ£€ç´¢ Elasticsearchï¼ˆç®€ç§°ESï¼‰æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼ã€RESTful é£æ ¼çš„æœç´¢å’Œæ•°æ®åˆ†æå¼•æ“ï¼Œèƒ½å¤Ÿè§£å†³ä¸æ–­æ¶Œç°å‡ºçš„å„ç§ç”¨ä¾‹ã€‚ä½œä¸º Elastic Stack çš„æ ¸å¿ƒï¼ŒElasticsearch ä¼šé›†ä¸­å­˜å‚¨æ‚¨çš„æ•°æ®ï¼Œè®©æ‚¨é£å¿«å®Œæˆæœç´¢ï¼Œå¾®è°ƒç›¸å…³æ€§ï¼Œè¿›è¡Œå¼ºå¤§çš„åˆ†æï¼Œå¹¶è½»æ¾ç¼©æ”¾è§„">
<meta name="author" content="aliga">
<link rel="canonical" href="https://Aliga123.github.io/posts/ai-llm/rag/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.js" onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://Aliga123.github.io/img/Q.gif">
<link rel="icon" type="image/png" sizes="16x16" href="https://Aliga123.github.io/img/Q.gif">
<link rel="icon" type="image/png" sizes="32x32" href="https://Aliga123.github.io/img/Q.gif">
<link rel="apple-touch-icon" href="https://Aliga123.github.io/img/Q.gif">
<link rel="mask-icon" href="https://Aliga123.github.io/img/Q.gif">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="zh" href="https://Aliga123.github.io/posts/ai-llm/rag/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script defer src="https://unpkg.com/mermaid@8.8.1/dist/mermaid.min.js"></script>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css">
<script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.3/dist/jquery.min.js"></script>



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = ""; 
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

  

<meta property="og:title" content="RAG" />
<meta property="og:description" content="elasticsearchï¼šå‚¨å­˜ä¸æ£€ç´¢ Elasticsearchï¼ˆç®€ç§°ESï¼‰æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼ã€RESTful é£æ ¼çš„æœç´¢å’Œæ•°æ®åˆ†æå¼•æ“ï¼Œèƒ½å¤Ÿè§£å†³ä¸æ–­æ¶Œç°å‡ºçš„å„ç§ç”¨ä¾‹ã€‚ä½œä¸º Elastic Stack çš„æ ¸å¿ƒï¼ŒElasticsearch ä¼šé›†ä¸­å­˜å‚¨æ‚¨çš„æ•°æ®ï¼Œè®©æ‚¨é£å¿«å®Œæˆæœç´¢ï¼Œå¾®è°ƒç›¸å…³æ€§ï¼Œè¿›è¡Œå¼ºå¤§çš„åˆ†æï¼Œå¹¶è½»æ¾ç¼©æ”¾è§„" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://Aliga123.github.io/posts/ai-llm/rag/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-07-28T00:18:23+08:00" />
<meta property="article:modified_time" content="2024-07-28T00:18:23+08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="RAG"/>
<meta name="twitter:description" content="elasticsearchï¼šå‚¨å­˜ä¸æ£€ç´¢ Elasticsearchï¼ˆç®€ç§°ESï¼‰æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼ã€RESTful é£æ ¼çš„æœç´¢å’Œæ•°æ®åˆ†æå¼•æ“ï¼Œèƒ½å¤Ÿè§£å†³ä¸æ–­æ¶Œç°å‡ºçš„å„ç§ç”¨ä¾‹ã€‚ä½œä¸º Elastic Stack çš„æ ¸å¿ƒï¼ŒElasticsearch ä¼šé›†ä¸­å­˜å‚¨æ‚¨çš„æ•°æ®ï¼Œè®©æ‚¨é£å¿«å®Œæˆæœç´¢ï¼Œå¾®è°ƒç›¸å…³æ€§ï¼Œè¿›è¡Œå¼ºå¤§çš„åˆ†æï¼Œå¹¶è½»æ¾ç¼©æ”¾è§„"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [

        {
          "@type": "ListItem",
          "position":  1 ,
          "name": "ğŸ“šæ–‡ç« ",
          "item": "https://Aliga123.github.io/posts/"
        },

        {
          "@type": "ListItem",
          "position":  2 ,
          "name": "ğŸ§± AIå¤§æ¨¡å‹åº”ç”¨å¼€å‘",
          "item": "https://Aliga123.github.io/posts/ai-llm/"
        }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "RAG",
      "item": "https://Aliga123.github.io/posts/ai-llm/rag/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "RAG",
  "name": "RAG",
  "description": "elasticsearchï¼šå‚¨å­˜ä¸æ£€ç´¢ Elasticsearchï¼ˆç®€ç§°ESï¼‰æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼ã€RESTful é£æ ¼çš„æœç´¢å’Œæ•°æ®åˆ†æå¼•æ“ï¼Œèƒ½å¤Ÿè§£å†³ä¸æ–­æ¶Œç°å‡ºçš„å„ç§ç”¨ä¾‹ã€‚ä½œä¸º Elastic Stack çš„æ ¸å¿ƒï¼ŒElasticsearch ä¼šé›†ä¸­å­˜å‚¨æ‚¨çš„æ•°æ®ï¼Œè®©æ‚¨é£å¿«å®Œæˆæœç´¢ï¼Œå¾®è°ƒç›¸å…³æ€§ï¼Œè¿›è¡Œå¼ºå¤§çš„åˆ†æï¼Œå¹¶è½»æ¾ç¼©æ”¾è§„",
  "keywords": [
    ""
  ],
  "articleBody": "elasticsearchï¼šå‚¨å­˜ä¸æ£€ç´¢ Elasticsearchï¼ˆç®€ç§°ESï¼‰æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼ã€RESTful é£æ ¼çš„æœç´¢å’Œæ•°æ®åˆ†æå¼•æ“ï¼Œèƒ½å¤Ÿè§£å†³ä¸æ–­æ¶Œç°å‡ºçš„å„ç§ç”¨ä¾‹ã€‚ä½œä¸º Elastic Stack çš„æ ¸å¿ƒï¼ŒElasticsearch ä¼šé›†ä¸­å­˜å‚¨æ‚¨çš„æ•°æ®ï¼Œè®©æ‚¨é£å¿«å®Œæˆæœç´¢ï¼Œå¾®è°ƒç›¸å…³æ€§ï¼Œè¿›è¡Œå¼ºå¤§çš„åˆ†æï¼Œå¹¶è½»æ¾ç¼©æ”¾è§„æ¨¡ã€‚\nå®‰è£…ä¸æœ¬åœ°åœ°å€ä½¿ç”¨ï¼Œå‚è€ƒblogï¼š\nå®‰è£…JDKã€é…ç½®jdkç¯å¢ƒå˜é‡ ä¸‹è½½å®‰è£…Elasticsearch ï¼Œé…ç½®ESç¯å¢ƒå˜é‡ æ‰“å¼€å®‰è£…ç›®å½•D:\\Toos\\elasticsearch-8.14.3\\binï¼ŒåŒå‡»elasticsearch.batæ–‡ä»¶ ä½¿ç”¨Googleæµè§ˆå™¨æ‰“å¼€http://localhost:9200ï¼Œæ£€æŸ¥æ˜¯å¦å¯åŠ¨æˆåŠŸ RAGç³»ç»Ÿçš„åŸºæœ¬æ­å»ºæµç¨‹ 1.æ–‡æ¡£çš„åŠ è½½ä¸åˆ‡å‰²\n# å®‰è£… pdf è§£æåº“ !pip install pdfminer.six from pdfminer.high_level import extract_pages from pdfminer.layout import LTTextContainer def extract_text_from_pdf(filename, page_numbers=None, min_line_length=1): '''ä» PDF æ–‡ä»¶ä¸­ï¼ˆæŒ‰æŒ‡å®šé¡µç ï¼‰æå–æ–‡å­—''' paragraphs = [] buffer = '' full_text = '' # æå–å…¨éƒ¨æ–‡æœ¬ for i, page_layout in enumerate(extract_pages(filename)): # å¦‚æœæŒ‡å®šäº†é¡µç èŒƒå›´ï¼Œè·³è¿‡èŒƒå›´å¤–çš„é¡µ if page_numbers is not None and i not in page_numbers: continue for element in page_layout: if isinstance(element, LTTextContainer): full_text += element.get_text() + '\\n' # æŒ‰ç©ºè¡Œåˆ†éš”ï¼Œå°†æ–‡æœ¬é‡æ–°ç»„ç»‡æˆæ®µè½ lines = full_text.split('\\n') for text in lines: if len(text) \u003e= min_line_length: buffer += (' '+text) if not text.endswith('-') else text.strip('-') elif buffer: paragraphs.append(buffer) buffer = '' if buffer: paragraphs.append(buffer) return paragraphs paragraphs = extract_text_from_pdf(\"llama2.pdf\", page_numbers=[ 2, 3], min_line_length=10) for para in paragraphs[:5]: print(para) 2.æ£€ç´¢å¼•æ“(ESå…³é”®è¯æ£€ç´¢)\n# å®‰è£… ES å®¢æˆ·ç«¯ !pip install elasticsearch7 # å®‰è£…NLTKï¼ˆæ–‡æœ¬å¤„ç†æ–¹æ³•åº“ï¼‰ !pip install nltk from elasticsearch7 import Elasticsearch, helpers from nltk.stem import PorterStemmer from nltk.tokenize import word_tokenize from nltk.corpus import stopwords import nltk import re import warnings warnings.simplefilter(\"ignore\") # å±è”½ ES çš„ä¸€äº›Warnings nltk.download('punkt') # è‹±æ–‡åˆ‡è¯ã€è¯æ ¹ã€åˆ‡å¥ç­‰æ–¹æ³• nltk.download('stopwords') # è‹±æ–‡åœç”¨è¯åº“ æå–æ–‡æœ¬å…³é”®è¯\ndef to_keywords(input_string): '''ï¼ˆè‹±æ–‡ï¼‰æ–‡æœ¬åªä¿ç•™å…³é”®å­—''' # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢æ‰€æœ‰éå­—æ¯æ•°å­—çš„å­—ç¬¦ä¸ºç©ºæ ¼ no_symbols = re.sub(r'[^a-zA-Z0-9\\s]', ' ', input_string) word_tokens = word_tokenize(no_symbols) stop_words = set(stopwords.words('english')) ps = PorterStemmer() # å»åœç”¨è¯ï¼Œå–è¯æ ¹ filtered_sentence = [ps.stem(w) for w in word_tokens if not w.lower() in stop_words] return ' '.join(filtered_sentence) å°†æ–‡æœ¬çŒå…¥æ£€ç´¢å¼•æ“\n# 1. åˆ›å»ºElasticsearchè¿æ¥ es = Elasticsearch( hosts=['http://localhost:9200'] # è¿æ¥åˆ°æœ¬åœ° ) ''' es = Elasticsearch( hosts=['http://117.50.198.53:9200'], # æœåŠ¡åœ°å€ä¸ç«¯å£ http_auth=(\"elastic\", \"FKaB1Jpz0Rlw0l6G\"), # ç”¨æˆ·åï¼Œå¯†ç  ) ''' # 2. å®šä¹‰ç´¢å¼•åç§° index_name = \"string_index_0924\" # 3. å¦‚æœç´¢å¼•å·²å­˜åœ¨ï¼Œåˆ é™¤å®ƒï¼ˆä»…ä¾›æ¼”ç¤ºï¼Œå®é™…åº”ç”¨æ—¶ä¸éœ€è¦è¿™æ­¥ï¼‰ if es.indices.exists(index=index_name): es.indices.delete(index=index_name) # 4. åˆ›å»ºç´¢å¼• es.indices.create(index=index_name) # 5. çŒåº“æŒ‡ä»¤ actions = [ { \"_index\": index_name, \"_source\": { \"keywords\": to_keywords(para), \"text\": para } } for para in paragraphs ] # 6. æ–‡æœ¬çŒåº“ helpers.bulk(es, actions) å®ç°å…³é”®å­—æ£€ç´¢\ndef search(query_string, top_n=3): # ES çš„æŸ¥è¯¢è¯­è¨€ search_query = { \"match\": { \"keywords\": to_keywords(query_string) } } res = es.search(index=index_name, query=search_query, size=top_n) return [hit[\"_source\"][\"text\"] for hit in res[\"hits\"][\"hits\"]] results = search(\"how many parameters does llama 2 have?\", 2) for r in results: print(r+\"\\n\") 3.LLMå°è£…\nfrom openai import OpenAI import os # åŠ è½½ç¯å¢ƒå˜é‡ from dotenv import load_dotenv, find_dotenv _ = load_dotenv(find_dotenv()) # è¯»å–æœ¬åœ° .env æ–‡ä»¶ï¼Œé‡Œé¢å®šä¹‰äº† OPENAI_API_KEY client = OpenAI( api_key=os.getenv(\"OPENAI_API_KEY\"), base_url=os.getenv(\"OPENAI_BASE_URL\") ) def get_completion(prompt, model=\"gpt-3.5-turbo-1106\"): '''å°è£… openai æ¥å£''' messages = [{\"role\": \"user\", \"content\": prompt}] response = client.chat.completions.create( model=model, messages=messages, temperature=0, # æ¨¡å‹è¾“å‡ºçš„éšæœºæ€§ï¼Œ0 è¡¨ç¤ºéšæœºæ€§æœ€å° ) return response.choices[0].message.content 4.Promptæ¨¡æ¿\nprompt_template = \"\"\" ä½ æ˜¯ä¸€ä¸ªé—®ç­”æœºå™¨äººã€‚ ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ä¸‹è¿°ç»™å®šçš„å·²çŸ¥ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚ ç¡®ä¿ä½ çš„å›å¤å®Œå…¨ä¾æ®ä¸‹è¿°å·²çŸ¥ä¿¡æ¯ã€‚ä¸è¦ç¼–é€ ç­”æ¡ˆã€‚ å¦‚æœä¸‹è¿°å·²çŸ¥ä¿¡æ¯ä¸è¶³ä»¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œè¯·ç›´æ¥å›å¤\"æˆ‘æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜\"ã€‚ å·²çŸ¥ä¿¡æ¯: __INFO__ ç”¨æˆ·é—®ï¼š __QUERY__ è¯·ç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·é—®é¢˜ã€‚ \"\"\" def build_prompt(prompt_template, **kwargs): '''å°† Prompt æ¨¡æ¿èµ‹å€¼''' prompt = prompt_template for k, v in kwargs.items(): if isinstance(v, str): val = v elif isinstance(v, list) and all(isinstance(elem, str) for elem in v): val = '\\n'.join(v) else: val = str(v) prompt = prompt.replace(f\"__{k.upper()}__\", val) return prompt 5.æé—®å›ç­”\nuser_query = \"how many parameters does llama 2 have?\" # 1. æ£€ç´¢ search_results = search(user_query, 2) # 2. æ„å»º Prompt prompt = build_prompt(prompt_template, info=search_results, query=user_query) print(\"===Prompt===\") print(prompt) # 3. è°ƒç”¨ LLM response = get_completion(prompt) # response = get_completion_ernie(prompt) print(\"===å›å¤===\") print(response) å‘é‡è·ç¦» å…³é”®å­—æ£€ç´¢çš„å±€é™æ€§ï¼šåŒä¸€ä¸ªè¯­ä¹‰ï¼Œç”¨è¯ä¸åŒï¼Œå¯èƒ½å¯¼è‡´æ£€ç´¢ä¸åˆ°æœ‰æ•ˆçš„ç»“æœã€‚\nå°†æ–‡æœ¬è½¬æ¢æˆå‘é‡ï¼Œå†å‘é‡æ£€ç´¢é€šè¿‡è®¡ç®—å‘é‡é—´ç›¸ä¼¼åº¦ï¼Œä»è€Œæ‰¾å‡ºç›¸å…³èµ„æ–™ã€‚\nè®¡ç®—å‘é‡è·ç¦»\nimport numpy as np from numpy import dot from numpy.linalg import norm def cos_sim(a, b): '''ä½™å¼¦è·ç¦» -- è¶Šå¤§è¶Šç›¸ä¼¼''' return dot(a, b)/(norm(a)*norm(b)) def l2(a, b): '''æ¬§å¼è·ç¦» -- è¶Šå°è¶Šç›¸ä¼¼''' x = np.asarray(a)-np.asarray(b) return norm(x) å‘é‡ç¼–ç  1.ä½¿ç”¨APIè¿›è¡Œå‘é‡ç¼–ç ï¼ˆæ”¶è´¹ï¼‰\nopenAI def get_embeddings(texts, model=\"text-embedding-ada-002\"): '''å°è£… OpenAI çš„ Embedding æ¨¡å‹æ¥å£''' data = client.embeddings.create(input=texts, model=model).data return [x.embedding for x in data] test_query = [\"æµ‹è¯•æ–‡æœ¬\"] vec = get_embeddings(test_query)[0] print(vec[:10]) query = \"å›½é™…äº‰ç«¯\" # ä¸”èƒ½æ”¯æŒè·¨è¯­è¨€ # query = \"global conflicts\" documents = [ \"è”åˆå›½å°±è‹ä¸¹è¾¾å°”å¯Œå°”åœ°åŒºå¤§è§„æ¨¡æš´åŠ›äº‹ä»¶å‘å‡ºè­¦å‘Š\", \"åœŸè€³å…¶ã€èŠ¬å…°ã€ç‘å…¸ä¸åŒ—çº¦ä»£è¡¨å°†ç»§ç»­å°±ç‘å…¸â€œå…¥çº¦â€é—®é¢˜è¿›è¡Œè°ˆåˆ¤\", \"æ—¥æœ¬å²é˜œå¸‚é™†ä¸Šè‡ªå«é˜Ÿå°„å‡»åœºå†…å‘ç”Ÿæªå‡»äº‹ä»¶ 3äººå—ä¼¤\", \"å›½å®¶æ¸¸æ³³ä¸­å¿ƒï¼ˆæ°´ç«‹æ–¹ï¼‰ï¼šæ¢å¤æ¸¸æ³³ã€å¬‰æ°´ä¹å›­ç­‰æ°´ä¸Šé¡¹ç›®è¿è¥\", \"æˆ‘å›½é¦–æ¬¡åœ¨ç©ºé—´ç«™å¼€å±•èˆ±å¤–è¾å°„ç”Ÿç‰©å­¦æš´éœ²å®éªŒ\", ] query_vec = get_embeddings([query])[0] doc_vecs = get_embeddings(documents) print(\"Cosine distance:\") print(cos_sim(query_vec, query_vec)) for vec in doc_vecs: print(cos_sim(query_vec, vec)) print(\"\\nEuclidean distance:\") print(l2(query_vec, query_vec)) for vec in doc_vecs: print(l2(query_vec, vec)) æ–‡å¿ƒåƒå¸†ï¼ˆBGE Embeddingï¼‰ï¼Œå› ä¸ºæ”¶è´¹æˆ‘è¿˜æ²¡æœ‰å°è¯•ã€‚ import json import requests import os # é€šè¿‡é‰´æƒæ¥å£è·å– access token def get_access_token(): \"\"\" ä½¿ç”¨ AKï¼ŒSK ç”Ÿæˆé‰´æƒç­¾åï¼ˆAccess Tokenï¼‰ :return: access_tokenï¼Œæˆ–æ˜¯None(å¦‚æœé”™è¯¯) \"\"\" url = \"https://aip.baidubce.com/oauth/2.0/token\" params = { \"grant_type\": \"client_credentials\", \"client_id\": os.getenv('ERNIE_CLIENT_ID'), \"client_secret\": os.getenv('ERNIE_CLIENT_SECRET') } return str(requests.post(url, params=params).json().get(\"access_token\")) # è°ƒç”¨æ–‡å¿ƒåƒå¸† è°ƒç”¨ BGE Embedding æ¥å£ def get_embeddings_bge(prompts): url = \"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/embeddings/bge_large_en?access_token=\" + get_access_token() payload = json.dumps({ \"input\": prompts }) headers = {'Content-Type': 'application/json'} response = requests.request( \"POST\", url, headers=headers, data=payload).json() data = response[\"data\"] return [x[\"embedding\"] for x in data] 2.æœ¬åœ°æ¨¡å‹è¿›è¡Œå‘é‡ç¼–ç \nfrom sentence_transformers import SentenceTransformer model = SentenceTransformer('BAAI/bge-large-zh-v1.5') query = \"å›½é™…äº‰ç«¯\" documents = [ \"è”åˆå›½å°±è‹ä¸¹è¾¾å°”å¯Œå°”åœ°åŒºå¤§è§„æ¨¡æš´åŠ›äº‹ä»¶å‘å‡ºè­¦å‘Š\", \"åœŸè€³å…¶ã€èŠ¬å…°ã€ç‘å…¸ä¸åŒ—çº¦ä»£è¡¨å°†ç»§ç»­å°±ç‘å…¸â€œå…¥çº¦â€é—®é¢˜è¿›è¡Œè°ˆåˆ¤\", \"æ—¥æœ¬å²é˜œå¸‚é™†ä¸Šè‡ªå«é˜Ÿå°„å‡»åœºå†…å‘ç”Ÿæªå‡»äº‹ä»¶ 3äººå—ä¼¤\", \"å›½å®¶æ¸¸æ³³ä¸­å¿ƒï¼ˆæ°´ç«‹æ–¹ï¼‰ï¼šæ¢å¤æ¸¸æ³³ã€å¬‰æ°´ä¹å›­ç­‰æ°´ä¸Šé¡¹ç›®è¿è¥\", \"æˆ‘å›½é¦–æ¬¡åœ¨ç©ºé—´ç«™å¼€å±•èˆ±å¤–è¾å°„ç”Ÿç‰©å­¦æš´éœ²å®éªŒ\", ] query_vec = model.encode(query, normalize_embeddings=True) doc_vecs = [ model.encode(doc, normalize_embeddings=True) for doc in documents ] print(\"Cosine distance:\") # è¯¥æ¨¡å‹ä½™å¼¦è·ç¦»è¶Šå¤§è¶Šç›¸ä¼¼ print(cos_sim(query_vec, query_vec)) for vec in doc_vecs: print(cos_sim(query_vec, vec)) åˆ’é‡ç‚¹ï¼š\nä¸æ˜¯æ¯ä¸ª Embedding æ¨¡å‹éƒ½å¯¹ä½™å¼¦è·ç¦»å’Œæ¬§æ°è·ç¦»åŒæ—¶æœ‰æ•ˆ å“ªç§ç›¸ä¼¼åº¦è®¡ç®—æœ‰æ•ˆè¦é˜…è¯»æ¨¡å‹çš„è¯´æ˜ï¼ˆé€šå¸¸éƒ½æ”¯æŒä½™å¼¦è·ç¦»è®¡ç®—ï¼‰ æ›´å¤šæœ¬åœ°æ¨¡å‹ï¼šhttps://github.com/FlagOpen/FlagEmbedding\nå‘é‡æ•°æ®åº“ ä»ä¸Šè¿°å¯ä»¥çŸ¥é“ï¼Œé€šè¿‡è®¡ç®—å‘é‡è·ç¦»å®ç°å¥å­å’Œå…¶ä»–å¥å­çš„ç›¸ä¼¼åº¦ã€‚\nç°åœ¨æˆ‘ä»¬éœ€è¦å°†æˆ‘ä»¬çš„å¤–éƒ¨çŸ¥è¯†é€šè¿‡embeddingæ¨¡å‹è½¬æ¢æˆå‘é‡ï¼Œä¿å­˜åœ¨å‘é‡æ•°æ®åº“ä¸­ï¼Œä½œä¸ºå‘é‡æ£€ç´¢è®¾è®¡çš„ä¸­é—´ä»¶ã€‚\n!pip install chromadb # ä¸ºäº†æ¼”ç¤ºæ–¹ä¾¿ï¼Œæˆ‘ä»¬åªå–ä¸¤é¡µï¼ˆç¬¬ä¸€ç« ï¼‰ paragraphs = extract_text_from_pdf(\"llama2.pdf\", page_numbers=[ 2, 3], min_line_length=10) import chromadb from chromadb.config import Settings class MyVectorDBConnector: def __init__(self, collection_name, embedding_fn): chroma_client = chromadb.Client(Settings(allow_reset=True)) # ä¸ºäº†æ¼”ç¤ºï¼Œå®é™…ä¸éœ€è¦æ¯æ¬¡ reset() chroma_client.reset() # åˆ›å»ºä¸€ä¸ª collection self.collection = chroma_client.get_or_create_collection(name=\"demo\") self.embedding_fn = embedding_fn def add_documents(self, documents, metadata={}): '''å‘ collection ä¸­æ·»åŠ æ–‡æ¡£ä¸å‘é‡''' self.collection.add( embeddings=self.embedding_fn(documents), # æ¯ä¸ªæ–‡æ¡£çš„å‘é‡ documents=documents, # æ–‡æ¡£çš„åŸæ–‡ ids=[f\"id{i}\" for i in range(len(documents))] # æ¯ä¸ªæ–‡æ¡£çš„ id ) def search(self, query, top_n): '''æ£€ç´¢å‘é‡æ•°æ®åº“''' results = self.collection.query( query_embeddings=self.embedding_fn([query]), n_results=top_n ) return results æ³¨æ„ï¼šä¸‹é¢ä»£ç ç¨‹åºæ‰§è¡Œå´©æºƒäº†ï¼Œæµ‹è¯•äº†å’Œæ–‡æœ¬é•¿åº¦æ²¡æœ‰å…³ç³»ï¼Œå¾ˆæœ‰å¯èƒ½æ˜¯å†…å­˜æœ‰å…³ï¼Œæ¢äº†autodläº‘æœåŠ¡çš„å¤§å†…å­˜æœºå­å¯è¡Œã€‚\n# åˆ›å»ºä¸€ä¸ªå‘é‡æ•°æ®åº“å¯¹è±¡ vector_db = MyVectorDBConnector(\"demo\", get_embeddings) # å‘å‘é‡æ•°æ®åº“ä¸­æ·»åŠ æ–‡æ¡£ vector_db.add_documents(paragraphs) user_query = \"Llama 2æœ‰å¤šå°‘å‚æ•°\" results = vector_db.search(user_query, 2) for para in results['documents'][0]: print(para+\"\\n\") ä¸»æµå‘é‡æ•°æ®åº“åŠŸèƒ½å¯¹æ¯”\nFAISS: Meta å¼€æºçš„å‘é‡æ£€ç´¢å¼•æ“ https://github.com/facebookresearch/faiss Pinecone: å•†ç”¨å‘é‡æ•°æ®åº“ï¼Œåªæœ‰äº‘æœåŠ¡ https://www.pinecone.io/ Milvus: å¼€æºå‘é‡æ•°æ®åº“ï¼ŒåŒæ—¶æœ‰äº‘æœåŠ¡ https://milvus.io/ Weaviate: å¼€æºå‘é‡æ•°æ®åº“ï¼ŒåŒæ—¶æœ‰äº‘æœåŠ¡ https://weaviate.io/ Qdrant: å¼€æºå‘é‡æ•°æ®åº“ï¼ŒåŒæ—¶æœ‰äº‘æœåŠ¡ https://qdrant.tech/ PGVector: Postgres çš„å¼€æºå‘é‡æ£€ç´¢å¼•æ“ https://github.com/pgvector/pgvector RediSearch: Redis çš„å¼€æºå‘é‡æ£€ç´¢å¼•æ“ https://github.com/RediSearch/RediSearch ElasticSearch ä¹Ÿæ”¯æŒå‘é‡æ£€ç´¢ https://www.elastic.co/enterprise-search/vector-search æ–‡æœ¬åˆ†å‰²çš„ç²’åº¦ ç¼ºé™·ï¼š\nç²’åº¦å¤ªå¤§å¯èƒ½å¯¼è‡´æ£€ç´¢ä¸ç²¾å‡†ï¼Œç²’åº¦å¤ªå°å¯èƒ½å¯¼è‡´ä¿¡æ¯ä¸å…¨é¢ é—®é¢˜çš„ç­”æ¡ˆå¯èƒ½è·¨è¶Šä¸¤ä¸ªç‰‡æ®µ æ”¹è¿›: æŒ‰ä¸€å®šç²’åº¦ï¼Œéƒ¨åˆ†é‡å å¼çš„åˆ‡å‰²æ–‡æœ¬ï¼Œä½¿ä¸Šä¸‹æ–‡æ›´å®Œæ•´\nfrom nltk.tokenize import sent_tokenize import json def split_text(paragraphs, chunk_size=300, overlap_size=100): '''æŒ‰æŒ‡å®š chunk_size å’Œ overlap_size äº¤å å‰²æ–‡æœ¬''' sentences = [s.strip() for p in paragraphs for s in sent_tokenize(p)] chunks = [] i = 0 while i \u003c len(sentences): chunk = sentences[i] overlap = '' prev_len = 0 prev = i - 1 # å‘å‰è®¡ç®—é‡å éƒ¨åˆ† while prev \u003e= 0 and len(sentences[prev])+len(overlap) \u003c= overlap_size: overlap = sentences[prev] + ' ' + overlap prev -= 1 chunk = overlap+chunk next = i + 1 # å‘åè®¡ç®—å½“å‰chunk while next \u003c len(sentences) and len(sentences[next])+len(chunk) \u003c= chunk_size: chunk = chunk + ' ' + sentences[next] next += 1 chunks.append(chunk) i = next return chunks chunks = split_text(paragraphs, 300, 100) # åˆ›å»ºä¸€ä¸ªå‘é‡æ•°æ®åº“å¯¹è±¡ vector_db = MyVectorDBConnector(\"demo_text_split\", get_embeddings) # å‘å‘é‡æ•°æ®åº“ä¸­æ·»åŠ æ–‡æ¡£ vector_db.add_documents(chunks) æ£€ç´¢åæ’åº é—®é¢˜: æœ‰æ—¶ï¼Œæœ€åˆé€‚çš„ç­”æ¡ˆä¸ä¸€å®šæ’åœ¨æ£€ç´¢çš„æœ€å‰é¢\næ–¹æ¡ˆ:\næ£€ç´¢æ—¶è¿‡æ‹›å›ä¸€éƒ¨åˆ†æ–‡æœ¬ é€šè¿‡ä¸€ä¸ªæ’åºæ¨¡å‹å¯¹ query å’Œ document é‡æ–°æ‰“åˆ†æ’åº !pip install sentence_transformers from sentence_transformers import CrossEncoder model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', max_length=512) user_query = \"how safe is llama 2\" scores = model.predict([(user_query, doc) for doc in search_results['documents'][0]]) # æŒ‰å¾—åˆ†æ’åº sorted_list = sorted( zip(scores, search_results['documents'][0]), key=lambda x: x[0], reverse=True) for score, doc in sorted_list: print(f\"{score}\\t{doc}\\n\") äº‘å‘é‡æ•°æ®åº“ï¼ˆpineconeä¸ºä¾‹ï¼Œå®ƒæœ‰2Gå…è´¹ç©ºé—´ï¼‰ !pip install \"pinecone-client[grpc]\" !pip install langchain !pip install langchain-openai !pip install langchain-pinecone !pip install langchain_text_splitters 1.åˆå§‹åŒ–å®¢æˆ·ç«¯è¿æ¥\nfrom pinecone.grpc import PineconeGRPC as Pinecone from pinecone import ServerlessSpec # åˆå§‹åŒ–å®¢æˆ·ç«¯è¿æ¥ pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\")) 2.åˆ›å»ºæ— æœåŠ¡å™¨ç´¢å¼•\n# åˆ›å»ºæ— æœåŠ¡å™¨ç´¢å¼•ï¼Œè¿™é‡Œé€‰ç”¨openaiæ¨¡å‹ï¼Œæ‰€ä»¥è®¾ç½®ç´¢å¼•ç»´åº¦å’Œè·ç¦»åº¦é‡ä»¥åŒ¹é…text-embedding-3-smallç”¨äºåˆ›å»ºåµŒå…¥çš„ OpenAI æ¨¡å‹çš„ç»´åº¦å’Œè·ç¦»åº¦é‡ã€‚ index_name = \"arxiv-llama2-index\" if index_name not in pc.list_indexes().names(): pc.create_index( name=index_name, dimension=1536, # æ›´æ–°æ¨¡å‹é€‰æ‹© metric=\"cosine\", # æ›´æ–°æ¨¡å‹é€‰æ‹© spec=ServerlessSpec( cloud='aws', region='us-east-1' ) ) 3.è·å–çŸ¥è¯†æ•°æ®ã€‚è¿™é‡Œä»¥æ‰‹åŠ¨æ„å»ºçš„mdæ–‡æ¡£ä¸ºä¾‹ï¼Œæ ¹æ®ç»“æ„å¯¹å†…å®¹è¿›è¡Œåˆ†å—ã€‚å¦‚æœæ˜¯textæ–‡æœ¬ç±»å‹æ•°æ®å‚è€ƒpineconeæ–‡æ¡£ã€‚\nfrom langchain_text_splitters import MarkdownHeaderTextSplitter # Chunk the document based on h2 headers. markdown_document = \"## Introduction\\n\\nWelcome to the whimsical world of the WonderVector5000, an astonishing leap into the realms of imaginative technology. This extraordinary device, borne of creative fancy, promises to revolutionize absolutely nothing while dazzling you with its fantastical features. Whether you're a seasoned technophile or just someone looking for a bit of fun, the WonderVector5000 is sure to leave you amused and bemused in equal measure. Let's explore the incredible, albeit entirely fictitious, specifications, setup process, and troubleshooting tips for this marvel of modern nonsense.\\n\\n## Product overview\\n\\nThe WonderVector5000 is packed with features that defy logic and physics, each designed to sound impressive while maintaining a delightful air of absurdity:\\n\\n- Quantum Flibberflabber Engine: The heart of the WonderVector5000, this engine operates on principles of quantum flibberflabber, a phenomenon as mysterious as it is meaningless. It's said to harness the power of improbability to function seamlessly across multiple dimensions.\\n\\n- Hyperbolic Singularity Matrix: This component compresses infinite possibilities into a singular hyperbolic state, allowing the device to predict outcomes with 0% accuracy, ensuring every use is a new adventure.\\n\\n- Aetherial Flux Capacitor: Drawing energy from the fictional aether, this flux capacitor provides unlimited power by tapping into the boundless reserves of imaginary energy fields.\\n\\n- Multi-Dimensional Holo-Interface: Interact with the WonderVector5000 through its holographic interface that projects controls and information in three-and-a-half dimensions, creating a user experience that's simultaneously futuristic and perplexing.\\n\\n- Neural Fandango Synchronizer: This advanced feature connects directly to the user's brain waves, converting your deepest thoughts into tangible actionsâ€”albeit with results that are whimsically unpredictable.\\n\\n- Chrono-Distortion Field: Manipulate time itself with the WonderVector5000's chrono-distortion field, allowing you to experience moments before they occur or revisit them in a state of temporal flux.\\n\\n## Use cases\\n\\nWhile the WonderVector5000 is fundamentally a device of fiction and fun, let's imagine some scenarios where it could hypothetically be applied:\\n\\n- Time Travel Adventures: Use the Chrono-Distortion Field to visit key moments in history or glimpse into the future. While actual temporal manipulation is impossible, the mere idea sparks endless storytelling possibilities.\\n\\n- Interdimensional Gaming: Engage with the Multi-Dimensional Holo-Interface for immersive, out-of-this-world gaming experiences. Imagine games that adapt to your thoughts via the Neural Fandango Synchronizer, creating a unique and ever-changing environment.\\n\\n- Infinite Creativity: Harness the Hyperbolic Singularity Matrix for brainstorming sessions. By compressing infinite possibilities into hyperbolic states, it could theoretically help unlock unprecedented creative ideas.\\n\\n- Energy Experiments: Explore the concept of limitless power with the Aetherial Flux Capacitor. Though purely fictional, the notion of drawing energy from the aether could inspire innovative thinking in energy research.\\n\\n## Getting started\\n\\nSetting up your WonderVector5000 is both simple and absurdly intricate. Follow these steps to unleash the full potential of your new device:\\n\\n1. Unpack the Device: Remove the WonderVector5000 from its anti-gravitational packaging, ensuring to handle with care to avoid disturbing the delicate balance of its components.\\n\\n2. Initiate the Quantum Flibberflabber Engine: Locate the translucent lever marked â€œQFE Startâ€ and pull it gently. You should notice a slight shimmer in the air as the engine engages, indicating that quantum flibberflabber is in effect.\\n\\n3. Calibrate the Hyperbolic Singularity Matrix: Turn the dials labeled 'Infinity A' and 'Infinity B' until the matrix stabilizes. You'll know it's calibrated correctly when the display shows a single, stable â€œâˆâ€.\\n\\n4. Engage the Aetherial Flux Capacitor: Insert the EtherKey into the designated slot and turn it clockwise. A faint humming sound should confirm that the aetherial flux capacitor is active.\\n\\n5. Activate the Multi-Dimensional Holo-Interface: Press the button resembling a floating question mark to activate the holo-interface. The controls should materialize before your eyes, slightly out of phase with reality.\\n\\n6. Synchronize the Neural Fandango Synchronizer: Place the neural headband on your forehead and think of the word â€œWonderâ€. The device will sync with your thoughts, a process that should take just a few moments.\\n\\n7. Set the Chrono-Distortion Field: Use the temporal sliders to adjust the time settings. Recommended presets include â€œPastâ€, â€œPresentâ€, and â€œFutureâ€, though feel free to explore other, more abstract temporal states.\\n\\n## Troubleshooting\\n\\nEven a device as fantastically designed as the WonderVector5000 can encounter problems. Here are some common issues and their solutions:\\n\\n- Issue: The Quantum Flibberflabber Engine won't start.\\n\\n - Solution: Ensure the anti-gravitational packaging has been completely removed. Check for any residual shards of improbability that might be obstructing the engine.\\n\\n- Issue: The Hyperbolic Singularity Matrix displays â€œâˆâˆâ€.\\n\\n - Solution: This indicates a hyper-infinite loop. Reset the dials to zero and then adjust them slowly until the display shows a single, stable infinity symbol.\\n\\n- Issue: The Aetherial Flux Capacitor isn't engaging.\\n\\n - Solution: Verify that the EtherKey is properly inserted and genuine. Counterfeit EtherKeys can often cause malfunctions. Replace with an authenticated EtherKey if necessary.\\n\\n- Issue: The Multi-Dimensional Holo-Interface shows garbled projections.\\n\\n - Solution: Realign the temporal resonators by tapping the holographic screen three times in quick succession. This should stabilize the projections.\\n\\n- Issue: The Neural Fandango Synchronizer causes headaches.\\n\\n - Solution: Ensure the headband is properly positioned and not too tight. Relax and focus on simple, calming thoughts to ease the synchronization process.\\n\\n- Issue: The Chrono-Distortion Field is stuck in the past.\\n\\n - Solution: Increase the temporal flux by 5%. If this fails, perform a hard reset by holding down the â€œFutureâ€ slider for ten seconds.\" headers_to_split_on = [ (\"##\", \"Header 2\") ] markdown_splitter = MarkdownHeaderTextSplitter( headers_to_split_on=headers_to_split_on, strip_headers=False ) md_header_splits = markdown_splitter.split_text(markdown_document) print(md_header_splits[:1]) 4.åˆå§‹åŒ–embeddingæ¨¡å‹\nfrom langchain_openai import OpenAIEmbeddings # Initialize a LangChain embedding object. model_name = \"text-embedding-3-small\" embeddings = OpenAIEmbeddings( model=model_name, openai_api_key=os.environ.get(\"OPENAI_API_KEY\") ) 4.çŒåº“ã€‚åµŒå…¥æ¯ä¸ªå—å¹¶å°†åµŒå…¥å†…å®¹æ’å…¥åˆ°æ‚¨çš„ Pinecone ç´¢å¼•ä¸­ã€‚\nfrom langchain_pinecone import PineconeVectorStore import os import time #å®šä¹‰ä¸€ä¸ªå‘½åç©ºé—´ã€‚åœ¨ç´¢å¼•ä¸­ï¼Œå‘é‡å­˜å‚¨åœ¨å‘½åç©ºé—´ä¸­ï¼Œå¹¶ä¸”æ‰€æœ‰æ›´æ–°æ’å…¥ã€æŸ¥è¯¢å’Œå…¶ä»–æ•°æ®æ“ä½œå§‹ç»ˆä»¥ä¸€ä¸ªå‘½åç©ºé—´ä¸ºç›®æ ‡ã€‚ namespace = \"wondervector5000\" # Embed each chunk and upsert the embeddings into your Pinecone index. docsearch = PineconeVectorStore.from_documents( documents=md_header_splits, index_name=index_name, embedding=embeddings, namespace=namespace # åœ¨ç´¢å¼•ä¸­ï¼Œå‘é‡å­˜å‚¨åœ¨å‘½åç©ºé—´ä¸­ ) time.sleep(1) 5.ï¼ˆå¯é€‰ï¼‰æŸ¥è®°å½•ã€‚ä½¿ç”¨ Pinecone çš„listå’Œqueryæ“ä½œæŸ¥çœ‹å…¶ä¸­ä¸€æ¡è®°å½•\nindex = pc.Index(index_name) for ids in index.list(namespace=namespace): query = index.query( id=ids[0], namespace=namespace, top_k=1, include_values=True, include_metadata=True ) print(query) 6.ä½¿ç”¨LangChainåˆ›å»ºä¸€ä¸ªå¯¹è¯å¯¹è±¡\nfrom langchain.chains import RetrievalQA from langchain_openai import ChatOpenAI import os # åˆå§‹åŒ–ä¸€ä¸ªä»Pineconeæ£€ç´¢ä¿¡æ¯çš„LangChainå¯¹è±¡ knowledge = PineconeVectorStore.from_existing_index( index_name=index_name, namespace=namespace, embedding=embeddings ) # åˆå§‹åŒ–ä¸€ä¸ªä¸LLMèŠå¤©çš„LangChainå¯¹è±¡ # without knowledge from Pinecone. llm = ChatOpenAI( openai_api_key=os.environ.get(\"OPENAI_API_KEY\"), model_name=\"gpt-3.5-turbo-1106\", temperature=0.0 ) qa = RetrievalQA.from_chain_type( llm=llm, chain_type=\"stuff\", retriever=knowledge.as_retriever() ) 7.å¯¹è¯ä½¿ç”¨ã€‚\n# Define a few questions about the WonderVector5000. query1 = \"\"\"What are the first 3 steps for getting started with the WonderVector5000?\"\"\" query2 = \"\"\"The Neural Fandango Synchronizer is giving me a headache. What do I do?\"\"\" # Send each query to the LLM twice, first with relevant knowledge from Pincone # and then without any additional knowledge. print(\"Query 1\\n\") print(\"Chat with knowledge:\") print(qa.invoke(query1).get(\"result\")) print(\"\\nChat without knowledge:\") print(llm.invoke(query1).content) print(\"\\nQuery 2\\n\") print(\"Chat with knowledge:\") print(qa.invoke(query2).get(\"result\")) print(\"\\nChat without knowledge:\") print(llm.invoke(query2).content) 8.ï¼ˆå¯é€‰ï¼‰å¦‚æœä¸éœ€è¦å¯ä»¥æ¸…ç†\n# æ¸…ç† pc.delete_index(index_name) ",
  "wordCount" : "4934",
  "inLanguage": "zh",
  "datePublished": "2024-07-28T00:18:23+08:00",
  "dateModified": "2024-07-28T00:18:23+08:00",
  "author":[{
    "@type": "Person",
    "name": "aliga"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://Aliga123.github.io/posts/ai-llm/rag/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "aliga's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://Aliga123.github.io/img/Q.gif"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    (function () {
        let  arr,reg = new RegExp("(^| )"+"change-themes"+"=([^;]*)(;|$)");
        if(arr = document.cookie.match(reg)) {
        } else {
            if (new Date().getHours() >= 19 || new Date().getHours() < 6) {
                document.body.classList.add('dark');
                localStorage.setItem("pref-theme", 'dark');
            } else {
                document.body.classList.remove('dark');
                localStorage.setItem("pref-theme", 'light');
            }
        }
    })()

    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }
</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://Aliga123.github.io/" accesskey="h" title="Aliga&#39;s Blog (Alt + H)">
            <img src="https://Aliga123.github.io/img/Q.gif" alt="logo" aria-label="logo"
                 height="35">Aliga&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://Aliga123.github.io/search" title="ğŸ” æœç´¢ (Alt &#43; /)" accesskey=/>
                <span>ğŸ” æœç´¢</span>
                </a>
            </li>
            <li>
                <a href="https://Aliga123.github.io/" title="ğŸ  ä¸»é¡µ">
                <span>ğŸ  ä¸»é¡µ</span>
                </a>
            </li>
            <li>
                <a href="https://Aliga123.github.io/posts" title="ğŸ“š æ–‡ç« ">
                <span>ğŸ“š æ–‡ç« </span>
                </a>
            </li>
            <li>
                <a href="https://Aliga123.github.io/tags" title="ğŸ§© æ ‡ç­¾">
                <span>ğŸ§© æ ‡ç­¾</span>
                </a>
            </li>
            <li>
                <a href="https://Aliga123.github.io/archives/" title="â±ï¸ æ—¶é—´è½´">
                <span>â±ï¸ æ—¶é—´è½´</span>
                </a>
            </li>
            <li>
                <a href="https://Aliga123.github.io/about" title="ğŸ™‹ğŸ»â€â™‚ï¸ å…³äº">
                <span>ğŸ™‹ğŸ»â€â™‚ï¸ å…³äº</span>
                </a>
            </li>
            <li>
                <a href="https://Aliga123.github.io/links" title="ğŸ¤ å‹é“¾">
                <span>ğŸ¤ å‹é“¾</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main page">
<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }
</style>

<article class="post-single">
    <div id="single-content">
        <header class="post-header">
            <div class="breadcrumbs"><a href="https://Aliga123.github.io/">ğŸ  ä¸»é¡µ</a>&nbsp;Â»&nbsp;<a href="https://Aliga123.github.io/posts/">ğŸ“šæ–‡ç« </a>&nbsp;Â»&nbsp;<a href="https://Aliga123.github.io/posts/ai-llm/">ğŸ§± AIå¤§æ¨¡å‹åº”ç”¨å¼€å‘</a></div>
            <h1 class="post-title">
                RAG
            </h1>
            <div class="post-meta">

<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }

    .parent-post-meta {
        display: flex;
        flex-wrap: wrap;
        opacity: 0.8;
    }
</style>

<span class="parent-post-meta">
    <span id="post_meta_style_1">
        <span class="fa fa-calendar-check-o"></span>
        <span>2024-07-28
            &nbsp;&nbsp;
        </span>
    </span>
    
    
    
    
    
    
    
    <span id="post_meta_style_3">
        <span class="fa fa-file-word-o"></span>
        <span>4934å­—
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_4">
        <span class="fa fa-clock-o"></span>
        <span>10åˆ†é’Ÿ
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_5">
        <span class="fa fa-user-o"></span>
        <span>aliga
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_6">
        <span class="fa fa-tags" style="opacity: 0.8"></span>
        <span>
            <span class="post-tags-meta">
            </span>
        </span>
    </span>
</span>
<span style="opacity: 0.8;">
                    <span id="post_meta_style_7">
                        &nbsp;&nbsp;
                        <span class="fa fa-eye" ></span>
                        <span>
                            <span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv"></span></span>
                            &nbsp;&nbsp;
                        </span>
                    </span>
                    <span id="post_meta_style_8">
                        <span class="fa fa-commenting-o"></span>
                        <span>
                            <script src="https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js"></script>
                            <script>
                                let url = document.documentURI
                                
                                let dnsUrl = "https://Aliga123.github.io/"
                                let urlSplit = url.split(dnsUrl)
                                let finalUrl = urlSplit[1]
                                if (finalUrl[0] !== '/') {
                                    finalUrl = '/'+finalUrl
                                }
                                twikoo.getCommentsCount({
                                    envId:  null , 
                                region:  null , 
                                urls: [ 
                                    
                                    finalUrl,
                                ],
                                    includeReply: false 
                                }).then(function (res) {
                                    let count = res[0].count
                                    const obj = document.getElementById("comment_count");
                                    obj.innerText = count
                                    
                                    
                                    
                                }).catch(function (err) {
                                    
                                    console.error(err);
                                });
                            </script>
                            <span id="comment_count"></span>
                        </span>
                    </span>
                </span>

</div>
        </header> <aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">ç›®å½•</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#elasticsearch%e5%82%a8%e5%ad%98%e4%b8%8e%e6%a3%80%e7%b4%a2" aria-label="elasticsearchï¼šå‚¨å­˜ä¸æ£€ç´¢">elasticsearchï¼šå‚¨å­˜ä¸æ£€ç´¢</a></li>
                <li>
                    <a href="#rag%e7%b3%bb%e7%bb%9f%e7%9a%84%e5%9f%ba%e6%9c%ac%e6%90%ad%e5%bb%ba%e6%b5%81%e7%a8%8b" aria-label="RAGç³»ç»Ÿçš„åŸºæœ¬æ­å»ºæµç¨‹">RAGç³»ç»Ÿçš„åŸºæœ¬æ­å»ºæµç¨‹</a></li>
                <li>
                    <a href="#%e5%90%91%e9%87%8f%e8%b7%9d%e7%a6%bb" aria-label="å‘é‡è·ç¦»">å‘é‡è·ç¦»</a></li>
                <li>
                    <a href="#%e5%90%91%e9%87%8f%e7%bc%96%e7%a0%81" aria-label="å‘é‡ç¼–ç ">å‘é‡ç¼–ç </a></li>
                <li>
                    <a href="#%e5%90%91%e9%87%8f%e6%95%b0%e6%8d%ae%e5%ba%93" aria-label="å‘é‡æ•°æ®åº“">å‘é‡æ•°æ®åº“</a></li>
                <li>
                    <a href="#%e6%96%87%e6%9c%ac%e5%88%86%e5%89%b2%e7%9a%84%e7%b2%92%e5%ba%a6" aria-label="æ–‡æœ¬åˆ†å‰²çš„ç²’åº¦">æ–‡æœ¬åˆ†å‰²çš„ç²’åº¦</a></li>
                <li>
                    <a href="#%e6%a3%80%e7%b4%a2%e5%90%8e%e6%8e%92%e5%ba%8f" aria-label="æ£€ç´¢åæ’åº">æ£€ç´¢åæ’åº</a></li>
                <li>
                    <a href="#%e4%ba%91%e5%90%91%e9%87%8f%e6%95%b0%e6%8d%ae%e5%ba%93pineconehttpsapppineconeioorganizations-nek9opfxfhrmbw1_bdkprojects7e366afe-e57f-465b-bc3e-06afffe9fbc0indexes%e4%b8%ba%e4%be%8b%e5%ae%83%e6%9c%892g%e5%85%8d%e8%b4%b9%e7%a9%ba%e9%97%b4" aria-label="äº‘å‘é‡æ•°æ®åº“ï¼ˆpineconeä¸ºä¾‹ï¼Œå®ƒæœ‰2Gå…è´¹ç©ºé—´ï¼‰">äº‘å‘é‡æ•°æ®åº“ï¼ˆ<a href="https://app.pinecone.io/organizations/-Nek9oPfXFHrmbW1_Bdk/projects/7e366afe-e57f-465b-bc3e-06afffe9fbc0/indexes">pinecone</a>ä¸ºä¾‹ï¼Œå®ƒæœ‰2Gå…è´¹ç©ºé—´ï¼‰</a>
                </li>
            </ul>
        </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
        
        activeElement = elements[0];
        const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
        document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
    }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        if (elements) {
            activeElement = Array.from(elements).find((element) => {
                if ((getOffsetTop(element) - window.pageYOffset) > 0 &&
                    (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                    return element;
                }
            }) || activeElement

            elements.forEach(element => {
                const id = encodeURI(element.getAttribute('id')).toLowerCase();
                if (element === activeElement){
                    document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
                } else {
                    document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
                }
            })
        }
    }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;
        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;
    }
</script>
        <div class="post-content"><h2 id="elasticsearchå‚¨å­˜ä¸æ£€ç´¢">elasticsearchï¼šå‚¨å­˜ä¸æ£€ç´¢<a hidden class="anchor" aria-hidden="true" href="#elasticsearchå‚¨å­˜ä¸æ£€ç´¢">#</a></h2>
<p>Elasticsearchï¼ˆç®€ç§°ESï¼‰æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼ã€RESTful é£æ ¼çš„æœç´¢å’Œæ•°æ®åˆ†æå¼•æ“ï¼Œèƒ½å¤Ÿè§£å†³ä¸æ–­æ¶Œç°å‡ºçš„å„ç§ç”¨ä¾‹ã€‚ä½œä¸º Elastic Stack çš„æ ¸å¿ƒï¼ŒElasticsearch ä¼šé›†ä¸­å­˜å‚¨æ‚¨çš„æ•°æ®ï¼Œè®©æ‚¨é£å¿«å®Œæˆæœç´¢ï¼Œå¾®è°ƒç›¸å…³æ€§ï¼Œè¿›è¡Œå¼ºå¤§çš„åˆ†æï¼Œå¹¶è½»æ¾ç¼©æ”¾è§„æ¨¡ã€‚</p>
<p>å®‰è£…ä¸æœ¬åœ°åœ°å€ä½¿ç”¨ï¼Œ<a href="https://blog.csdn.net/chen15369337607/article/details/131783783">å‚è€ƒblog</a>ï¼š</p>
<ul>
<li>å®‰è£…JDKã€é…ç½®jdkç¯å¢ƒå˜é‡</li>
<li>ä¸‹è½½å®‰è£…<a href="https://www.elastic.co/cn/elasticsearch">Elasticsearch</a> ï¼Œé…ç½®ESç¯å¢ƒå˜é‡</li>
<li>æ‰“å¼€å®‰è£…ç›®å½•<code>D:\Toos\elasticsearch-8.14.3\bin</code>ï¼ŒåŒå‡»<code>elasticsearch.bat</code>æ–‡ä»¶</li>
<li>ä½¿ç”¨Googleæµè§ˆå™¨æ‰“å¼€http://localhost:9200ï¼Œæ£€æŸ¥æ˜¯å¦å¯åŠ¨æˆåŠŸ</li>
</ul>
<h2 id="ragç³»ç»Ÿçš„åŸºæœ¬æ­å»ºæµç¨‹">RAGç³»ç»Ÿçš„åŸºæœ¬æ­å»ºæµç¨‹<a hidden class="anchor" aria-hidden="true" href="#ragç³»ç»Ÿçš„åŸºæœ¬æ­å»ºæµç¨‹">#</a></h2>
<p><strong>1.æ–‡æ¡£çš„åŠ è½½ä¸åˆ‡å‰²</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># å®‰è£… pdf è§£æåº“</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>pip install pdfminer<span style="color:#f92672">.</span>six
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> pdfminer.high_level <span style="color:#f92672">import</span> extract_pages
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pdfminer.layout <span style="color:#f92672">import</span> LTTextContainer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">extract_text_from_pdf</span>(filename, page_numbers<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>, min_line_length<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;ä» PDF æ–‡ä»¶ä¸­ï¼ˆæŒ‰æŒ‡å®šé¡µç ï¼‰æå–æ–‡å­—&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    paragraphs <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    buffer <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    full_text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># æå–å…¨éƒ¨æ–‡æœ¬</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i, page_layout <span style="color:#f92672">in</span> enumerate(extract_pages(filename)):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># å¦‚æœæŒ‡å®šäº†é¡µç èŒƒå›´ï¼Œè·³è¿‡èŒƒå›´å¤–çš„é¡µ</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> page_numbers <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span> <span style="color:#f92672">and</span> i <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> page_numbers:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">continue</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> element <span style="color:#f92672">in</span> page_layout:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> isinstance(element, LTTextContainer):
</span></span><span style="display:flex;"><span>                full_text <span style="color:#f92672">+=</span> element<span style="color:#f92672">.</span>get_text() <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># æŒ‰ç©ºè¡Œåˆ†éš”ï¼Œå°†æ–‡æœ¬é‡æ–°ç»„ç»‡æˆæ®µè½</span>
</span></span><span style="display:flex;"><span>    lines <span style="color:#f92672">=</span> full_text<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> text <span style="color:#f92672">in</span> lines:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> len(text) <span style="color:#f92672">&gt;=</span> min_line_length:
</span></span><span style="display:flex;"><span>            buffer <span style="color:#f92672">+=</span> (<span style="color:#e6db74">&#39; &#39;</span><span style="color:#f92672">+</span>text) <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> text<span style="color:#f92672">.</span>endswith(<span style="color:#e6db74">&#39;-&#39;</span>) <span style="color:#66d9ef">else</span> text<span style="color:#f92672">.</span>strip(<span style="color:#e6db74">&#39;-&#39;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">elif</span> buffer:
</span></span><span style="display:flex;"><span>            paragraphs<span style="color:#f92672">.</span>append(buffer)
</span></span><span style="display:flex;"><span>            buffer <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> buffer:
</span></span><span style="display:flex;"><span>        paragraphs<span style="color:#f92672">.</span>append(buffer)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> paragraphs
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>paragraphs <span style="color:#f92672">=</span> extract_text_from_pdf(<span style="color:#e6db74">&#34;llama2.pdf&#34;</span>, page_numbers<span style="color:#f92672">=</span>[
</span></span><span style="display:flex;"><span>                                   <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>], min_line_length<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> para <span style="color:#f92672">in</span> paragraphs[:<span style="color:#ae81ff">5</span>]:
</span></span><span style="display:flex;"><span>    print(para)
</span></span></code></pre></div><p><strong>2.æ£€ç´¢å¼•æ“(ESå…³é”®è¯æ£€ç´¢)</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># å®‰è£… ES å®¢æˆ·ç«¯</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>pip install elasticsearch7
</span></span><span style="display:flex;"><span><span style="color:#75715e"># å®‰è£…NLTKï¼ˆæ–‡æœ¬å¤„ç†æ–¹æ³•åº“ï¼‰</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>pip install nltk
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> elasticsearch7 <span style="color:#f92672">import</span> Elasticsearch, helpers
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> PorterStemmer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> nltk
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> warnings
</span></span><span style="display:flex;"><span>warnings<span style="color:#f92672">.</span>simplefilter(<span style="color:#e6db74">&#34;ignore&#34;</span>)  <span style="color:#75715e"># å±è”½ ES çš„ä¸€äº›Warnings</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nltk<span style="color:#f92672">.</span>download(<span style="color:#e6db74">&#39;punkt&#39;</span>)  <span style="color:#75715e"># è‹±æ–‡åˆ‡è¯ã€è¯æ ¹ã€åˆ‡å¥ç­‰æ–¹æ³•</span>
</span></span><span style="display:flex;"><span>nltk<span style="color:#f92672">.</span>download(<span style="color:#e6db74">&#39;stopwords&#39;</span>)  <span style="color:#75715e"># è‹±æ–‡åœç”¨è¯åº“</span>
</span></span></code></pre></div><p>æå–æ–‡æœ¬å…³é”®è¯</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">to_keywords</span>(input_string):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;ï¼ˆè‹±æ–‡ï¼‰æ–‡æœ¬åªä¿ç•™å…³é”®å­—&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢æ‰€æœ‰éå­—æ¯æ•°å­—çš„å­—ç¬¦ä¸ºç©ºæ ¼</span>
</span></span><span style="display:flex;"><span>    no_symbols <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;[^a-zA-Z0-9\s]&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, input_string)
</span></span><span style="display:flex;"><span>    word_tokens <span style="color:#f92672">=</span> word_tokenize(no_symbols)
</span></span><span style="display:flex;"><span>    stop_words <span style="color:#f92672">=</span> set(stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#39;english&#39;</span>))
</span></span><span style="display:flex;"><span>    ps <span style="color:#f92672">=</span> PorterStemmer()
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># å»åœç”¨è¯ï¼Œå–è¯æ ¹</span>
</span></span><span style="display:flex;"><span>    filtered_sentence <span style="color:#f92672">=</span> [ps<span style="color:#f92672">.</span>stem(w)
</span></span><span style="display:flex;"><span>                         <span style="color:#66d9ef">for</span> w <span style="color:#f92672">in</span> word_tokens <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> w<span style="color:#f92672">.</span>lower() <span style="color:#f92672">in</span> stop_words]
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#39; &#39;</span><span style="color:#f92672">.</span>join(filtered_sentence)
</span></span></code></pre></div><p>å°†æ–‡æœ¬çŒå…¥æ£€ç´¢å¼•æ“</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 1. åˆ›å»ºElasticsearchè¿æ¥</span>
</span></span><span style="display:flex;"><span>es <span style="color:#f92672">=</span> Elasticsearch(
</span></span><span style="display:flex;"><span>    hosts<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;http://localhost:9200&#39;</span>]  <span style="color:#75715e"># è¿æ¥åˆ°æœ¬åœ°</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">es = Elasticsearch(
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    hosts=[&#39;http://117.50.198.53:9200&#39;],  # æœåŠ¡åœ°å€ä¸ç«¯å£
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    http_auth=(&#34;elastic&#34;, &#34;FKaB1Jpz0Rlw0l6G&#34;),  # ç”¨æˆ·åï¼Œå¯†ç 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 2. å®šä¹‰ç´¢å¼•åç§°</span>
</span></span><span style="display:flex;"><span>index_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;string_index_0924&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 3. å¦‚æœç´¢å¼•å·²å­˜åœ¨ï¼Œåˆ é™¤å®ƒï¼ˆä»…ä¾›æ¼”ç¤ºï¼Œå®é™…åº”ç”¨æ—¶ä¸éœ€è¦è¿™æ­¥ï¼‰</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> es<span style="color:#f92672">.</span>indices<span style="color:#f92672">.</span>exists(index<span style="color:#f92672">=</span>index_name):
</span></span><span style="display:flex;"><span>    es<span style="color:#f92672">.</span>indices<span style="color:#f92672">.</span>delete(index<span style="color:#f92672">=</span>index_name)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 4. åˆ›å»ºç´¢å¼•</span>
</span></span><span style="display:flex;"><span>es<span style="color:#f92672">.</span>indices<span style="color:#f92672">.</span>create(index<span style="color:#f92672">=</span>index_name)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 5. çŒåº“æŒ‡ä»¤</span>
</span></span><span style="display:flex;"><span>actions <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;_index&#34;</span>: index_name,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;_source&#34;</span>: {
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;keywords&#34;</span>: to_keywords(para),
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;text&#34;</span>: para
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> para <span style="color:#f92672">in</span> paragraphs
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 6. æ–‡æœ¬çŒåº“</span>
</span></span><span style="display:flex;"><span>helpers<span style="color:#f92672">.</span>bulk(es, actions)
</span></span></code></pre></div><p>å®ç°å…³é”®å­—æ£€ç´¢</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">search</span>(query_string, top_n<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># ES çš„æŸ¥è¯¢è¯­è¨€</span>
</span></span><span style="display:flex;"><span>    search_query <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;match&#34;</span>: {
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;keywords&#34;</span>: to_keywords(query_string)
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    res <span style="color:#f92672">=</span> es<span style="color:#f92672">.</span>search(index<span style="color:#f92672">=</span>index_name, query<span style="color:#f92672">=</span>search_query, size<span style="color:#f92672">=</span>top_n)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> [hit[<span style="color:#e6db74">&#34;_source&#34;</span>][<span style="color:#e6db74">&#34;text&#34;</span>] <span style="color:#66d9ef">for</span> hit <span style="color:#f92672">in</span> res[<span style="color:#e6db74">&#34;hits&#34;</span>][<span style="color:#e6db74">&#34;hits&#34;</span>]]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>results <span style="color:#f92672">=</span> search(<span style="color:#e6db74">&#34;how many parameters does llama 2 have?&#34;</span>, <span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> r <span style="color:#f92672">in</span> results:
</span></span><span style="display:flex;"><span>    print(r<span style="color:#f92672">+</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p><strong>3.LLMå°è£…</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> openai <span style="color:#f92672">import</span> OpenAI
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#75715e"># åŠ è½½ç¯å¢ƒå˜é‡</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> dotenv <span style="color:#f92672">import</span> load_dotenv, find_dotenv
</span></span><span style="display:flex;"><span>_ <span style="color:#f92672">=</span> load_dotenv(find_dotenv())  <span style="color:#75715e"># è¯»å–æœ¬åœ° .env æ–‡ä»¶ï¼Œé‡Œé¢å®šä¹‰äº† OPENAI_API_KEY</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>client <span style="color:#f92672">=</span> OpenAI(
</span></span><span style="display:flex;"><span>    api_key<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>getenv(<span style="color:#e6db74">&#34;OPENAI_API_KEY&#34;</span>),
</span></span><span style="display:flex;"><span>    base_url<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>getenv(<span style="color:#e6db74">&#34;OPENAI_BASE_URL&#34;</span>)
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_completion</span>(prompt, model<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;gpt-3.5-turbo-1106&#34;</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;å°è£… openai æ¥å£&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    messages <span style="color:#f92672">=</span> [{<span style="color:#e6db74">&#34;role&#34;</span>: <span style="color:#e6db74">&#34;user&#34;</span>, <span style="color:#e6db74">&#34;content&#34;</span>: prompt}]
</span></span><span style="display:flex;"><span>    response <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>chat<span style="color:#f92672">.</span>completions<span style="color:#f92672">.</span>create(
</span></span><span style="display:flex;"><span>        model<span style="color:#f92672">=</span>model,
</span></span><span style="display:flex;"><span>        messages<span style="color:#f92672">=</span>messages,
</span></span><span style="display:flex;"><span>        temperature<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,  <span style="color:#75715e"># æ¨¡å‹è¾“å‡ºçš„éšæœºæ€§ï¼Œ0 è¡¨ç¤ºéšæœºæ€§æœ€å°</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> response<span style="color:#f92672">.</span>choices[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>message<span style="color:#f92672">.</span>content
</span></span></code></pre></div><p><strong>4.Promptæ¨¡æ¿</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>prompt_template <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">ä½ æ˜¯ä¸€ä¸ªé—®ç­”æœºå™¨äººã€‚
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ä¸‹è¿°ç»™å®šçš„å·²çŸ¥ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">ç¡®ä¿ä½ çš„å›å¤å®Œå…¨ä¾æ®ä¸‹è¿°å·²çŸ¥ä¿¡æ¯ã€‚ä¸è¦ç¼–é€ ç­”æ¡ˆã€‚
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">å¦‚æœä¸‹è¿°å·²çŸ¥ä¿¡æ¯ä¸è¶³ä»¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œè¯·ç›´æ¥å›å¤&#34;æˆ‘æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜&#34;ã€‚
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">å·²çŸ¥ä¿¡æ¯:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">__INFO__
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">ç”¨æˆ·é—®ï¼š
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">__QUERY__
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">è¯·ç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_prompt</span>(prompt_template, <span style="color:#f92672">**</span>kwargs):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;å°† Prompt æ¨¡æ¿èµ‹å€¼&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    prompt <span style="color:#f92672">=</span> prompt_template
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> k, v <span style="color:#f92672">in</span> kwargs<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> isinstance(v, str):
</span></span><span style="display:flex;"><span>            val <span style="color:#f92672">=</span> v
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">elif</span> isinstance(v, list) <span style="color:#f92672">and</span> all(isinstance(elem, str) <span style="color:#66d9ef">for</span> elem <span style="color:#f92672">in</span> v):
</span></span><span style="display:flex;"><span>            val <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>join(v)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            val <span style="color:#f92672">=</span> str(v)
</span></span><span style="display:flex;"><span>        prompt <span style="color:#f92672">=</span> prompt<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;__</span><span style="color:#e6db74">{</span>k<span style="color:#f92672">.</span>upper()<span style="color:#e6db74">}</span><span style="color:#e6db74">__&#34;</span>, val)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> prompt
</span></span></code></pre></div><p><strong>5.æé—®å›ç­”</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>user_query <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;how many parameters does llama 2 have?&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 1. æ£€ç´¢</span>
</span></span><span style="display:flex;"><span>search_results <span style="color:#f92672">=</span> search(user_query, <span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 2. æ„å»º Prompt</span>
</span></span><span style="display:flex;"><span>prompt <span style="color:#f92672">=</span> build_prompt(prompt_template, info<span style="color:#f92672">=</span>search_results, query<span style="color:#f92672">=</span>user_query)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;===Prompt===&#34;</span>)
</span></span><span style="display:flex;"><span>print(prompt)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 3. è°ƒç”¨ LLM</span>
</span></span><span style="display:flex;"><span>response <span style="color:#f92672">=</span> get_completion(prompt)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># response = get_completion_ernie(prompt)</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;===å›å¤===&#34;</span>)
</span></span><span style="display:flex;"><span>print(response)
</span></span></code></pre></div><h2 id="å‘é‡è·ç¦»">å‘é‡è·ç¦»<a hidden class="anchor" aria-hidden="true" href="#å‘é‡è·ç¦»">#</a></h2>
<p>å…³é”®å­—æ£€ç´¢çš„å±€é™æ€§ï¼šåŒä¸€ä¸ªè¯­ä¹‰ï¼Œç”¨è¯ä¸åŒï¼Œå¯èƒ½å¯¼è‡´æ£€ç´¢ä¸åˆ°æœ‰æ•ˆçš„ç»“æœã€‚</p>
<p>å°†æ–‡æœ¬è½¬æ¢æˆå‘é‡ï¼Œå†å‘é‡æ£€ç´¢é€šè¿‡è®¡ç®—å‘é‡é—´ç›¸ä¼¼åº¦ï¼Œä»è€Œæ‰¾å‡ºç›¸å…³èµ„æ–™ã€‚</p>
<img src="img/image-20240718003949186.png" alt="image-20240718003949186" style="zoom:33%;" />
<p><strong>è®¡ç®—å‘é‡è·ç¦»</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> numpy <span style="color:#f92672">import</span> dot
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> numpy.linalg <span style="color:#f92672">import</span> norm
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">cos_sim</span>(a, b):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;ä½™å¼¦è·ç¦» -- è¶Šå¤§è¶Šç›¸ä¼¼&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> dot(a, b)<span style="color:#f92672">/</span>(norm(a)<span style="color:#f92672">*</span>norm(b))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">l2</span>(a, b):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;æ¬§å¼è·ç¦» -- è¶Šå°è¶Šç›¸ä¼¼&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>asarray(a)<span style="color:#f92672">-</span>np<span style="color:#f92672">.</span>asarray(b)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> norm(x)
</span></span></code></pre></div><h2 id="å‘é‡ç¼–ç ">å‘é‡ç¼–ç <a hidden class="anchor" aria-hidden="true" href="#å‘é‡ç¼–ç ">#</a></h2>
<p><strong>1.ä½¿ç”¨APIè¿›è¡Œå‘é‡ç¼–ç ï¼ˆæ”¶è´¹ï¼‰</strong></p>
<ul>
<li>openAI</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_embeddings</span>(texts, model<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;text-embedding-ada-002&#34;</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;å°è£… OpenAI çš„ Embedding æ¨¡å‹æ¥å£&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    data <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>embeddings<span style="color:#f92672">.</span>create(input<span style="color:#f92672">=</span>texts, model<span style="color:#f92672">=</span>model)<span style="color:#f92672">.</span>data
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> [x<span style="color:#f92672">.</span>embedding <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> data]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>test_query <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;æµ‹è¯•æ–‡æœ¬&#34;</span>]
</span></span><span style="display:flex;"><span>vec <span style="color:#f92672">=</span> get_embeddings(test_query)[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>print(vec[:<span style="color:#ae81ff">10</span>])
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>query <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;å›½é™…äº‰ç«¯&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ä¸”èƒ½æ”¯æŒè·¨è¯­è¨€</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># query = &#34;global conflicts&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>documents <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;è”åˆå›½å°±è‹ä¸¹è¾¾å°”å¯Œå°”åœ°åŒºå¤§è§„æ¨¡æš´åŠ›äº‹ä»¶å‘å‡ºè­¦å‘Š&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;åœŸè€³å…¶ã€èŠ¬å…°ã€ç‘å…¸ä¸åŒ—çº¦ä»£è¡¨å°†ç»§ç»­å°±ç‘å…¸â€œå…¥çº¦â€é—®é¢˜è¿›è¡Œè°ˆåˆ¤&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;æ—¥æœ¬å²é˜œå¸‚é™†ä¸Šè‡ªå«é˜Ÿå°„å‡»åœºå†…å‘ç”Ÿæªå‡»äº‹ä»¶ 3äººå—ä¼¤&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;å›½å®¶æ¸¸æ³³ä¸­å¿ƒï¼ˆæ°´ç«‹æ–¹ï¼‰ï¼šæ¢å¤æ¸¸æ³³ã€å¬‰æ°´ä¹å›­ç­‰æ°´ä¸Šé¡¹ç›®è¿è¥&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;æˆ‘å›½é¦–æ¬¡åœ¨ç©ºé—´ç«™å¼€å±•èˆ±å¤–è¾å°„ç”Ÿç‰©å­¦æš´éœ²å®éªŒ&#34;</span>,
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>query_vec <span style="color:#f92672">=</span> get_embeddings([query])[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>doc_vecs <span style="color:#f92672">=</span> get_embeddings(documents)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Cosine distance:&#34;</span>)
</span></span><span style="display:flex;"><span>print(cos_sim(query_vec, query_vec))
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> vec <span style="color:#f92672">in</span> doc_vecs:
</span></span><span style="display:flex;"><span>    print(cos_sim(query_vec, vec))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Euclidean distance:&#34;</span>)
</span></span><span style="display:flex;"><span>print(l2(query_vec, query_vec))
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> vec <span style="color:#f92672">in</span> doc_vecs:
</span></span><span style="display:flex;"><span>    print(l2(query_vec, vec))
</span></span></code></pre></div><ul>
<li>æ–‡å¿ƒåƒå¸†ï¼ˆBGE Embeddingï¼‰ï¼Œå› ä¸ºæ”¶è´¹æˆ‘è¿˜æ²¡æœ‰å°è¯•ã€‚</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> json
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> requests
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># é€šè¿‡é‰´æƒæ¥å£è·å– access token</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_access_token</span>():
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    ä½¿ç”¨ AKï¼ŒSK ç”Ÿæˆé‰´æƒç­¾åï¼ˆAccess Tokenï¼‰
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    :return: access_tokenï¼Œæˆ–æ˜¯None(å¦‚æœé”™è¯¯)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;https://aip.baidubce.com/oauth/2.0/token&#34;</span>
</span></span><span style="display:flex;"><span>    params <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;grant_type&#34;</span>: <span style="color:#e6db74">&#34;client_credentials&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;client_id&#34;</span>: os<span style="color:#f92672">.</span>getenv(<span style="color:#e6db74">&#39;ERNIE_CLIENT_ID&#39;</span>),
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;client_secret&#34;</span>: os<span style="color:#f92672">.</span>getenv(<span style="color:#e6db74">&#39;ERNIE_CLIENT_SECRET&#39;</span>)
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> str(requests<span style="color:#f92672">.</span>post(url, params<span style="color:#f92672">=</span>params)<span style="color:#f92672">.</span>json()<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;access_token&#34;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># è°ƒç”¨æ–‡å¿ƒåƒå¸† è°ƒç”¨ BGE Embedding æ¥å£</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_embeddings_bge</span>(prompts):
</span></span><span style="display:flex;"><span>    url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/embeddings/bge_large_en?access_token=&#34;</span> <span style="color:#f92672">+</span> get_access_token()
</span></span><span style="display:flex;"><span>    payload <span style="color:#f92672">=</span> json<span style="color:#f92672">.</span>dumps({
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;input&#34;</span>: prompts
</span></span><span style="display:flex;"><span>    })
</span></span><span style="display:flex;"><span>    headers <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;Content-Type&#39;</span>: <span style="color:#e6db74">&#39;application/json&#39;</span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    response <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>request(
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;POST&#34;</span>, url, headers<span style="color:#f92672">=</span>headers, data<span style="color:#f92672">=</span>payload)<span style="color:#f92672">.</span>json()
</span></span><span style="display:flex;"><span>    data <span style="color:#f92672">=</span> response[<span style="color:#e6db74">&#34;data&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> [x[<span style="color:#e6db74">&#34;embedding&#34;</span>] <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> data]
</span></span></code></pre></div><p><strong>2.æœ¬åœ°æ¨¡å‹è¿›è¡Œå‘é‡ç¼–ç </strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sentence_transformers <span style="color:#f92672">import</span> SentenceTransformer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> SentenceTransformer(<span style="color:#e6db74">&#39;BAAI/bge-large-zh-v1.5&#39;</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>query <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;å›½é™…äº‰ç«¯&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>documents <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;è”åˆå›½å°±è‹ä¸¹è¾¾å°”å¯Œå°”åœ°åŒºå¤§è§„æ¨¡æš´åŠ›äº‹ä»¶å‘å‡ºè­¦å‘Š&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;åœŸè€³å…¶ã€èŠ¬å…°ã€ç‘å…¸ä¸åŒ—çº¦ä»£è¡¨å°†ç»§ç»­å°±ç‘å…¸â€œå…¥çº¦â€é—®é¢˜è¿›è¡Œè°ˆåˆ¤&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;æ—¥æœ¬å²é˜œå¸‚é™†ä¸Šè‡ªå«é˜Ÿå°„å‡»åœºå†…å‘ç”Ÿæªå‡»äº‹ä»¶ 3äººå—ä¼¤&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;å›½å®¶æ¸¸æ³³ä¸­å¿ƒï¼ˆæ°´ç«‹æ–¹ï¼‰ï¼šæ¢å¤æ¸¸æ³³ã€å¬‰æ°´ä¹å›­ç­‰æ°´ä¸Šé¡¹ç›®è¿è¥&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;æˆ‘å›½é¦–æ¬¡åœ¨ç©ºé—´ç«™å¼€å±•èˆ±å¤–è¾å°„ç”Ÿç‰©å­¦æš´éœ²å®éªŒ&#34;</span>,
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>query_vec <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>encode(query, normalize_embeddings<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>doc_vecs <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>encode(doc, normalize_embeddings<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> doc <span style="color:#f92672">in</span> documents
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Cosine distance:&#34;</span>)  <span style="color:#75715e"># è¯¥æ¨¡å‹ä½™å¼¦è·ç¦»è¶Šå¤§è¶Šç›¸ä¼¼</span>
</span></span><span style="display:flex;"><span>print(cos_sim(query_vec, query_vec))
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> vec <span style="color:#f92672">in</span> doc_vecs:
</span></span><span style="display:flex;"><span>    print(cos_sim(query_vec, vec))
</span></span></code></pre></div><p><strong>åˆ’é‡ç‚¹ï¼š</strong></p>
<ol>
<li>ä¸æ˜¯æ¯ä¸ª Embedding æ¨¡å‹éƒ½å¯¹ä½™å¼¦è·ç¦»å’Œæ¬§æ°è·ç¦»åŒæ—¶æœ‰æ•ˆ</li>
<li>å“ªç§ç›¸ä¼¼åº¦è®¡ç®—æœ‰æ•ˆè¦é˜…è¯»æ¨¡å‹çš„è¯´æ˜ï¼ˆé€šå¸¸éƒ½æ”¯æŒä½™å¼¦è·ç¦»è®¡ç®—ï¼‰</li>
</ol>
<p><strong>æ›´å¤šæœ¬åœ°æ¨¡å‹ï¼šhttps://github.com/FlagOpen/FlagEmbedding</strong></p>
<h2 id="å‘é‡æ•°æ®åº“">å‘é‡æ•°æ®åº“<a hidden class="anchor" aria-hidden="true" href="#å‘é‡æ•°æ®åº“">#</a></h2>
<p>ä»ä¸Šè¿°å¯ä»¥çŸ¥é“ï¼Œé€šè¿‡è®¡ç®—å‘é‡è·ç¦»å®ç°å¥å­å’Œå…¶ä»–å¥å­çš„ç›¸ä¼¼åº¦ã€‚</p>
<p>ç°åœ¨æˆ‘ä»¬éœ€è¦å°†æˆ‘ä»¬çš„å¤–éƒ¨çŸ¥è¯†é€šè¿‡embeddingæ¨¡å‹è½¬æ¢æˆå‘é‡ï¼Œä¿å­˜åœ¨å‘é‡æ•°æ®åº“ä¸­ï¼Œä½œä¸ºå‘é‡æ£€ç´¢è®¾è®¡çš„ä¸­é—´ä»¶ã€‚</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>pip install chromadb
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># ä¸ºäº†æ¼”ç¤ºæ–¹ä¾¿ï¼Œæˆ‘ä»¬åªå–ä¸¤é¡µï¼ˆç¬¬ä¸€ç« ï¼‰</span>
</span></span><span style="display:flex;"><span>paragraphs <span style="color:#f92672">=</span> extract_text_from_pdf(<span style="color:#e6db74">&#34;llama2.pdf&#34;</span>, page_numbers<span style="color:#f92672">=</span>[
</span></span><span style="display:flex;"><span>                                   <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>], min_line_length<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> chromadb
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> chromadb.config <span style="color:#f92672">import</span> Settings
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyVectorDBConnector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, collection_name, embedding_fn):
</span></span><span style="display:flex;"><span>        chroma_client <span style="color:#f92672">=</span> chromadb<span style="color:#f92672">.</span>Client(Settings(allow_reset<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># ä¸ºäº†æ¼”ç¤ºï¼Œå®é™…ä¸éœ€è¦æ¯æ¬¡ reset()</span>
</span></span><span style="display:flex;"><span>        chroma_client<span style="color:#f92672">.</span>reset()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># åˆ›å»ºä¸€ä¸ª collection</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>collection <span style="color:#f92672">=</span> chroma_client<span style="color:#f92672">.</span>get_or_create_collection(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;demo&#34;</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>embedding_fn <span style="color:#f92672">=</span> embedding_fn
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">add_documents</span>(self, documents, metadata<span style="color:#f92672">=</span>{}):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;&#39;&#39;å‘ collection ä¸­æ·»åŠ æ–‡æ¡£ä¸å‘é‡&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>collection<span style="color:#f92672">.</span>add(
</span></span><span style="display:flex;"><span>            embeddings<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>embedding_fn(documents),  <span style="color:#75715e"># æ¯ä¸ªæ–‡æ¡£çš„å‘é‡</span>
</span></span><span style="display:flex;"><span>            documents<span style="color:#f92672">=</span>documents,  <span style="color:#75715e"># æ–‡æ¡£çš„åŸæ–‡</span>
</span></span><span style="display:flex;"><span>            ids<span style="color:#f92672">=</span>[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;id</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span> <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(documents))]  <span style="color:#75715e"># æ¯ä¸ªæ–‡æ¡£çš„ id</span>
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">search</span>(self, query, top_n):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;&#39;&#39;æ£€ç´¢å‘é‡æ•°æ®åº“&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>        results <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>collection<span style="color:#f92672">.</span>query(
</span></span><span style="display:flex;"><span>            query_embeddings<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>embedding_fn([query]),
</span></span><span style="display:flex;"><span>            n_results<span style="color:#f92672">=</span>top_n
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> results
</span></span></code></pre></div><p><strong>æ³¨æ„</strong>ï¼šä¸‹é¢ä»£ç ç¨‹åºæ‰§è¡Œå´©æºƒäº†ï¼Œæµ‹è¯•äº†å’Œæ–‡æœ¬é•¿åº¦æ²¡æœ‰å…³ç³»ï¼Œå¾ˆæœ‰å¯èƒ½æ˜¯å†…å­˜æœ‰å…³ï¼Œæ¢äº†autodläº‘æœåŠ¡çš„å¤§å†…å­˜æœºå­å¯è¡Œã€‚</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># åˆ›å»ºä¸€ä¸ªå‘é‡æ•°æ®åº“å¯¹è±¡</span>
</span></span><span style="display:flex;"><span>vector_db <span style="color:#f92672">=</span> MyVectorDBConnector(<span style="color:#e6db74">&#34;demo&#34;</span>, get_embeddings)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># å‘å‘é‡æ•°æ®åº“ä¸­æ·»åŠ æ–‡æ¡£</span>
</span></span><span style="display:flex;"><span>vector_db<span style="color:#f92672">.</span>add_documents(paragraphs)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>user_query <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Llama 2æœ‰å¤šå°‘å‚æ•°&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>results <span style="color:#f92672">=</span> vector_db<span style="color:#f92672">.</span>search(user_query, <span style="color:#ae81ff">2</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> para <span style="color:#f92672">in</span> results[<span style="color:#e6db74">&#39;documents&#39;</span>][<span style="color:#ae81ff">0</span>]:
</span></span><span style="display:flex;"><span>    print(para<span style="color:#f92672">+</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p><strong>ä¸»æµå‘é‡æ•°æ®åº“åŠŸèƒ½å¯¹æ¯”</strong></p>
<p><img loading="lazy" src="img/image-20240718013136827.png" alt="image-20240718013136827"  />
</p>
<ul>
<li>FAISS: Meta å¼€æºçš„å‘é‡æ£€ç´¢å¼•æ“ <a href="https://github.com/facebookresearch/faiss">https://github.com/facebookresearch/faiss</a></li>
<li>Pinecone: å•†ç”¨å‘é‡æ•°æ®åº“ï¼Œåªæœ‰äº‘æœåŠ¡ <a href="https://www.pinecone.io/">https://www.pinecone.io/</a></li>
<li>Milvus: å¼€æºå‘é‡æ•°æ®åº“ï¼ŒåŒæ—¶æœ‰äº‘æœåŠ¡ <a href="https://milvus.io/">https://milvus.io/</a></li>
<li>Weaviate: å¼€æºå‘é‡æ•°æ®åº“ï¼ŒåŒæ—¶æœ‰äº‘æœåŠ¡ <a href="https://weaviate.io/">https://weaviate.io/</a></li>
<li>Qdrant: å¼€æºå‘é‡æ•°æ®åº“ï¼ŒåŒæ—¶æœ‰äº‘æœåŠ¡ <a href="https://qdrant.tech/">https://qdrant.tech/</a></li>
<li>PGVector: Postgres çš„å¼€æºå‘é‡æ£€ç´¢å¼•æ“ <a href="https://github.com/pgvector/pgvector">https://github.com/pgvector/pgvector</a></li>
<li>RediSearch: Redis çš„å¼€æºå‘é‡æ£€ç´¢å¼•æ“ <a href="https://github.com/RediSearch/RediSearch">https://github.com/RediSearch/RediSearch</a></li>
<li>ElasticSearch ä¹Ÿæ”¯æŒå‘é‡æ£€ç´¢ <a href="https://www.elastic.co/enterprise-search/vector-search">https://www.elastic.co/enterprise-search/vector-search</a></li>
</ul>
<h2 id="æ–‡æœ¬åˆ†å‰²çš„ç²’åº¦">æ–‡æœ¬åˆ†å‰²çš„ç²’åº¦<a hidden class="anchor" aria-hidden="true" href="#æ–‡æœ¬åˆ†å‰²çš„ç²’åº¦">#</a></h2>
<p><strong>ç¼ºé™·</strong>ï¼š</p>
<ol>
<li>ç²’åº¦å¤ªå¤§å¯èƒ½å¯¼è‡´æ£€ç´¢ä¸ç²¾å‡†ï¼Œç²’åº¦å¤ªå°å¯èƒ½å¯¼è‡´ä¿¡æ¯ä¸å…¨é¢</li>
<li>é—®é¢˜çš„ç­”æ¡ˆå¯èƒ½è·¨è¶Šä¸¤ä¸ªç‰‡æ®µ</li>
</ol>
<p><strong>æ”¹è¿›</strong>: æŒ‰ä¸€å®šç²’åº¦ï¼Œéƒ¨åˆ†é‡å å¼çš„åˆ‡å‰²æ–‡æœ¬ï¼Œä½¿ä¸Šä¸‹æ–‡æ›´å®Œæ•´</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> sent_tokenize
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> json
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">split_text</span>(paragraphs, chunk_size<span style="color:#f92672">=</span><span style="color:#ae81ff">300</span>, overlap_size<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;æŒ‰æŒ‡å®š chunk_size å’Œ overlap_size äº¤å å‰²æ–‡æœ¬&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    sentences <span style="color:#f92672">=</span> [s<span style="color:#f92672">.</span>strip() <span style="color:#66d9ef">for</span> p <span style="color:#f92672">in</span> paragraphs <span style="color:#66d9ef">for</span> s <span style="color:#f92672">in</span> sent_tokenize(p)]
</span></span><span style="display:flex;"><span>    chunks <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">while</span> i <span style="color:#f92672">&lt;</span> len(sentences):
</span></span><span style="display:flex;"><span>        chunk <span style="color:#f92672">=</span> sentences[i]
</span></span><span style="display:flex;"><span>        overlap <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>
</span></span><span style="display:flex;"><span>        prev_len <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        prev <span style="color:#f92672">=</span> i <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># å‘å‰è®¡ç®—é‡å éƒ¨åˆ†</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">while</span> prev <span style="color:#f92672">&gt;=</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">and</span> len(sentences[prev])<span style="color:#f92672">+</span>len(overlap) <span style="color:#f92672">&lt;=</span> overlap_size:
</span></span><span style="display:flex;"><span>            overlap <span style="color:#f92672">=</span> sentences[prev] <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39; &#39;</span> <span style="color:#f92672">+</span> overlap
</span></span><span style="display:flex;"><span>            prev <span style="color:#f92672">-=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        chunk <span style="color:#f92672">=</span> overlap<span style="color:#f92672">+</span>chunk
</span></span><span style="display:flex;"><span>        next <span style="color:#f92672">=</span> i <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># å‘åè®¡ç®—å½“å‰chunk</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">while</span> next <span style="color:#f92672">&lt;</span> len(sentences) <span style="color:#f92672">and</span> len(sentences[next])<span style="color:#f92672">+</span>len(chunk) <span style="color:#f92672">&lt;=</span> chunk_size:
</span></span><span style="display:flex;"><span>            chunk <span style="color:#f92672">=</span> chunk <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39; &#39;</span> <span style="color:#f92672">+</span> sentences[next]
</span></span><span style="display:flex;"><span>            next <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        chunks<span style="color:#f92672">.</span>append(chunk)
</span></span><span style="display:flex;"><span>        i <span style="color:#f92672">=</span> next
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> chunks
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>chunks <span style="color:#f92672">=</span> split_text(paragraphs, <span style="color:#ae81ff">300</span>, <span style="color:#ae81ff">100</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># åˆ›å»ºä¸€ä¸ªå‘é‡æ•°æ®åº“å¯¹è±¡</span>
</span></span><span style="display:flex;"><span>vector_db <span style="color:#f92672">=</span> MyVectorDBConnector(<span style="color:#e6db74">&#34;demo_text_split&#34;</span>, get_embeddings)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># å‘å‘é‡æ•°æ®åº“ä¸­æ·»åŠ æ–‡æ¡£</span>
</span></span><span style="display:flex;"><span>vector_db<span style="color:#f92672">.</span>add_documents(chunks)
</span></span></code></pre></div><h2 id="æ£€ç´¢åæ’åº">æ£€ç´¢åæ’åº<a hidden class="anchor" aria-hidden="true" href="#æ£€ç´¢åæ’åº">#</a></h2>
<p><strong>é—®é¢˜</strong>: æœ‰æ—¶ï¼Œæœ€åˆé€‚çš„ç­”æ¡ˆä¸ä¸€å®šæ’åœ¨æ£€ç´¢çš„æœ€å‰é¢</p>
<p><strong>æ–¹æ¡ˆ</strong>:</p>
<ol>
<li>æ£€ç´¢æ—¶è¿‡æ‹›å›ä¸€éƒ¨åˆ†æ–‡æœ¬</li>
<li>é€šè¿‡ä¸€ä¸ªæ’åºæ¨¡å‹å¯¹ query å’Œ document é‡æ–°æ‰“åˆ†æ’åº</li>
</ol>
<img src="img/image-20240718195050350.png" alt="image-20240718195050350" style="zoom:50%;" />
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>pip install sentence_transformers
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sentence_transformers <span style="color:#f92672">import</span> CrossEncoder
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> CrossEncoder(<span style="color:#e6db74">&#39;cross-encoder/ms-marco-MiniLM-L-6-v2&#39;</span>, max_length<span style="color:#f92672">=</span><span style="color:#ae81ff">512</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>user_query <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;how safe is llama 2&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>scores <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict([(user_query, doc)
</span></span><span style="display:flex;"><span>                       <span style="color:#66d9ef">for</span> doc <span style="color:#f92672">in</span> search_results[<span style="color:#e6db74">&#39;documents&#39;</span>][<span style="color:#ae81ff">0</span>]])
</span></span><span style="display:flex;"><span><span style="color:#75715e"># æŒ‰å¾—åˆ†æ’åº</span>
</span></span><span style="display:flex;"><span>sorted_list <span style="color:#f92672">=</span> sorted(
</span></span><span style="display:flex;"><span>    zip(scores, search_results[<span style="color:#e6db74">&#39;documents&#39;</span>][<span style="color:#ae81ff">0</span>]), key<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> x: x[<span style="color:#ae81ff">0</span>], reverse<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> score, doc <span style="color:#f92672">in</span> sorted_list:
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>score<span style="color:#e6db74">}</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">{</span>doc<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><h2 id="äº‘å‘é‡æ•°æ®åº“pineconehttpsapppineconeioorganizations-nek9opfxfhrmbw1_bdkprojects7e366afe-e57f-465b-bc3e-06afffe9fbc0indexesä¸ºä¾‹å®ƒæœ‰2gå…è´¹ç©ºé—´">äº‘å‘é‡æ•°æ®åº“ï¼ˆ<a href="https://app.pinecone.io/organizations/-Nek9oPfXFHrmbW1_Bdk/projects/7e366afe-e57f-465b-bc3e-06afffe9fbc0/indexes">pinecone</a>ä¸ºä¾‹ï¼Œå®ƒæœ‰2Gå…è´¹ç©ºé—´ï¼‰<a hidden class="anchor" aria-hidden="true" href="#äº‘å‘é‡æ•°æ®åº“pineconehttpsapppineconeioorganizations-nek9opfxfhrmbw1_bdkprojects7e366afe-e57f-465b-bc3e-06afffe9fbc0indexesä¸ºä¾‹å®ƒæœ‰2gå…è´¹ç©ºé—´">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>pip install <span style="color:#e6db74">&#34;pinecone-client[grpc]&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>pip install langchain
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>pip install langchain<span style="color:#f92672">-</span>openai
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>pip install langchain<span style="color:#f92672">-</span>pinecone
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>pip install langchain_text_splitters
</span></span></code></pre></div><p><strong>1.åˆå§‹åŒ–å®¢æˆ·ç«¯è¿æ¥</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> pinecone.grpc <span style="color:#f92672">import</span> PineconeGRPC <span style="color:#66d9ef">as</span> Pinecone
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pinecone <span style="color:#f92672">import</span> ServerlessSpec
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># åˆå§‹åŒ–å®¢æˆ·ç«¯è¿æ¥</span>
</span></span><span style="display:flex;"><span>pc <span style="color:#f92672">=</span> Pinecone(api_key<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>getenv(<span style="color:#e6db74">&#34;PINECONE_API_KEY&#34;</span>))
</span></span></code></pre></div><p><strong>2.åˆ›å»ºæ— æœåŠ¡å™¨ç´¢å¼•</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># åˆ›å»ºæ— æœåŠ¡å™¨ç´¢å¼•ï¼Œè¿™é‡Œé€‰ç”¨openaiæ¨¡å‹ï¼Œæ‰€ä»¥è®¾ç½®ç´¢å¼•ç»´åº¦å’Œè·ç¦»åº¦é‡ä»¥åŒ¹é…text-embedding-3-smallç”¨äºåˆ›å»ºåµŒå…¥çš„ OpenAI æ¨¡å‹çš„ç»´åº¦å’Œè·ç¦»åº¦é‡ã€‚</span>
</span></span><span style="display:flex;"><span>index_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;arxiv-llama2-index&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> index_name <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> pc<span style="color:#f92672">.</span>list_indexes()<span style="color:#f92672">.</span>names():
</span></span><span style="display:flex;"><span>    pc<span style="color:#f92672">.</span>create_index(
</span></span><span style="display:flex;"><span>        name<span style="color:#f92672">=</span>index_name,
</span></span><span style="display:flex;"><span>        dimension<span style="color:#f92672">=</span><span style="color:#ae81ff">1536</span>, <span style="color:#75715e"># æ›´æ–°æ¨¡å‹é€‰æ‹©</span>
</span></span><span style="display:flex;"><span>        metric<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;cosine&#34;</span>, <span style="color:#75715e"># æ›´æ–°æ¨¡å‹é€‰æ‹©</span>
</span></span><span style="display:flex;"><span>        spec<span style="color:#f92672">=</span>ServerlessSpec(
</span></span><span style="display:flex;"><span>            cloud<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;aws&#39;</span>, 
</span></span><span style="display:flex;"><span>            region<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;us-east-1&#39;</span>
</span></span><span style="display:flex;"><span>        ) 
</span></span><span style="display:flex;"><span>    ) 
</span></span></code></pre></div><p><strong>3.è·å–çŸ¥è¯†æ•°æ®ã€‚è¿™é‡Œä»¥æ‰‹åŠ¨æ„å»ºçš„mdæ–‡æ¡£ä¸ºä¾‹ï¼Œæ ¹æ®ç»“æ„å¯¹å†…å®¹è¿›è¡Œåˆ†å—ã€‚å¦‚æœæ˜¯textæ–‡æœ¬ç±»å‹æ•°æ®å‚è€ƒ<a href="https://docs.pinecone.io/integrations/langchain#key-concepts">pineconeæ–‡æ¡£</a>ã€‚</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_text_splitters <span style="color:#f92672">import</span> MarkdownHeaderTextSplitter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Chunk the document based on h2 headers.</span>
</span></span><span style="display:flex;"><span>markdown_document <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;## Introduction</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">Welcome to the whimsical world of the WonderVector5000, an astonishing leap into the realms of imaginative technology. This extraordinary device, borne of creative fancy, promises to revolutionize absolutely nothing while dazzling you with its fantastical features. Whether you&#39;re a seasoned technophile or just someone looking for a bit of fun, the WonderVector5000 is sure to leave you amused and bemused in equal measure. Let&#39;s explore the incredible, albeit entirely fictitious, specifications, setup process, and troubleshooting tips for this marvel of modern nonsense.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">## Product overview</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">The WonderVector5000 is packed with features that defy logic and physics, each designed to sound impressive while maintaining a delightful air of absurdity:</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Quantum Flibberflabber Engine: The heart of the WonderVector5000, this engine operates on principles of quantum flibberflabber, a phenomenon as mysterious as it is meaningless. It&#39;s said to harness the power of improbability to function seamlessly across multiple dimensions.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Hyperbolic Singularity Matrix: This component compresses infinite possibilities into a singular hyperbolic state, allowing the device to predict outcomes with 0</span><span style="color:#e6db74">% a</span><span style="color:#e6db74">ccuracy, ensuring every use is a new adventure.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Aetherial Flux Capacitor: Drawing energy from the fictional aether, this flux capacitor provides unlimited power by tapping into the boundless reserves of imaginary energy fields.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Multi-Dimensional Holo-Interface: Interact with the WonderVector5000 through its holographic interface that projects controls and information in three-and-a-half dimensions, creating a user experience that&#39;s simultaneously futuristic and perplexing.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Neural Fandango Synchronizer: This advanced feature connects directly to the user&#39;s brain waves, converting your deepest thoughts into tangible actionsâ€”albeit with results that are whimsically unpredictable.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Chrono-Distortion Field: Manipulate time itself with the WonderVector5000&#39;s chrono-distortion field, allowing you to experience moments before they occur or revisit them in a state of temporal flux.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">## Use cases</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">While the WonderVector5000 is fundamentally a device of fiction and fun, let&#39;s imagine some scenarios where it could hypothetically be applied:</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Time Travel Adventures: Use the Chrono-Distortion Field to visit key moments in history or glimpse into the future. While actual temporal manipulation is impossible, the mere idea sparks endless storytelling possibilities.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Interdimensional Gaming: Engage with the Multi-Dimensional Holo-Interface for immersive, out-of-this-world gaming experiences. Imagine games that adapt to your thoughts via the Neural Fandango Synchronizer, creating a unique and ever-changing environment.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Infinite Creativity: Harness the Hyperbolic Singularity Matrix for brainstorming sessions. By compressing infinite possibilities into hyperbolic states, it could theoretically help unlock unprecedented creative ideas.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Energy Experiments: Explore the concept of limitless power with the Aetherial Flux Capacitor. Though purely fictional, the notion of drawing energy from the aether could inspire innovative thinking in energy research.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">## Getting started</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">Setting up your WonderVector5000 is both simple and absurdly intricate. Follow these steps to unleash the full potential of your new device:</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">1. Unpack the Device: Remove the WonderVector5000 from its anti-gravitational packaging, ensuring to handle with care to avoid disturbing the delicate balance of its components.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">2. Initiate the Quantum Flibberflabber Engine: Locate the translucent lever marked â€œQFE Startâ€ and pull it gently. You should notice a slight shimmer in the air as the engine engages, indicating that quantum flibberflabber is in effect.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">3. Calibrate the Hyperbolic Singularity Matrix: Turn the dials labeled &#39;Infinity A&#39; and &#39;Infinity B&#39; until the matrix stabilizes. You&#39;ll know it&#39;s calibrated correctly when the display shows a single, stable â€œâˆâ€.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">4. Engage the Aetherial Flux Capacitor: Insert the EtherKey into the designated slot and turn it clockwise. A faint humming sound should confirm that the aetherial flux capacitor is active.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">5. Activate the Multi-Dimensional Holo-Interface: Press the button resembling a floating question mark to activate the holo-interface. The controls should materialize before your eyes, slightly out of phase with reality.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">6. Synchronize the Neural Fandango Synchronizer: Place the neural headband on your forehead and think of the word â€œWonderâ€. The device will sync with your thoughts, a process that should take just a few moments.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">7. Set the Chrono-Distortion Field: Use the temporal sliders to adjust the time settings. Recommended presets include â€œPastâ€, â€œPresentâ€, and â€œFutureâ€, though feel free to explore other, more abstract temporal states.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">## Troubleshooting</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">Even a device as fantastically designed as the WonderVector5000 can encounter problems. Here are some common issues and their solutions:</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Issue: The Quantum Flibberflabber Engine won&#39;t start.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">    - Solution: Ensure the anti-gravitational packaging has been completely removed. Check for any residual shards of improbability that might be obstructing the engine.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Issue: The Hyperbolic Singularity Matrix displays â€œâˆâˆâ€.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">    - Solution: This indicates a hyper-infinite loop. Reset the dials to zero and then adjust them slowly until the display shows a single, stable infinity symbol.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Issue: The Aetherial Flux Capacitor isn&#39;t engaging.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">    - Solution: Verify that the EtherKey is properly inserted and genuine. Counterfeit EtherKeys can often cause malfunctions. Replace with an authenticated EtherKey if necessary.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Issue: The Multi-Dimensional Holo-Interface shows garbled projections.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">    - Solution: Realign the temporal resonators by tapping the holographic screen three times in quick succession. This should stabilize the projections.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Issue: The Neural Fandango Synchronizer causes headaches.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">    - Solution: Ensure the headband is properly positioned and not too tight. Relax and focus on simple, calming thoughts to ease the synchronization process.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Issue: The Chrono-Distortion Field is stuck in the past.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">    - Solution: Increase the temporal flux by 5%. If this fails, perform a hard reset by holding down the â€œFutureâ€ slider for ten seconds.&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>headers_to_split_on <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    (<span style="color:#e6db74">&#34;##&#34;</span>, <span style="color:#e6db74">&#34;Header 2&#34;</span>)
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>markdown_splitter <span style="color:#f92672">=</span> MarkdownHeaderTextSplitter(
</span></span><span style="display:flex;"><span>    headers_to_split_on<span style="color:#f92672">=</span>headers_to_split_on, strip_headers<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>md_header_splits <span style="color:#f92672">=</span> markdown_splitter<span style="color:#f92672">.</span>split_text(markdown_document)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(md_header_splits[:<span style="color:#ae81ff">1</span>])
</span></span></code></pre></div><p><strong>4.åˆå§‹åŒ–embeddingæ¨¡å‹</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_openai <span style="color:#f92672">import</span> OpenAIEmbeddings
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialize a LangChain embedding object.</span>
</span></span><span style="display:flex;"><span>model_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;text-embedding-3-small&#34;</span>  
</span></span><span style="display:flex;"><span>embeddings <span style="color:#f92672">=</span> OpenAIEmbeddings(  
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">=</span>model_name,  
</span></span><span style="display:flex;"><span>    openai_api_key<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>environ<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;OPENAI_API_KEY&#34;</span>)  
</span></span><span style="display:flex;"><span>) 
</span></span></code></pre></div><p><strong>4.çŒåº“ã€‚åµŒå…¥æ¯ä¸ªå—å¹¶å°†åµŒå…¥å†…å®¹æ’å…¥åˆ°æ‚¨çš„ Pinecone ç´¢å¼•ä¸­ã€‚</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_pinecone <span style="color:#f92672">import</span> PineconeVectorStore
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> time
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#å®šä¹‰ä¸€ä¸ªå‘½åç©ºé—´ã€‚åœ¨ç´¢å¼•ä¸­ï¼Œå‘é‡å­˜å‚¨åœ¨å‘½åç©ºé—´ä¸­ï¼Œå¹¶ä¸”æ‰€æœ‰æ›´æ–°æ’å…¥ã€æŸ¥è¯¢å’Œå…¶ä»–æ•°æ®æ“ä½œå§‹ç»ˆä»¥ä¸€ä¸ªå‘½åç©ºé—´ä¸ºç›®æ ‡ã€‚</span>
</span></span><span style="display:flex;"><span>namespace <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;wondervector5000&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Embed each chunk and upsert the embeddings into your Pinecone index.</span>
</span></span><span style="display:flex;"><span>docsearch <span style="color:#f92672">=</span> PineconeVectorStore<span style="color:#f92672">.</span>from_documents(
</span></span><span style="display:flex;"><span>    documents<span style="color:#f92672">=</span>md_header_splits,
</span></span><span style="display:flex;"><span>    index_name<span style="color:#f92672">=</span>index_name,
</span></span><span style="display:flex;"><span>    embedding<span style="color:#f92672">=</span>embeddings, 
</span></span><span style="display:flex;"><span>    namespace<span style="color:#f92672">=</span>namespace  <span style="color:#75715e"># åœ¨ç´¢å¼•ä¸­ï¼Œå‘é‡å­˜å‚¨åœ¨å‘½åç©ºé—´ä¸­</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">.</span>sleep(<span style="color:#ae81ff">1</span>)
</span></span></code></pre></div><p><strong>5.ï¼ˆå¯é€‰ï¼‰æŸ¥è®°å½•ã€‚ä½¿ç”¨ Pinecone çš„<code>list</code>å’Œ<code>query</code>æ“ä½œæŸ¥çœ‹å…¶ä¸­ä¸€æ¡è®°å½•</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>index <span style="color:#f92672">=</span> pc<span style="color:#f92672">.</span>Index(index_name)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> ids <span style="color:#f92672">in</span> index<span style="color:#f92672">.</span>list(namespace<span style="color:#f92672">=</span>namespace):
</span></span><span style="display:flex;"><span>    query <span style="color:#f92672">=</span> index<span style="color:#f92672">.</span>query(
</span></span><span style="display:flex;"><span>        id<span style="color:#f92672">=</span>ids[<span style="color:#ae81ff">0</span>], 
</span></span><span style="display:flex;"><span>        namespace<span style="color:#f92672">=</span>namespace, 
</span></span><span style="display:flex;"><span>        top_k<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>        include_values<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>        include_metadata<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    print(query)
</span></span></code></pre></div><p><strong>6.ä½¿ç”¨LangChainåˆ›å»ºä¸€ä¸ªå¯¹è¯å¯¹è±¡</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.chains <span style="color:#f92672">import</span> RetrievalQA  
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_openai <span style="color:#f92672">import</span> ChatOpenAI
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># åˆå§‹åŒ–ä¸€ä¸ªä»Pineconeæ£€ç´¢ä¿¡æ¯çš„LangChainå¯¹è±¡</span>
</span></span><span style="display:flex;"><span>knowledge <span style="color:#f92672">=</span> PineconeVectorStore<span style="color:#f92672">.</span>from_existing_index(
</span></span><span style="display:flex;"><span>    index_name<span style="color:#f92672">=</span>index_name,
</span></span><span style="display:flex;"><span>    namespace<span style="color:#f92672">=</span>namespace,
</span></span><span style="display:flex;"><span>    embedding<span style="color:#f92672">=</span>embeddings
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># åˆå§‹åŒ–ä¸€ä¸ªä¸LLMèŠå¤©çš„LangChainå¯¹è±¡</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># without knowledge from Pinecone.</span>
</span></span><span style="display:flex;"><span>llm <span style="color:#f92672">=</span> ChatOpenAI(
</span></span><span style="display:flex;"><span>    openai_api_key<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>environ<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;OPENAI_API_KEY&#34;</span>),
</span></span><span style="display:flex;"><span>    model_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;gpt-3.5-turbo-1106&#34;</span>,
</span></span><span style="display:flex;"><span>    temperature<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>qa <span style="color:#f92672">=</span> RetrievalQA<span style="color:#f92672">.</span>from_chain_type(
</span></span><span style="display:flex;"><span>    llm<span style="color:#f92672">=</span>llm,
</span></span><span style="display:flex;"><span>    chain_type<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;stuff&#34;</span>,
</span></span><span style="display:flex;"><span>    retriever<span style="color:#f92672">=</span>knowledge<span style="color:#f92672">.</span>as_retriever()
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p><strong>7.å¯¹è¯ä½¿ç”¨ã€‚</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Define a few questions about the WonderVector5000.</span>
</span></span><span style="display:flex;"><span>query1 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;&#34;What are the first 3 steps for getting started 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">with the WonderVector5000?&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>query2 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;&#34;The Neural Fandango Synchronizer is giving me a 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">headache. What do I do?&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Send each query to the LLM twice, first with relevant knowledge from Pincone </span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># and then without any additional knowledge.</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Query 1</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Chat with knowledge:&#34;</span>)
</span></span><span style="display:flex;"><span>print(qa<span style="color:#f92672">.</span>invoke(query1)<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;result&#34;</span>))
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Chat without knowledge:&#34;</span>)
</span></span><span style="display:flex;"><span>print(llm<span style="color:#f92672">.</span>invoke(query1)<span style="color:#f92672">.</span>content)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Query 2</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Chat with knowledge:&#34;</span>)
</span></span><span style="display:flex;"><span>print(qa<span style="color:#f92672">.</span>invoke(query2)<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;result&#34;</span>))
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Chat without knowledge:&#34;</span>)
</span></span><span style="display:flex;"><span>print(llm<span style="color:#f92672">.</span>invoke(query2)<span style="color:#f92672">.</span>content)
</span></span></code></pre></div><p>8.ï¼ˆå¯é€‰ï¼‰å¦‚æœä¸éœ€è¦å¯ä»¥æ¸…ç†</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># æ¸…ç†</span>
</span></span><span style="display:flex;"><span>pc<span style="color:#f92672">.</span>delete_index(index_name)
</span></span></code></pre></div>

        </div>
        <div class="post-reward">
            <div style="padding: 0 0 0 0; margin: 0 0 0 0; width: 100%; font-size:16px; text-align: center;">
                <div id="QR" style="opacity: 0;">
                    <div id="wechat" style="display: inline-block">
                        <a class="fancybox" rel="group">
                            <img id="wechat_qr" src="https://Aliga123.github.io/img/wechat_pay.jpg" alt="wechat_pay"></a>
                        <p>å¾®ä¿¡</p>
                    </div>
                    <div id="alipay" style="display: inline-block">
                        <a class="fancybox" rel="group">
                            <img id="alipay_qr" src="https://Aliga123.github.io/img/alipay.jpg" alt="alipay"></a>
                        <p>æ”¯ä»˜å®</p>
                    </div>
                </div>
                <button id="rewardButton"
                        onclick="
                    var qr = document.getElementById('QR');
                    if (qr.style.opacity === '0') {
                        qr.style.opacity='1';
                    } else {
                        qr.style.opacity='0'
                    }"
                >
                    <span>ğŸ§§ é¼“åŠ±</span>
                </button>
            </div>
        </div>

        <footer class="post-footer">
            
<nav class="paginav">
  <a class="prev" href="https://Aliga123.github.io/posts/ai-llm/prompt%E5%B7%A5%E7%A8%8B--cottot/">
    <span class="title">Â« ä¸Šä¸€é¡µ</span>
    <br>
    <span>Promptå·¥ç¨‹-CoTã€ToT</span>
  </a>
  <a class="next" href="https://Aliga123.github.io/posts/ai-llm/semantic-kernel/">
    <span class="title">ä¸‹ä¸€é¡µ Â»</span>
    <br>
    <span>Semantic Kernel</span>
  </a>
</nav>

        </footer>
    </div>

<style>
    .comments_details summary::marker {
        font-size: 20px;
        content: 'ğŸ‘‰å±•å¼€è¯„è®º';
        color: var(--content);
    }
    .comments_details[open] summary::marker{
        font-size: 20px;
        content: 'ğŸ‘‡å…³é—­è¯„è®º';
        color: var(--content);
    }
</style>


<div>
    <details class="comments_details">
        <summary style="cursor: pointer; margin: 50px 0 20px 0;width: 130px;">
            <span style="font-size: 20px;color: var(--content);">...</span>
        </summary>
        <div id="tcomment"></div>
    </details>
    <script src="https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js">
    </script>
    <script>
        twikoo.init({
            envId:  null ,
        el: "#tcomment",
            lang: 'zh-CN',
            region:  null ,
        path: window.TWIKOO_MAGIC_PATH||window.location.pathname,
        })
    </script>
</div>
</article>
</main>

<footer class="footer">
    <span>
        Copyright
        &copy;
        2020-2024
        <a href="https://Aliga123.github.io/" style="color:#939393;">aliga&#39;s Blog</a>
        All Rights Reserved
    </span>
    <a href="https://beian.miit.gov.cn/" target="_blank" style="color:#939393;">å¡«å†™è‡ªå·±çš„å¤‡æ¡ˆå·</a>&nbsp;
    <span>
        <a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=null"
           style="display:inline-block;text-decoration:none;height:20px;color:#939393;">
            <img src="%e5%a1%ab%e8%87%aa%e5%b7%b1%e7%9a%84%e5%85%ac%e5%ae%89%e5%9b%be%e6%a0%87%e9%93%be%e6%8e%a5" style="float:left;margin: 0px 5px 0px 0px;"/>
            å¡«è‡ªå·±çš„å…¬ç½‘å®‰å¤‡
        </a>
    </span>
    <span id="busuanzi_container">
        <span class="fa fa-user"></span> <span id="busuanzi_value_site_uv"></span>
        <span class="fa fa-eye"></span> <span id="busuanzi_value_site_pv"></span>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <span class="topInner">
        <svg class="topSvg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z"/>
        </svg>
        <span id="read_progress"></span>
    </span>
</a>

<script>
    document.addEventListener('scroll', function (e) {
        const readProgress = document.getElementById("read_progress");
        const scrollHeight = document.documentElement.scrollHeight;
        const clientHeight = document.documentElement.clientHeight;
        const scrollTop = document.documentElement.scrollTop || document.body.scrollTop;
        readProgress.innerText = ((scrollTop / (scrollHeight - clientHeight)).toFixed(2) * 100).toFixed(0);
    })
</script>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });
</script>
<script>
    let mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 200 || document.documentElement.scrollTop > 200) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };
</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        (function() {
            document.cookie = "change-themes" + "="+ escape ("false");
        })()

        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    });
</script>

<script>
    document.body.addEventListener('copy', function (e) {
        if (window.getSelection().toString() && window.getSelection().toString().length > 50) {
            let clipboardData = e.clipboardData || window.clipboardData;
            if (clipboardData) {
                e.preventDefault();
                let htmlData = window.getSelection().toString() +
                    '\r\n\nâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\r\n' +
                    'ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºã€Œ'+"aliga's Blog"+'ã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚' +
                '\r\nåŸæ–‡é“¾æ¥ï¼š' + location.href;
                let textData = window.getSelection().toString() +
                    '\r\n\nâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\r\n' +
                    'ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºã€Œ'+"aliga's Blog"+'ã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚' +
                '\r\nåŸæ–‡é“¾æ¥ï¼š' + location.href;
                clipboardData.setData('text/html', htmlData);
                clipboardData.setData('text/plain', textData);
            }
        }
    });
</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;
        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'å¤åˆ¶';

        function copyingDone() {
            copybutton.innerText = 'å·²å¤åˆ¶ï¼';
            setTimeout(() => {
                copybutton.innerText = 'å¤åˆ¶';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                let text = codeblock.textContent +
                    '\r\nâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\r\n' +
                    'ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºã€Œ'+"aliga's Blog"+'ã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚' +
                '\r\nåŸæ–‡é“¾æ¥ï¼š' + location.href;
                navigator.clipboard.writeText(text);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) {}
            selection.removeRange(range);
        });

        let language = codeblock.className.replaceAll("language-", "")
        let macTool = document.createElement("div")
        let macTool1 = document.createElement("div")
        let macTool2 = document.createElement("div")
        let macTool3 = document.createElement("div")
        let languageType = document.createElement("div")
        languageType.innerText = language
        macTool.setAttribute('class', 'mac-tool')
        macTool1.setAttribute('class', 'mac bb1')
        macTool2.setAttribute('class', 'mac bb2')
        macTool3.setAttribute('class', 'mac bb3')
        languageType.setAttribute('class', 'language-type')
        macTool.appendChild(macTool1)
        macTool.appendChild(macTool2)
        macTool.appendChild(macTool3)
        macTool.appendChild(languageType)

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
            container.appendChild(macTool)
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        }
    });
</script>
</body>

</html>
