<!DOCTYPE html>
<html lang="zh" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>RAG | aliga&#39;s Blog</title>
<meta name="keywords" content="">
<meta name="description" content="elasticsearch：储存与检索 Elasticsearch（简称ES）是一个分布式、RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。作为 Elastic Stack 的核心，Elasticsearch 会集中存储您的数据，让您飞快完成搜索，微调相关性，进行强大的分析，并轻松缩放规">
<meta name="author" content="aliga">
<link rel="canonical" href="https://Aliga123.github.io/posts/ai-llm/rag/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.js" onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://Aliga123.github.io/img/Q.gif">
<link rel="icon" type="image/png" sizes="16x16" href="https://Aliga123.github.io/img/Q.gif">
<link rel="icon" type="image/png" sizes="32x32" href="https://Aliga123.github.io/img/Q.gif">
<link rel="apple-touch-icon" href="https://Aliga123.github.io/img/Q.gif">
<link rel="mask-icon" href="https://Aliga123.github.io/img/Q.gif">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="zh" href="https://Aliga123.github.io/posts/ai-llm/rag/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script defer src="https://unpkg.com/mermaid@8.8.1/dist/mermaid.min.js"></script>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css">
<script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.3/dist/jquery.min.js"></script>



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = ""; 
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

  

<meta property="og:title" content="RAG" />
<meta property="og:description" content="elasticsearch：储存与检索 Elasticsearch（简称ES）是一个分布式、RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。作为 Elastic Stack 的核心，Elasticsearch 会集中存储您的数据，让您飞快完成搜索，微调相关性，进行强大的分析，并轻松缩放规" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://Aliga123.github.io/posts/ai-llm/rag/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-07-28T00:18:23+08:00" />
<meta property="article:modified_time" content="2024-07-28T00:18:23+08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="RAG"/>
<meta name="twitter:description" content="elasticsearch：储存与检索 Elasticsearch（简称ES）是一个分布式、RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。作为 Elastic Stack 的核心，Elasticsearch 会集中存储您的数据，让您飞快完成搜索，微调相关性，进行强大的分析，并轻松缩放规"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [

        {
          "@type": "ListItem",
          "position":  1 ,
          "name": "📚文章",
          "item": "https://Aliga123.github.io/posts/"
        },

        {
          "@type": "ListItem",
          "position":  2 ,
          "name": "🧱 AI大模型应用开发",
          "item": "https://Aliga123.github.io/posts/ai-llm/"
        }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "RAG",
      "item": "https://Aliga123.github.io/posts/ai-llm/rag/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "RAG",
  "name": "RAG",
  "description": "elasticsearch：储存与检索 Elasticsearch（简称ES）是一个分布式、RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。作为 Elastic Stack 的核心，Elasticsearch 会集中存储您的数据，让您飞快完成搜索，微调相关性，进行强大的分析，并轻松缩放规",
  "keywords": [
    ""
  ],
  "articleBody": "elasticsearch：储存与检索 Elasticsearch（简称ES）是一个分布式、RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。作为 Elastic Stack 的核心，Elasticsearch 会集中存储您的数据，让您飞快完成搜索，微调相关性，进行强大的分析，并轻松缩放规模。\n安装与本地地址使用，参考blog：\n安装JDK、配置jdk环境变量 下载安装Elasticsearch ，配置ES环境变量 打开安装目录D:\\Toos\\elasticsearch-8.14.3\\bin，双击elasticsearch.bat文件 使用Google浏览器打开http://localhost:9200，检查是否启动成功 RAG系统的基本搭建流程 1.文档的加载与切割\n# 安装 pdf 解析库 !pip install pdfminer.six from pdfminer.high_level import extract_pages from pdfminer.layout import LTTextContainer def extract_text_from_pdf(filename, page_numbers=None, min_line_length=1): '''从 PDF 文件中（按指定页码）提取文字''' paragraphs = [] buffer = '' full_text = '' # 提取全部文本 for i, page_layout in enumerate(extract_pages(filename)): # 如果指定了页码范围，跳过范围外的页 if page_numbers is not None and i not in page_numbers: continue for element in page_layout: if isinstance(element, LTTextContainer): full_text += element.get_text() + '\\n' # 按空行分隔，将文本重新组织成段落 lines = full_text.split('\\n') for text in lines: if len(text) \u003e= min_line_length: buffer += (' '+text) if not text.endswith('-') else text.strip('-') elif buffer: paragraphs.append(buffer) buffer = '' if buffer: paragraphs.append(buffer) return paragraphs paragraphs = extract_text_from_pdf(\"llama2.pdf\", page_numbers=[ 2, 3], min_line_length=10) for para in paragraphs[:5]: print(para) 2.检索引擎(ES关键词检索)\n# 安装 ES 客户端 !pip install elasticsearch7 # 安装NLTK（文本处理方法库） !pip install nltk from elasticsearch7 import Elasticsearch, helpers from nltk.stem import PorterStemmer from nltk.tokenize import word_tokenize from nltk.corpus import stopwords import nltk import re import warnings warnings.simplefilter(\"ignore\") # 屏蔽 ES 的一些Warnings nltk.download('punkt') # 英文切词、词根、切句等方法 nltk.download('stopwords') # 英文停用词库 提取文本关键词\ndef to_keywords(input_string): '''（英文）文本只保留关键字''' # 使用正则表达式替换所有非字母数字的字符为空格 no_symbols = re.sub(r'[^a-zA-Z0-9\\s]', ' ', input_string) word_tokens = word_tokenize(no_symbols) stop_words = set(stopwords.words('english')) ps = PorterStemmer() # 去停用词，取词根 filtered_sentence = [ps.stem(w) for w in word_tokens if not w.lower() in stop_words] return ' '.join(filtered_sentence) 将文本灌入检索引擎\n# 1. 创建Elasticsearch连接 es = Elasticsearch( hosts=['http://localhost:9200'] # 连接到本地 ) ''' es = Elasticsearch( hosts=['http://117.50.198.53:9200'], # 服务地址与端口 http_auth=(\"elastic\", \"FKaB1Jpz0Rlw0l6G\"), # 用户名，密码 ) ''' # 2. 定义索引名称 index_name = \"string_index_0924\" # 3. 如果索引已存在，删除它（仅供演示，实际应用时不需要这步） if es.indices.exists(index=index_name): es.indices.delete(index=index_name) # 4. 创建索引 es.indices.create(index=index_name) # 5. 灌库指令 actions = [ { \"_index\": index_name, \"_source\": { \"keywords\": to_keywords(para), \"text\": para } } for para in paragraphs ] # 6. 文本灌库 helpers.bulk(es, actions) 实现关键字检索\ndef search(query_string, top_n=3): # ES 的查询语言 search_query = { \"match\": { \"keywords\": to_keywords(query_string) } } res = es.search(index=index_name, query=search_query, size=top_n) return [hit[\"_source\"][\"text\"] for hit in res[\"hits\"][\"hits\"]] results = search(\"how many parameters does llama 2 have?\", 2) for r in results: print(r+\"\\n\") 3.LLM封装\nfrom openai import OpenAI import os # 加载环境变量 from dotenv import load_dotenv, find_dotenv _ = load_dotenv(find_dotenv()) # 读取本地 .env 文件，里面定义了 OPENAI_API_KEY client = OpenAI( api_key=os.getenv(\"OPENAI_API_KEY\"), base_url=os.getenv(\"OPENAI_BASE_URL\") ) def get_completion(prompt, model=\"gpt-3.5-turbo-1106\"): '''封装 openai 接口''' messages = [{\"role\": \"user\", \"content\": prompt}] response = client.chat.completions.create( model=model, messages=messages, temperature=0, # 模型输出的随机性，0 表示随机性最小 ) return response.choices[0].message.content 4.Prompt模板\nprompt_template = \"\"\" 你是一个问答机器人。 你的任务是根据下述给定的已知信息回答用户问题。 确保你的回复完全依据下述已知信息。不要编造答案。 如果下述已知信息不足以回答用户的问题，请直接回复\"我无法回答您的问题\"。 已知信息: __INFO__ 用户问： __QUERY__ 请用中文回答用户问题。 \"\"\" def build_prompt(prompt_template, **kwargs): '''将 Prompt 模板赋值''' prompt = prompt_template for k, v in kwargs.items(): if isinstance(v, str): val = v elif isinstance(v, list) and all(isinstance(elem, str) for elem in v): val = '\\n'.join(v) else: val = str(v) prompt = prompt.replace(f\"__{k.upper()}__\", val) return prompt 5.提问回答\nuser_query = \"how many parameters does llama 2 have?\" # 1. 检索 search_results = search(user_query, 2) # 2. 构建 Prompt prompt = build_prompt(prompt_template, info=search_results, query=user_query) print(\"===Prompt===\") print(prompt) # 3. 调用 LLM response = get_completion(prompt) # response = get_completion_ernie(prompt) print(\"===回复===\") print(response) 向量距离 关键字检索的局限性：同一个语义，用词不同，可能导致检索不到有效的结果。\n将文本转换成向量，再向量检索通过计算向量间相似度，从而找出相关资料。\n计算向量距离\nimport numpy as np from numpy import dot from numpy.linalg import norm def cos_sim(a, b): '''余弦距离 -- 越大越相似''' return dot(a, b)/(norm(a)*norm(b)) def l2(a, b): '''欧式距离 -- 越小越相似''' x = np.asarray(a)-np.asarray(b) return norm(x) 向量编码 1.使用API进行向量编码（收费）\nopenAI def get_embeddings(texts, model=\"text-embedding-ada-002\"): '''封装 OpenAI 的 Embedding 模型接口''' data = client.embeddings.create(input=texts, model=model).data return [x.embedding for x in data] test_query = [\"测试文本\"] vec = get_embeddings(test_query)[0] print(vec[:10]) query = \"国际争端\" # 且能支持跨语言 # query = \"global conflicts\" documents = [ \"联合国就苏丹达尔富尔地区大规模暴力事件发出警告\", \"土耳其、芬兰、瑞典与北约代表将继续就瑞典“入约”问题进行谈判\", \"日本岐阜市陆上自卫队射击场内发生枪击事件 3人受伤\", \"国家游泳中心（水立方）：恢复游泳、嬉水乐园等水上项目运营\", \"我国首次在空间站开展舱外辐射生物学暴露实验\", ] query_vec = get_embeddings([query])[0] doc_vecs = get_embeddings(documents) print(\"Cosine distance:\") print(cos_sim(query_vec, query_vec)) for vec in doc_vecs: print(cos_sim(query_vec, vec)) print(\"\\nEuclidean distance:\") print(l2(query_vec, query_vec)) for vec in doc_vecs: print(l2(query_vec, vec)) 文心千帆（BGE Embedding），因为收费我还没有尝试。 import json import requests import os # 通过鉴权接口获取 access token def get_access_token(): \"\"\" 使用 AK，SK 生成鉴权签名（Access Token） :return: access_token，或是None(如果错误) \"\"\" url = \"https://aip.baidubce.com/oauth/2.0/token\" params = { \"grant_type\": \"client_credentials\", \"client_id\": os.getenv('ERNIE_CLIENT_ID'), \"client_secret\": os.getenv('ERNIE_CLIENT_SECRET') } return str(requests.post(url, params=params).json().get(\"access_token\")) # 调用文心千帆 调用 BGE Embedding 接口 def get_embeddings_bge(prompts): url = \"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/embeddings/bge_large_en?access_token=\" + get_access_token() payload = json.dumps({ \"input\": prompts }) headers = {'Content-Type': 'application/json'} response = requests.request( \"POST\", url, headers=headers, data=payload).json() data = response[\"data\"] return [x[\"embedding\"] for x in data] 2.本地模型进行向量编码\nfrom sentence_transformers import SentenceTransformer model = SentenceTransformer('BAAI/bge-large-zh-v1.5') query = \"国际争端\" documents = [ \"联合国就苏丹达尔富尔地区大规模暴力事件发出警告\", \"土耳其、芬兰、瑞典与北约代表将继续就瑞典“入约”问题进行谈判\", \"日本岐阜市陆上自卫队射击场内发生枪击事件 3人受伤\", \"国家游泳中心（水立方）：恢复游泳、嬉水乐园等水上项目运营\", \"我国首次在空间站开展舱外辐射生物学暴露实验\", ] query_vec = model.encode(query, normalize_embeddings=True) doc_vecs = [ model.encode(doc, normalize_embeddings=True) for doc in documents ] print(\"Cosine distance:\") # 该模型余弦距离越大越相似 print(cos_sim(query_vec, query_vec)) for vec in doc_vecs: print(cos_sim(query_vec, vec)) 划重点：\n不是每个 Embedding 模型都对余弦距离和欧氏距离同时有效 哪种相似度计算有效要阅读模型的说明（通常都支持余弦距离计算） 更多本地模型：https://github.com/FlagOpen/FlagEmbedding\n向量数据库 从上述可以知道，通过计算向量距离实现句子和其他句子的相似度。\n现在我们需要将我们的外部知识通过embedding模型转换成向量，保存在向量数据库中，作为向量检索设计的中间件。\n!pip install chromadb # 为了演示方便，我们只取两页（第一章） paragraphs = extract_text_from_pdf(\"llama2.pdf\", page_numbers=[ 2, 3], min_line_length=10) import chromadb from chromadb.config import Settings class MyVectorDBConnector: def __init__(self, collection_name, embedding_fn): chroma_client = chromadb.Client(Settings(allow_reset=True)) # 为了演示，实际不需要每次 reset() chroma_client.reset() # 创建一个 collection self.collection = chroma_client.get_or_create_collection(name=\"demo\") self.embedding_fn = embedding_fn def add_documents(self, documents, metadata={}): '''向 collection 中添加文档与向量''' self.collection.add( embeddings=self.embedding_fn(documents), # 每个文档的向量 documents=documents, # 文档的原文 ids=[f\"id{i}\" for i in range(len(documents))] # 每个文档的 id ) def search(self, query, top_n): '''检索向量数据库''' results = self.collection.query( query_embeddings=self.embedding_fn([query]), n_results=top_n ) return results 注意：下面代码程序执行崩溃了，测试了和文本长度没有关系，很有可能是内存有关，换了autodl云服务的大内存机子可行。\n# 创建一个向量数据库对象 vector_db = MyVectorDBConnector(\"demo\", get_embeddings) # 向向量数据库中添加文档 vector_db.add_documents(paragraphs) user_query = \"Llama 2有多少参数\" results = vector_db.search(user_query, 2) for para in results['documents'][0]: print(para+\"\\n\") 主流向量数据库功能对比\nFAISS: Meta 开源的向量检索引擎 https://github.com/facebookresearch/faiss Pinecone: 商用向量数据库，只有云服务 https://www.pinecone.io/ Milvus: 开源向量数据库，同时有云服务 https://milvus.io/ Weaviate: 开源向量数据库，同时有云服务 https://weaviate.io/ Qdrant: 开源向量数据库，同时有云服务 https://qdrant.tech/ PGVector: Postgres 的开源向量检索引擎 https://github.com/pgvector/pgvector RediSearch: Redis 的开源向量检索引擎 https://github.com/RediSearch/RediSearch ElasticSearch 也支持向量检索 https://www.elastic.co/enterprise-search/vector-search 文本分割的粒度 缺陷：\n粒度太大可能导致检索不精准，粒度太小可能导致信息不全面 问题的答案可能跨越两个片段 改进: 按一定粒度，部分重叠式的切割文本，使上下文更完整\nfrom nltk.tokenize import sent_tokenize import json def split_text(paragraphs, chunk_size=300, overlap_size=100): '''按指定 chunk_size 和 overlap_size 交叠割文本''' sentences = [s.strip() for p in paragraphs for s in sent_tokenize(p)] chunks = [] i = 0 while i \u003c len(sentences): chunk = sentences[i] overlap = '' prev_len = 0 prev = i - 1 # 向前计算重叠部分 while prev \u003e= 0 and len(sentences[prev])+len(overlap) \u003c= overlap_size: overlap = sentences[prev] + ' ' + overlap prev -= 1 chunk = overlap+chunk next = i + 1 # 向后计算当前chunk while next \u003c len(sentences) and len(sentences[next])+len(chunk) \u003c= chunk_size: chunk = chunk + ' ' + sentences[next] next += 1 chunks.append(chunk) i = next return chunks chunks = split_text(paragraphs, 300, 100) # 创建一个向量数据库对象 vector_db = MyVectorDBConnector(\"demo_text_split\", get_embeddings) # 向向量数据库中添加文档 vector_db.add_documents(chunks) 检索后排序 问题: 有时，最合适的答案不一定排在检索的最前面\n方案:\n检索时过招回一部分文本 通过一个排序模型对 query 和 document 重新打分排序 !pip install sentence_transformers from sentence_transformers import CrossEncoder model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', max_length=512) user_query = \"how safe is llama 2\" scores = model.predict([(user_query, doc) for doc in search_results['documents'][0]]) # 按得分排序 sorted_list = sorted( zip(scores, search_results['documents'][0]), key=lambda x: x[0], reverse=True) for score, doc in sorted_list: print(f\"{score}\\t{doc}\\n\") 云向量数据库（pinecone为例，它有2G免费空间） !pip install \"pinecone-client[grpc]\" !pip install langchain !pip install langchain-openai !pip install langchain-pinecone !pip install langchain_text_splitters 1.初始化客户端连接\nfrom pinecone.grpc import PineconeGRPC as Pinecone from pinecone import ServerlessSpec # 初始化客户端连接 pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\")) 2.创建无服务器索引\n# 创建无服务器索引，这里选用openai模型，所以设置索引维度和距离度量以匹配text-embedding-3-small用于创建嵌入的 OpenAI 模型的维度和距离度量。 index_name = \"arxiv-llama2-index\" if index_name not in pc.list_indexes().names(): pc.create_index( name=index_name, dimension=1536, # 更新模型选择 metric=\"cosine\", # 更新模型选择 spec=ServerlessSpec( cloud='aws', region='us-east-1' ) ) 3.获取知识数据。这里以手动构建的md文档为例，根据结构对内容进行分块。如果是text文本类型数据参考pinecone文档。\nfrom langchain_text_splitters import MarkdownHeaderTextSplitter # Chunk the document based on h2 headers. markdown_document = \"## Introduction\\n\\nWelcome to the whimsical world of the WonderVector5000, an astonishing leap into the realms of imaginative technology. This extraordinary device, borne of creative fancy, promises to revolutionize absolutely nothing while dazzling you with its fantastical features. Whether you're a seasoned technophile or just someone looking for a bit of fun, the WonderVector5000 is sure to leave you amused and bemused in equal measure. Let's explore the incredible, albeit entirely fictitious, specifications, setup process, and troubleshooting tips for this marvel of modern nonsense.\\n\\n## Product overview\\n\\nThe WonderVector5000 is packed with features that defy logic and physics, each designed to sound impressive while maintaining a delightful air of absurdity:\\n\\n- Quantum Flibberflabber Engine: The heart of the WonderVector5000, this engine operates on principles of quantum flibberflabber, a phenomenon as mysterious as it is meaningless. It's said to harness the power of improbability to function seamlessly across multiple dimensions.\\n\\n- Hyperbolic Singularity Matrix: This component compresses infinite possibilities into a singular hyperbolic state, allowing the device to predict outcomes with 0% accuracy, ensuring every use is a new adventure.\\n\\n- Aetherial Flux Capacitor: Drawing energy from the fictional aether, this flux capacitor provides unlimited power by tapping into the boundless reserves of imaginary energy fields.\\n\\n- Multi-Dimensional Holo-Interface: Interact with the WonderVector5000 through its holographic interface that projects controls and information in three-and-a-half dimensions, creating a user experience that's simultaneously futuristic and perplexing.\\n\\n- Neural Fandango Synchronizer: This advanced feature connects directly to the user's brain waves, converting your deepest thoughts into tangible actions—albeit with results that are whimsically unpredictable.\\n\\n- Chrono-Distortion Field: Manipulate time itself with the WonderVector5000's chrono-distortion field, allowing you to experience moments before they occur or revisit them in a state of temporal flux.\\n\\n## Use cases\\n\\nWhile the WonderVector5000 is fundamentally a device of fiction and fun, let's imagine some scenarios where it could hypothetically be applied:\\n\\n- Time Travel Adventures: Use the Chrono-Distortion Field to visit key moments in history or glimpse into the future. While actual temporal manipulation is impossible, the mere idea sparks endless storytelling possibilities.\\n\\n- Interdimensional Gaming: Engage with the Multi-Dimensional Holo-Interface for immersive, out-of-this-world gaming experiences. Imagine games that adapt to your thoughts via the Neural Fandango Synchronizer, creating a unique and ever-changing environment.\\n\\n- Infinite Creativity: Harness the Hyperbolic Singularity Matrix for brainstorming sessions. By compressing infinite possibilities into hyperbolic states, it could theoretically help unlock unprecedented creative ideas.\\n\\n- Energy Experiments: Explore the concept of limitless power with the Aetherial Flux Capacitor. Though purely fictional, the notion of drawing energy from the aether could inspire innovative thinking in energy research.\\n\\n## Getting started\\n\\nSetting up your WonderVector5000 is both simple and absurdly intricate. Follow these steps to unleash the full potential of your new device:\\n\\n1. Unpack the Device: Remove the WonderVector5000 from its anti-gravitational packaging, ensuring to handle with care to avoid disturbing the delicate balance of its components.\\n\\n2. Initiate the Quantum Flibberflabber Engine: Locate the translucent lever marked “QFE Start” and pull it gently. You should notice a slight shimmer in the air as the engine engages, indicating that quantum flibberflabber is in effect.\\n\\n3. Calibrate the Hyperbolic Singularity Matrix: Turn the dials labeled 'Infinity A' and 'Infinity B' until the matrix stabilizes. You'll know it's calibrated correctly when the display shows a single, stable “∞”.\\n\\n4. Engage the Aetherial Flux Capacitor: Insert the EtherKey into the designated slot and turn it clockwise. A faint humming sound should confirm that the aetherial flux capacitor is active.\\n\\n5. Activate the Multi-Dimensional Holo-Interface: Press the button resembling a floating question mark to activate the holo-interface. The controls should materialize before your eyes, slightly out of phase with reality.\\n\\n6. Synchronize the Neural Fandango Synchronizer: Place the neural headband on your forehead and think of the word “Wonder”. The device will sync with your thoughts, a process that should take just a few moments.\\n\\n7. Set the Chrono-Distortion Field: Use the temporal sliders to adjust the time settings. Recommended presets include “Past”, “Present”, and “Future”, though feel free to explore other, more abstract temporal states.\\n\\n## Troubleshooting\\n\\nEven a device as fantastically designed as the WonderVector5000 can encounter problems. Here are some common issues and their solutions:\\n\\n- Issue: The Quantum Flibberflabber Engine won't start.\\n\\n - Solution: Ensure the anti-gravitational packaging has been completely removed. Check for any residual shards of improbability that might be obstructing the engine.\\n\\n- Issue: The Hyperbolic Singularity Matrix displays “∞∞”.\\n\\n - Solution: This indicates a hyper-infinite loop. Reset the dials to zero and then adjust them slowly until the display shows a single, stable infinity symbol.\\n\\n- Issue: The Aetherial Flux Capacitor isn't engaging.\\n\\n - Solution: Verify that the EtherKey is properly inserted and genuine. Counterfeit EtherKeys can often cause malfunctions. Replace with an authenticated EtherKey if necessary.\\n\\n- Issue: The Multi-Dimensional Holo-Interface shows garbled projections.\\n\\n - Solution: Realign the temporal resonators by tapping the holographic screen three times in quick succession. This should stabilize the projections.\\n\\n- Issue: The Neural Fandango Synchronizer causes headaches.\\n\\n - Solution: Ensure the headband is properly positioned and not too tight. Relax and focus on simple, calming thoughts to ease the synchronization process.\\n\\n- Issue: The Chrono-Distortion Field is stuck in the past.\\n\\n - Solution: Increase the temporal flux by 5%. If this fails, perform a hard reset by holding down the “Future” slider for ten seconds.\" headers_to_split_on = [ (\"##\", \"Header 2\") ] markdown_splitter = MarkdownHeaderTextSplitter( headers_to_split_on=headers_to_split_on, strip_headers=False ) md_header_splits = markdown_splitter.split_text(markdown_document) print(md_header_splits[:1]) 4.初始化embedding模型\nfrom langchain_openai import OpenAIEmbeddings # Initialize a LangChain embedding object. model_name = \"text-embedding-3-small\" embeddings = OpenAIEmbeddings( model=model_name, openai_api_key=os.environ.get(\"OPENAI_API_KEY\") ) 4.灌库。嵌入每个块并将嵌入内容插入到您的 Pinecone 索引中。\nfrom langchain_pinecone import PineconeVectorStore import os import time #定义一个命名空间。在索引中，向量存储在命名空间中，并且所有更新插入、查询和其他数据操作始终以一个命名空间为目标。 namespace = \"wondervector5000\" # Embed each chunk and upsert the embeddings into your Pinecone index. docsearch = PineconeVectorStore.from_documents( documents=md_header_splits, index_name=index_name, embedding=embeddings, namespace=namespace # 在索引中，向量存储在命名空间中 ) time.sleep(1) 5.（可选）查记录。使用 Pinecone 的list和query操作查看其中一条记录\nindex = pc.Index(index_name) for ids in index.list(namespace=namespace): query = index.query( id=ids[0], namespace=namespace, top_k=1, include_values=True, include_metadata=True ) print(query) 6.使用LangChain创建一个对话对象\nfrom langchain.chains import RetrievalQA from langchain_openai import ChatOpenAI import os # 初始化一个从Pinecone检索信息的LangChain对象 knowledge = PineconeVectorStore.from_existing_index( index_name=index_name, namespace=namespace, embedding=embeddings ) # 初始化一个与LLM聊天的LangChain对象 # without knowledge from Pinecone. llm = ChatOpenAI( openai_api_key=os.environ.get(\"OPENAI_API_KEY\"), model_name=\"gpt-3.5-turbo-1106\", temperature=0.0 ) qa = RetrievalQA.from_chain_type( llm=llm, chain_type=\"stuff\", retriever=knowledge.as_retriever() ) 7.对话使用。\n# Define a few questions about the WonderVector5000. query1 = \"\"\"What are the first 3 steps for getting started with the WonderVector5000?\"\"\" query2 = \"\"\"The Neural Fandango Synchronizer is giving me a headache. What do I do?\"\"\" # Send each query to the LLM twice, first with relevant knowledge from Pincone # and then without any additional knowledge. print(\"Query 1\\n\") print(\"Chat with knowledge:\") print(qa.invoke(query1).get(\"result\")) print(\"\\nChat without knowledge:\") print(llm.invoke(query1).content) print(\"\\nQuery 2\\n\") print(\"Chat with knowledge:\") print(qa.invoke(query2).get(\"result\")) print(\"\\nChat without knowledge:\") print(llm.invoke(query2).content) 8.（可选）如果不需要可以清理\n# 清理 pc.delete_index(index_name) ",
  "wordCount" : "4934",
  "inLanguage": "zh",
  "datePublished": "2024-07-28T00:18:23+08:00",
  "dateModified": "2024-07-28T00:18:23+08:00",
  "author":[{
    "@type": "Person",
    "name": "aliga"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://Aliga123.github.io/posts/ai-llm/rag/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "aliga's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://Aliga123.github.io/img/Q.gif"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    (function () {
        let  arr,reg = new RegExp("(^| )"+"change-themes"+"=([^;]*)(;|$)");
        if(arr = document.cookie.match(reg)) {
        } else {
            if (new Date().getHours() >= 19 || new Date().getHours() < 6) {
                document.body.classList.add('dark');
                localStorage.setItem("pref-theme", 'dark');
            } else {
                document.body.classList.remove('dark');
                localStorage.setItem("pref-theme", 'light');
            }
        }
    })()

    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }
</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://Aliga123.github.io/" accesskey="h" title="Aliga&#39;s Blog (Alt + H)">
            <img src="https://Aliga123.github.io/img/Q.gif" alt="logo" aria-label="logo"
                 height="35">Aliga&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://Aliga123.github.io/search" title="🔍 搜索 (Alt &#43; /)" accesskey=/>
                <span>🔍 搜索</span>
                </a>
            </li>
            <li>
                <a href="https://Aliga123.github.io/" title="🏠 主页">
                <span>🏠 主页</span>
                </a>
            </li>
            <li>
                <a href="https://Aliga123.github.io/posts" title="📚 文章">
                <span>📚 文章</span>
                </a>
            </li>
            <li>
                <a href="https://Aliga123.github.io/tags" title="🧩 标签">
                <span>🧩 标签</span>
                </a>
            </li>
            <li>
                <a href="https://Aliga123.github.io/archives/" title="⏱️ 时间轴">
                <span>⏱️ 时间轴</span>
                </a>
            </li>
            <li>
                <a href="https://Aliga123.github.io/about" title="🙋🏻‍♂️ 关于">
                <span>🙋🏻‍♂️ 关于</span>
                </a>
            </li>
            <li>
                <a href="https://Aliga123.github.io/links" title="🤝 友链">
                <span>🤝 友链</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main page">
<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }
</style>

<article class="post-single">
    <div id="single-content">
        <header class="post-header">
            <div class="breadcrumbs"><a href="https://Aliga123.github.io/">🏠 主页</a>&nbsp;»&nbsp;<a href="https://Aliga123.github.io/posts/">📚文章</a>&nbsp;»&nbsp;<a href="https://Aliga123.github.io/posts/ai-llm/">🧱 AI大模型应用开发</a></div>
            <h1 class="post-title">
                RAG
            </h1>
            <div class="post-meta">

<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }

    .parent-post-meta {
        display: flex;
        flex-wrap: wrap;
        opacity: 0.8;
    }
</style>

<span class="parent-post-meta">
    <span id="post_meta_style_1">
        <span class="fa fa-calendar-check-o"></span>
        <span>2024-07-28
            &nbsp;&nbsp;
        </span>
    </span>
    
    
    
    
    
    
    
    <span id="post_meta_style_3">
        <span class="fa fa-file-word-o"></span>
        <span>4934字
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_4">
        <span class="fa fa-clock-o"></span>
        <span>10分钟
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_5">
        <span class="fa fa-user-o"></span>
        <span>aliga
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_6">
        <span class="fa fa-tags" style="opacity: 0.8"></span>
        <span>
            <span class="post-tags-meta">
            </span>
        </span>
    </span>
</span>
<span style="opacity: 0.8;">
                    <span id="post_meta_style_7">
                        &nbsp;&nbsp;
                        <span class="fa fa-eye" ></span>
                        <span>
                            <span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv"></span></span>
                            &nbsp;&nbsp;
                        </span>
                    </span>
                    <span id="post_meta_style_8">
                        <span class="fa fa-commenting-o"></span>
                        <span>
                            <script src="https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js"></script>
                            <script>
                                let url = document.documentURI
                                
                                let dnsUrl = "https://Aliga123.github.io/"
                                let urlSplit = url.split(dnsUrl)
                                let finalUrl = urlSplit[1]
                                if (finalUrl[0] !== '/') {
                                    finalUrl = '/'+finalUrl
                                }
                                twikoo.getCommentsCount({
                                    envId:  null , 
                                region:  null , 
                                urls: [ 
                                    
                                    finalUrl,
                                ],
                                    includeReply: false 
                                }).then(function (res) {
                                    let count = res[0].count
                                    const obj = document.getElementById("comment_count");
                                    obj.innerText = count
                                    
                                    
                                    
                                }).catch(function (err) {
                                    
                                    console.error(err);
                                });
                            </script>
                            <span id="comment_count"></span>
                        </span>
                    </span>
                </span>

</div>
        </header> <aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">目录</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#elasticsearch%e5%82%a8%e5%ad%98%e4%b8%8e%e6%a3%80%e7%b4%a2" aria-label="elasticsearch：储存与检索">elasticsearch：储存与检索</a></li>
                <li>
                    <a href="#rag%e7%b3%bb%e7%bb%9f%e7%9a%84%e5%9f%ba%e6%9c%ac%e6%90%ad%e5%bb%ba%e6%b5%81%e7%a8%8b" aria-label="RAG系统的基本搭建流程">RAG系统的基本搭建流程</a></li>
                <li>
                    <a href="#%e5%90%91%e9%87%8f%e8%b7%9d%e7%a6%bb" aria-label="向量距离">向量距离</a></li>
                <li>
                    <a href="#%e5%90%91%e9%87%8f%e7%bc%96%e7%a0%81" aria-label="向量编码">向量编码</a></li>
                <li>
                    <a href="#%e5%90%91%e9%87%8f%e6%95%b0%e6%8d%ae%e5%ba%93" aria-label="向量数据库">向量数据库</a></li>
                <li>
                    <a href="#%e6%96%87%e6%9c%ac%e5%88%86%e5%89%b2%e7%9a%84%e7%b2%92%e5%ba%a6" aria-label="文本分割的粒度">文本分割的粒度</a></li>
                <li>
                    <a href="#%e6%a3%80%e7%b4%a2%e5%90%8e%e6%8e%92%e5%ba%8f" aria-label="检索后排序">检索后排序</a></li>
                <li>
                    <a href="#%e4%ba%91%e5%90%91%e9%87%8f%e6%95%b0%e6%8d%ae%e5%ba%93pineconehttpsapppineconeioorganizations-nek9opfxfhrmbw1_bdkprojects7e366afe-e57f-465b-bc3e-06afffe9fbc0indexes%e4%b8%ba%e4%be%8b%e5%ae%83%e6%9c%892g%e5%85%8d%e8%b4%b9%e7%a9%ba%e9%97%b4" aria-label="云向量数据库（pinecone为例，它有2G免费空间）">云向量数据库（<a href="https://app.pinecone.io/organizations/-Nek9oPfXFHrmbW1_Bdk/projects/7e366afe-e57f-465b-bc3e-06afffe9fbc0/indexes">pinecone</a>为例，它有2G免费空间）</a>
                </li>
            </ul>
        </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
        
        activeElement = elements[0];
        const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
        document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
    }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        if (elements) {
            activeElement = Array.from(elements).find((element) => {
                if ((getOffsetTop(element) - window.pageYOffset) > 0 &&
                    (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                    return element;
                }
            }) || activeElement

            elements.forEach(element => {
                const id = encodeURI(element.getAttribute('id')).toLowerCase();
                if (element === activeElement){
                    document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
                } else {
                    document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
                }
            })
        }
    }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;
        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;
    }
</script>
        <div class="post-content"><h2 id="elasticsearch储存与检索">elasticsearch：储存与检索<a hidden class="anchor" aria-hidden="true" href="#elasticsearch储存与检索">#</a></h2>
<p>Elasticsearch（简称ES）是一个分布式、RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。作为 Elastic Stack 的核心，Elasticsearch 会集中存储您的数据，让您飞快完成搜索，微调相关性，进行强大的分析，并轻松缩放规模。</p>
<p>安装与本地地址使用，<a href="https://blog.csdn.net/chen15369337607/article/details/131783783">参考blog</a>：</p>
<ul>
<li>安装JDK、配置jdk环境变量</li>
<li>下载安装<a href="https://www.elastic.co/cn/elasticsearch">Elasticsearch</a> ，配置ES环境变量</li>
<li>打开安装目录<code>D:\Toos\elasticsearch-8.14.3\bin</code>，双击<code>elasticsearch.bat</code>文件</li>
<li>使用Google浏览器打开http://localhost:9200，检查是否启动成功</li>
</ul>
<h2 id="rag系统的基本搭建流程">RAG系统的基本搭建流程<a hidden class="anchor" aria-hidden="true" href="#rag系统的基本搭建流程">#</a></h2>
<p><strong>1.文档的加载与切割</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 安装 pdf 解析库</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>pip install pdfminer<span style="color:#f92672">.</span>six
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> pdfminer.high_level <span style="color:#f92672">import</span> extract_pages
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pdfminer.layout <span style="color:#f92672">import</span> LTTextContainer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">extract_text_from_pdf</span>(filename, page_numbers<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>, min_line_length<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;从 PDF 文件中（按指定页码）提取文字&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    paragraphs <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    buffer <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    full_text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 提取全部文本</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i, page_layout <span style="color:#f92672">in</span> enumerate(extract_pages(filename)):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 如果指定了页码范围，跳过范围外的页</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> page_numbers <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span> <span style="color:#f92672">and</span> i <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> page_numbers:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">continue</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> element <span style="color:#f92672">in</span> page_layout:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> isinstance(element, LTTextContainer):
</span></span><span style="display:flex;"><span>                full_text <span style="color:#f92672">+=</span> element<span style="color:#f92672">.</span>get_text() <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 按空行分隔，将文本重新组织成段落</span>
</span></span><span style="display:flex;"><span>    lines <span style="color:#f92672">=</span> full_text<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> text <span style="color:#f92672">in</span> lines:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> len(text) <span style="color:#f92672">&gt;=</span> min_line_length:
</span></span><span style="display:flex;"><span>            buffer <span style="color:#f92672">+=</span> (<span style="color:#e6db74">&#39; &#39;</span><span style="color:#f92672">+</span>text) <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> text<span style="color:#f92672">.</span>endswith(<span style="color:#e6db74">&#39;-&#39;</span>) <span style="color:#66d9ef">else</span> text<span style="color:#f92672">.</span>strip(<span style="color:#e6db74">&#39;-&#39;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">elif</span> buffer:
</span></span><span style="display:flex;"><span>            paragraphs<span style="color:#f92672">.</span>append(buffer)
</span></span><span style="display:flex;"><span>            buffer <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> buffer:
</span></span><span style="display:flex;"><span>        paragraphs<span style="color:#f92672">.</span>append(buffer)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> paragraphs
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>paragraphs <span style="color:#f92672">=</span> extract_text_from_pdf(<span style="color:#e6db74">&#34;llama2.pdf&#34;</span>, page_numbers<span style="color:#f92672">=</span>[
</span></span><span style="display:flex;"><span>                                   <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>], min_line_length<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> para <span style="color:#f92672">in</span> paragraphs[:<span style="color:#ae81ff">5</span>]:
</span></span><span style="display:flex;"><span>    print(para)
</span></span></code></pre></div><p><strong>2.检索引擎(ES关键词检索)</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 安装 ES 客户端</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>pip install elasticsearch7
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 安装NLTK（文本处理方法库）</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>pip install nltk
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> elasticsearch7 <span style="color:#f92672">import</span> Elasticsearch, helpers
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> PorterStemmer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> nltk
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> warnings
</span></span><span style="display:flex;"><span>warnings<span style="color:#f92672">.</span>simplefilter(<span style="color:#e6db74">&#34;ignore&#34;</span>)  <span style="color:#75715e"># 屏蔽 ES 的一些Warnings</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nltk<span style="color:#f92672">.</span>download(<span style="color:#e6db74">&#39;punkt&#39;</span>)  <span style="color:#75715e"># 英文切词、词根、切句等方法</span>
</span></span><span style="display:flex;"><span>nltk<span style="color:#f92672">.</span>download(<span style="color:#e6db74">&#39;stopwords&#39;</span>)  <span style="color:#75715e"># 英文停用词库</span>
</span></span></code></pre></div><p>提取文本关键词</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">to_keywords</span>(input_string):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;（英文）文本只保留关键字&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 使用正则表达式替换所有非字母数字的字符为空格</span>
</span></span><span style="display:flex;"><span>    no_symbols <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;[^a-zA-Z0-9\s]&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, input_string)
</span></span><span style="display:flex;"><span>    word_tokens <span style="color:#f92672">=</span> word_tokenize(no_symbols)
</span></span><span style="display:flex;"><span>    stop_words <span style="color:#f92672">=</span> set(stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#39;english&#39;</span>))
</span></span><span style="display:flex;"><span>    ps <span style="color:#f92672">=</span> PorterStemmer()
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 去停用词，取词根</span>
</span></span><span style="display:flex;"><span>    filtered_sentence <span style="color:#f92672">=</span> [ps<span style="color:#f92672">.</span>stem(w)
</span></span><span style="display:flex;"><span>                         <span style="color:#66d9ef">for</span> w <span style="color:#f92672">in</span> word_tokens <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> w<span style="color:#f92672">.</span>lower() <span style="color:#f92672">in</span> stop_words]
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#39; &#39;</span><span style="color:#f92672">.</span>join(filtered_sentence)
</span></span></code></pre></div><p>将文本灌入检索引擎</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 1. 创建Elasticsearch连接</span>
</span></span><span style="display:flex;"><span>es <span style="color:#f92672">=</span> Elasticsearch(
</span></span><span style="display:flex;"><span>    hosts<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;http://localhost:9200&#39;</span>]  <span style="color:#75715e"># 连接到本地</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">es = Elasticsearch(
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    hosts=[&#39;http://117.50.198.53:9200&#39;],  # 服务地址与端口
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    http_auth=(&#34;elastic&#34;, &#34;FKaB1Jpz0Rlw0l6G&#34;),  # 用户名，密码
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 2. 定义索引名称</span>
</span></span><span style="display:flex;"><span>index_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;string_index_0924&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 3. 如果索引已存在，删除它（仅供演示，实际应用时不需要这步）</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> es<span style="color:#f92672">.</span>indices<span style="color:#f92672">.</span>exists(index<span style="color:#f92672">=</span>index_name):
</span></span><span style="display:flex;"><span>    es<span style="color:#f92672">.</span>indices<span style="color:#f92672">.</span>delete(index<span style="color:#f92672">=</span>index_name)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 4. 创建索引</span>
</span></span><span style="display:flex;"><span>es<span style="color:#f92672">.</span>indices<span style="color:#f92672">.</span>create(index<span style="color:#f92672">=</span>index_name)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 5. 灌库指令</span>
</span></span><span style="display:flex;"><span>actions <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;_index&#34;</span>: index_name,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;_source&#34;</span>: {
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;keywords&#34;</span>: to_keywords(para),
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;text&#34;</span>: para
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> para <span style="color:#f92672">in</span> paragraphs
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 6. 文本灌库</span>
</span></span><span style="display:flex;"><span>helpers<span style="color:#f92672">.</span>bulk(es, actions)
</span></span></code></pre></div><p>实现关键字检索</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">search</span>(query_string, top_n<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># ES 的查询语言</span>
</span></span><span style="display:flex;"><span>    search_query <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;match&#34;</span>: {
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;keywords&#34;</span>: to_keywords(query_string)
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    res <span style="color:#f92672">=</span> es<span style="color:#f92672">.</span>search(index<span style="color:#f92672">=</span>index_name, query<span style="color:#f92672">=</span>search_query, size<span style="color:#f92672">=</span>top_n)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> [hit[<span style="color:#e6db74">&#34;_source&#34;</span>][<span style="color:#e6db74">&#34;text&#34;</span>] <span style="color:#66d9ef">for</span> hit <span style="color:#f92672">in</span> res[<span style="color:#e6db74">&#34;hits&#34;</span>][<span style="color:#e6db74">&#34;hits&#34;</span>]]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>results <span style="color:#f92672">=</span> search(<span style="color:#e6db74">&#34;how many parameters does llama 2 have?&#34;</span>, <span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> r <span style="color:#f92672">in</span> results:
</span></span><span style="display:flex;"><span>    print(r<span style="color:#f92672">+</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p><strong>3.LLM封装</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> openai <span style="color:#f92672">import</span> OpenAI
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 加载环境变量</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> dotenv <span style="color:#f92672">import</span> load_dotenv, find_dotenv
</span></span><span style="display:flex;"><span>_ <span style="color:#f92672">=</span> load_dotenv(find_dotenv())  <span style="color:#75715e"># 读取本地 .env 文件，里面定义了 OPENAI_API_KEY</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>client <span style="color:#f92672">=</span> OpenAI(
</span></span><span style="display:flex;"><span>    api_key<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>getenv(<span style="color:#e6db74">&#34;OPENAI_API_KEY&#34;</span>),
</span></span><span style="display:flex;"><span>    base_url<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>getenv(<span style="color:#e6db74">&#34;OPENAI_BASE_URL&#34;</span>)
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_completion</span>(prompt, model<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;gpt-3.5-turbo-1106&#34;</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;封装 openai 接口&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    messages <span style="color:#f92672">=</span> [{<span style="color:#e6db74">&#34;role&#34;</span>: <span style="color:#e6db74">&#34;user&#34;</span>, <span style="color:#e6db74">&#34;content&#34;</span>: prompt}]
</span></span><span style="display:flex;"><span>    response <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>chat<span style="color:#f92672">.</span>completions<span style="color:#f92672">.</span>create(
</span></span><span style="display:flex;"><span>        model<span style="color:#f92672">=</span>model,
</span></span><span style="display:flex;"><span>        messages<span style="color:#f92672">=</span>messages,
</span></span><span style="display:flex;"><span>        temperature<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,  <span style="color:#75715e"># 模型输出的随机性，0 表示随机性最小</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> response<span style="color:#f92672">.</span>choices[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>message<span style="color:#f92672">.</span>content
</span></span></code></pre></div><p><strong>4.Prompt模板</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>prompt_template <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">你是一个问答机器人。
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">你的任务是根据下述给定的已知信息回答用户问题。
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">确保你的回复完全依据下述已知信息。不要编造答案。
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">如果下述已知信息不足以回答用户的问题，请直接回复&#34;我无法回答您的问题&#34;。
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">已知信息:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">__INFO__
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">用户问：
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">__QUERY__
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">请用中文回答用户问题。
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_prompt</span>(prompt_template, <span style="color:#f92672">**</span>kwargs):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;将 Prompt 模板赋值&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    prompt <span style="color:#f92672">=</span> prompt_template
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> k, v <span style="color:#f92672">in</span> kwargs<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> isinstance(v, str):
</span></span><span style="display:flex;"><span>            val <span style="color:#f92672">=</span> v
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">elif</span> isinstance(v, list) <span style="color:#f92672">and</span> all(isinstance(elem, str) <span style="color:#66d9ef">for</span> elem <span style="color:#f92672">in</span> v):
</span></span><span style="display:flex;"><span>            val <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>join(v)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            val <span style="color:#f92672">=</span> str(v)
</span></span><span style="display:flex;"><span>        prompt <span style="color:#f92672">=</span> prompt<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;__</span><span style="color:#e6db74">{</span>k<span style="color:#f92672">.</span>upper()<span style="color:#e6db74">}</span><span style="color:#e6db74">__&#34;</span>, val)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> prompt
</span></span></code></pre></div><p><strong>5.提问回答</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>user_query <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;how many parameters does llama 2 have?&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 1. 检索</span>
</span></span><span style="display:flex;"><span>search_results <span style="color:#f92672">=</span> search(user_query, <span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 2. 构建 Prompt</span>
</span></span><span style="display:flex;"><span>prompt <span style="color:#f92672">=</span> build_prompt(prompt_template, info<span style="color:#f92672">=</span>search_results, query<span style="color:#f92672">=</span>user_query)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;===Prompt===&#34;</span>)
</span></span><span style="display:flex;"><span>print(prompt)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 3. 调用 LLM</span>
</span></span><span style="display:flex;"><span>response <span style="color:#f92672">=</span> get_completion(prompt)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># response = get_completion_ernie(prompt)</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;===回复===&#34;</span>)
</span></span><span style="display:flex;"><span>print(response)
</span></span></code></pre></div><h2 id="向量距离">向量距离<a hidden class="anchor" aria-hidden="true" href="#向量距离">#</a></h2>
<p>关键字检索的局限性：同一个语义，用词不同，可能导致检索不到有效的结果。</p>
<p>将文本转换成向量，再向量检索通过计算向量间相似度，从而找出相关资料。</p>
<img src="img/image-20240718003949186.png" alt="image-20240718003949186" style="zoom:33%;" />
<p><strong>计算向量距离</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> numpy <span style="color:#f92672">import</span> dot
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> numpy.linalg <span style="color:#f92672">import</span> norm
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">cos_sim</span>(a, b):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;余弦距离 -- 越大越相似&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> dot(a, b)<span style="color:#f92672">/</span>(norm(a)<span style="color:#f92672">*</span>norm(b))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">l2</span>(a, b):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;欧式距离 -- 越小越相似&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>asarray(a)<span style="color:#f92672">-</span>np<span style="color:#f92672">.</span>asarray(b)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> norm(x)
</span></span></code></pre></div><h2 id="向量编码">向量编码<a hidden class="anchor" aria-hidden="true" href="#向量编码">#</a></h2>
<p><strong>1.使用API进行向量编码（收费）</strong></p>
<ul>
<li>openAI</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_embeddings</span>(texts, model<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;text-embedding-ada-002&#34;</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;封装 OpenAI 的 Embedding 模型接口&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    data <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>embeddings<span style="color:#f92672">.</span>create(input<span style="color:#f92672">=</span>texts, model<span style="color:#f92672">=</span>model)<span style="color:#f92672">.</span>data
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> [x<span style="color:#f92672">.</span>embedding <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> data]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>test_query <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;测试文本&#34;</span>]
</span></span><span style="display:flex;"><span>vec <span style="color:#f92672">=</span> get_embeddings(test_query)[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>print(vec[:<span style="color:#ae81ff">10</span>])
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>query <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;国际争端&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 且能支持跨语言</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># query = &#34;global conflicts&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>documents <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;联合国就苏丹达尔富尔地区大规模暴力事件发出警告&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;土耳其、芬兰、瑞典与北约代表将继续就瑞典“入约”问题进行谈判&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;日本岐阜市陆上自卫队射击场内发生枪击事件 3人受伤&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;国家游泳中心（水立方）：恢复游泳、嬉水乐园等水上项目运营&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;我国首次在空间站开展舱外辐射生物学暴露实验&#34;</span>,
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>query_vec <span style="color:#f92672">=</span> get_embeddings([query])[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>doc_vecs <span style="color:#f92672">=</span> get_embeddings(documents)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Cosine distance:&#34;</span>)
</span></span><span style="display:flex;"><span>print(cos_sim(query_vec, query_vec))
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> vec <span style="color:#f92672">in</span> doc_vecs:
</span></span><span style="display:flex;"><span>    print(cos_sim(query_vec, vec))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Euclidean distance:&#34;</span>)
</span></span><span style="display:flex;"><span>print(l2(query_vec, query_vec))
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> vec <span style="color:#f92672">in</span> doc_vecs:
</span></span><span style="display:flex;"><span>    print(l2(query_vec, vec))
</span></span></code></pre></div><ul>
<li>文心千帆（BGE Embedding），因为收费我还没有尝试。</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> json
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> requests
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 通过鉴权接口获取 access token</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_access_token</span>():
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    使用 AK，SK 生成鉴权签名（Access Token）
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    :return: access_token，或是None(如果错误)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;https://aip.baidubce.com/oauth/2.0/token&#34;</span>
</span></span><span style="display:flex;"><span>    params <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;grant_type&#34;</span>: <span style="color:#e6db74">&#34;client_credentials&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;client_id&#34;</span>: os<span style="color:#f92672">.</span>getenv(<span style="color:#e6db74">&#39;ERNIE_CLIENT_ID&#39;</span>),
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;client_secret&#34;</span>: os<span style="color:#f92672">.</span>getenv(<span style="color:#e6db74">&#39;ERNIE_CLIENT_SECRET&#39;</span>)
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> str(requests<span style="color:#f92672">.</span>post(url, params<span style="color:#f92672">=</span>params)<span style="color:#f92672">.</span>json()<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;access_token&#34;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 调用文心千帆 调用 BGE Embedding 接口</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_embeddings_bge</span>(prompts):
</span></span><span style="display:flex;"><span>    url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/embeddings/bge_large_en?access_token=&#34;</span> <span style="color:#f92672">+</span> get_access_token()
</span></span><span style="display:flex;"><span>    payload <span style="color:#f92672">=</span> json<span style="color:#f92672">.</span>dumps({
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;input&#34;</span>: prompts
</span></span><span style="display:flex;"><span>    })
</span></span><span style="display:flex;"><span>    headers <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;Content-Type&#39;</span>: <span style="color:#e6db74">&#39;application/json&#39;</span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    response <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>request(
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;POST&#34;</span>, url, headers<span style="color:#f92672">=</span>headers, data<span style="color:#f92672">=</span>payload)<span style="color:#f92672">.</span>json()
</span></span><span style="display:flex;"><span>    data <span style="color:#f92672">=</span> response[<span style="color:#e6db74">&#34;data&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> [x[<span style="color:#e6db74">&#34;embedding&#34;</span>] <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> data]
</span></span></code></pre></div><p><strong>2.本地模型进行向量编码</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sentence_transformers <span style="color:#f92672">import</span> SentenceTransformer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> SentenceTransformer(<span style="color:#e6db74">&#39;BAAI/bge-large-zh-v1.5&#39;</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>query <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;国际争端&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>documents <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;联合国就苏丹达尔富尔地区大规模暴力事件发出警告&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;土耳其、芬兰、瑞典与北约代表将继续就瑞典“入约”问题进行谈判&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;日本岐阜市陆上自卫队射击场内发生枪击事件 3人受伤&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;国家游泳中心（水立方）：恢复游泳、嬉水乐园等水上项目运营&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;我国首次在空间站开展舱外辐射生物学暴露实验&#34;</span>,
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>query_vec <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>encode(query, normalize_embeddings<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>doc_vecs <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>encode(doc, normalize_embeddings<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> doc <span style="color:#f92672">in</span> documents
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Cosine distance:&#34;</span>)  <span style="color:#75715e"># 该模型余弦距离越大越相似</span>
</span></span><span style="display:flex;"><span>print(cos_sim(query_vec, query_vec))
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> vec <span style="color:#f92672">in</span> doc_vecs:
</span></span><span style="display:flex;"><span>    print(cos_sim(query_vec, vec))
</span></span></code></pre></div><p><strong>划重点：</strong></p>
<ol>
<li>不是每个 Embedding 模型都对余弦距离和欧氏距离同时有效</li>
<li>哪种相似度计算有效要阅读模型的说明（通常都支持余弦距离计算）</li>
</ol>
<p><strong>更多本地模型：https://github.com/FlagOpen/FlagEmbedding</strong></p>
<h2 id="向量数据库">向量数据库<a hidden class="anchor" aria-hidden="true" href="#向量数据库">#</a></h2>
<p>从上述可以知道，通过计算向量距离实现句子和其他句子的相似度。</p>
<p>现在我们需要将我们的外部知识通过embedding模型转换成向量，保存在向量数据库中，作为向量检索设计的中间件。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>pip install chromadb
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 为了演示方便，我们只取两页（第一章）</span>
</span></span><span style="display:flex;"><span>paragraphs <span style="color:#f92672">=</span> extract_text_from_pdf(<span style="color:#e6db74">&#34;llama2.pdf&#34;</span>, page_numbers<span style="color:#f92672">=</span>[
</span></span><span style="display:flex;"><span>                                   <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>], min_line_length<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> chromadb
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> chromadb.config <span style="color:#f92672">import</span> Settings
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyVectorDBConnector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, collection_name, embedding_fn):
</span></span><span style="display:flex;"><span>        chroma_client <span style="color:#f92672">=</span> chromadb<span style="color:#f92672">.</span>Client(Settings(allow_reset<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 为了演示，实际不需要每次 reset()</span>
</span></span><span style="display:flex;"><span>        chroma_client<span style="color:#f92672">.</span>reset()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 创建一个 collection</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>collection <span style="color:#f92672">=</span> chroma_client<span style="color:#f92672">.</span>get_or_create_collection(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;demo&#34;</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>embedding_fn <span style="color:#f92672">=</span> embedding_fn
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">add_documents</span>(self, documents, metadata<span style="color:#f92672">=</span>{}):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;&#39;&#39;向 collection 中添加文档与向量&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>collection<span style="color:#f92672">.</span>add(
</span></span><span style="display:flex;"><span>            embeddings<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>embedding_fn(documents),  <span style="color:#75715e"># 每个文档的向量</span>
</span></span><span style="display:flex;"><span>            documents<span style="color:#f92672">=</span>documents,  <span style="color:#75715e"># 文档的原文</span>
</span></span><span style="display:flex;"><span>            ids<span style="color:#f92672">=</span>[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;id</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span> <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(documents))]  <span style="color:#75715e"># 每个文档的 id</span>
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">search</span>(self, query, top_n):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;&#39;&#39;检索向量数据库&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>        results <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>collection<span style="color:#f92672">.</span>query(
</span></span><span style="display:flex;"><span>            query_embeddings<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>embedding_fn([query]),
</span></span><span style="display:flex;"><span>            n_results<span style="color:#f92672">=</span>top_n
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> results
</span></span></code></pre></div><p><strong>注意</strong>：下面代码程序执行崩溃了，测试了和文本长度没有关系，很有可能是内存有关，换了autodl云服务的大内存机子可行。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 创建一个向量数据库对象</span>
</span></span><span style="display:flex;"><span>vector_db <span style="color:#f92672">=</span> MyVectorDBConnector(<span style="color:#e6db74">&#34;demo&#34;</span>, get_embeddings)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 向向量数据库中添加文档</span>
</span></span><span style="display:flex;"><span>vector_db<span style="color:#f92672">.</span>add_documents(paragraphs)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>user_query <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Llama 2有多少参数&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>results <span style="color:#f92672">=</span> vector_db<span style="color:#f92672">.</span>search(user_query, <span style="color:#ae81ff">2</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> para <span style="color:#f92672">in</span> results[<span style="color:#e6db74">&#39;documents&#39;</span>][<span style="color:#ae81ff">0</span>]:
</span></span><span style="display:flex;"><span>    print(para<span style="color:#f92672">+</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p><strong>主流向量数据库功能对比</strong></p>
<p><img loading="lazy" src="img/image-20240718013136827.png" alt="image-20240718013136827"  />
</p>
<ul>
<li>FAISS: Meta 开源的向量检索引擎 <a href="https://github.com/facebookresearch/faiss">https://github.com/facebookresearch/faiss</a></li>
<li>Pinecone: 商用向量数据库，只有云服务 <a href="https://www.pinecone.io/">https://www.pinecone.io/</a></li>
<li>Milvus: 开源向量数据库，同时有云服务 <a href="https://milvus.io/">https://milvus.io/</a></li>
<li>Weaviate: 开源向量数据库，同时有云服务 <a href="https://weaviate.io/">https://weaviate.io/</a></li>
<li>Qdrant: 开源向量数据库，同时有云服务 <a href="https://qdrant.tech/">https://qdrant.tech/</a></li>
<li>PGVector: Postgres 的开源向量检索引擎 <a href="https://github.com/pgvector/pgvector">https://github.com/pgvector/pgvector</a></li>
<li>RediSearch: Redis 的开源向量检索引擎 <a href="https://github.com/RediSearch/RediSearch">https://github.com/RediSearch/RediSearch</a></li>
<li>ElasticSearch 也支持向量检索 <a href="https://www.elastic.co/enterprise-search/vector-search">https://www.elastic.co/enterprise-search/vector-search</a></li>
</ul>
<h2 id="文本分割的粒度">文本分割的粒度<a hidden class="anchor" aria-hidden="true" href="#文本分割的粒度">#</a></h2>
<p><strong>缺陷</strong>：</p>
<ol>
<li>粒度太大可能导致检索不精准，粒度太小可能导致信息不全面</li>
<li>问题的答案可能跨越两个片段</li>
</ol>
<p><strong>改进</strong>: 按一定粒度，部分重叠式的切割文本，使上下文更完整</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> sent_tokenize
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> json
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">split_text</span>(paragraphs, chunk_size<span style="color:#f92672">=</span><span style="color:#ae81ff">300</span>, overlap_size<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;&#39;&#39;按指定 chunk_size 和 overlap_size 交叠割文本&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    sentences <span style="color:#f92672">=</span> [s<span style="color:#f92672">.</span>strip() <span style="color:#66d9ef">for</span> p <span style="color:#f92672">in</span> paragraphs <span style="color:#66d9ef">for</span> s <span style="color:#f92672">in</span> sent_tokenize(p)]
</span></span><span style="display:flex;"><span>    chunks <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">while</span> i <span style="color:#f92672">&lt;</span> len(sentences):
</span></span><span style="display:flex;"><span>        chunk <span style="color:#f92672">=</span> sentences[i]
</span></span><span style="display:flex;"><span>        overlap <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>
</span></span><span style="display:flex;"><span>        prev_len <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        prev <span style="color:#f92672">=</span> i <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 向前计算重叠部分</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">while</span> prev <span style="color:#f92672">&gt;=</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">and</span> len(sentences[prev])<span style="color:#f92672">+</span>len(overlap) <span style="color:#f92672">&lt;=</span> overlap_size:
</span></span><span style="display:flex;"><span>            overlap <span style="color:#f92672">=</span> sentences[prev] <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39; &#39;</span> <span style="color:#f92672">+</span> overlap
</span></span><span style="display:flex;"><span>            prev <span style="color:#f92672">-=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        chunk <span style="color:#f92672">=</span> overlap<span style="color:#f92672">+</span>chunk
</span></span><span style="display:flex;"><span>        next <span style="color:#f92672">=</span> i <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 向后计算当前chunk</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">while</span> next <span style="color:#f92672">&lt;</span> len(sentences) <span style="color:#f92672">and</span> len(sentences[next])<span style="color:#f92672">+</span>len(chunk) <span style="color:#f92672">&lt;=</span> chunk_size:
</span></span><span style="display:flex;"><span>            chunk <span style="color:#f92672">=</span> chunk <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39; &#39;</span> <span style="color:#f92672">+</span> sentences[next]
</span></span><span style="display:flex;"><span>            next <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        chunks<span style="color:#f92672">.</span>append(chunk)
</span></span><span style="display:flex;"><span>        i <span style="color:#f92672">=</span> next
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> chunks
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>chunks <span style="color:#f92672">=</span> split_text(paragraphs, <span style="color:#ae81ff">300</span>, <span style="color:#ae81ff">100</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 创建一个向量数据库对象</span>
</span></span><span style="display:flex;"><span>vector_db <span style="color:#f92672">=</span> MyVectorDBConnector(<span style="color:#e6db74">&#34;demo_text_split&#34;</span>, get_embeddings)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 向向量数据库中添加文档</span>
</span></span><span style="display:flex;"><span>vector_db<span style="color:#f92672">.</span>add_documents(chunks)
</span></span></code></pre></div><h2 id="检索后排序">检索后排序<a hidden class="anchor" aria-hidden="true" href="#检索后排序">#</a></h2>
<p><strong>问题</strong>: 有时，最合适的答案不一定排在检索的最前面</p>
<p><strong>方案</strong>:</p>
<ol>
<li>检索时过招回一部分文本</li>
<li>通过一个排序模型对 query 和 document 重新打分排序</li>
</ol>
<img src="img/image-20240718195050350.png" alt="image-20240718195050350" style="zoom:50%;" />
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>pip install sentence_transformers
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sentence_transformers <span style="color:#f92672">import</span> CrossEncoder
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> CrossEncoder(<span style="color:#e6db74">&#39;cross-encoder/ms-marco-MiniLM-L-6-v2&#39;</span>, max_length<span style="color:#f92672">=</span><span style="color:#ae81ff">512</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>user_query <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;how safe is llama 2&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>scores <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict([(user_query, doc)
</span></span><span style="display:flex;"><span>                       <span style="color:#66d9ef">for</span> doc <span style="color:#f92672">in</span> search_results[<span style="color:#e6db74">&#39;documents&#39;</span>][<span style="color:#ae81ff">0</span>]])
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 按得分排序</span>
</span></span><span style="display:flex;"><span>sorted_list <span style="color:#f92672">=</span> sorted(
</span></span><span style="display:flex;"><span>    zip(scores, search_results[<span style="color:#e6db74">&#39;documents&#39;</span>][<span style="color:#ae81ff">0</span>]), key<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> x: x[<span style="color:#ae81ff">0</span>], reverse<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> score, doc <span style="color:#f92672">in</span> sorted_list:
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>score<span style="color:#e6db74">}</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">{</span>doc<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><h2 id="云向量数据库pineconehttpsapppineconeioorganizations-nek9opfxfhrmbw1_bdkprojects7e366afe-e57f-465b-bc3e-06afffe9fbc0indexes为例它有2g免费空间">云向量数据库（<a href="https://app.pinecone.io/organizations/-Nek9oPfXFHrmbW1_Bdk/projects/7e366afe-e57f-465b-bc3e-06afffe9fbc0/indexes">pinecone</a>为例，它有2G免费空间）<a hidden class="anchor" aria-hidden="true" href="#云向量数据库pineconehttpsapppineconeioorganizations-nek9opfxfhrmbw1_bdkprojects7e366afe-e57f-465b-bc3e-06afffe9fbc0indexes为例它有2g免费空间">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>pip install <span style="color:#e6db74">&#34;pinecone-client[grpc]&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>pip install langchain
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>pip install langchain<span style="color:#f92672">-</span>openai
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>pip install langchain<span style="color:#f92672">-</span>pinecone
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>pip install langchain_text_splitters
</span></span></code></pre></div><p><strong>1.初始化客户端连接</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> pinecone.grpc <span style="color:#f92672">import</span> PineconeGRPC <span style="color:#66d9ef">as</span> Pinecone
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pinecone <span style="color:#f92672">import</span> ServerlessSpec
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 初始化客户端连接</span>
</span></span><span style="display:flex;"><span>pc <span style="color:#f92672">=</span> Pinecone(api_key<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>getenv(<span style="color:#e6db74">&#34;PINECONE_API_KEY&#34;</span>))
</span></span></code></pre></div><p><strong>2.创建无服务器索引</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 创建无服务器索引，这里选用openai模型，所以设置索引维度和距离度量以匹配text-embedding-3-small用于创建嵌入的 OpenAI 模型的维度和距离度量。</span>
</span></span><span style="display:flex;"><span>index_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;arxiv-llama2-index&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> index_name <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> pc<span style="color:#f92672">.</span>list_indexes()<span style="color:#f92672">.</span>names():
</span></span><span style="display:flex;"><span>    pc<span style="color:#f92672">.</span>create_index(
</span></span><span style="display:flex;"><span>        name<span style="color:#f92672">=</span>index_name,
</span></span><span style="display:flex;"><span>        dimension<span style="color:#f92672">=</span><span style="color:#ae81ff">1536</span>, <span style="color:#75715e"># 更新模型选择</span>
</span></span><span style="display:flex;"><span>        metric<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;cosine&#34;</span>, <span style="color:#75715e"># 更新模型选择</span>
</span></span><span style="display:flex;"><span>        spec<span style="color:#f92672">=</span>ServerlessSpec(
</span></span><span style="display:flex;"><span>            cloud<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;aws&#39;</span>, 
</span></span><span style="display:flex;"><span>            region<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;us-east-1&#39;</span>
</span></span><span style="display:flex;"><span>        ) 
</span></span><span style="display:flex;"><span>    ) 
</span></span></code></pre></div><p><strong>3.获取知识数据。这里以手动构建的md文档为例，根据结构对内容进行分块。如果是text文本类型数据参考<a href="https://docs.pinecone.io/integrations/langchain#key-concepts">pinecone文档</a>。</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_text_splitters <span style="color:#f92672">import</span> MarkdownHeaderTextSplitter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Chunk the document based on h2 headers.</span>
</span></span><span style="display:flex;"><span>markdown_document <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;## Introduction</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">Welcome to the whimsical world of the WonderVector5000, an astonishing leap into the realms of imaginative technology. This extraordinary device, borne of creative fancy, promises to revolutionize absolutely nothing while dazzling you with its fantastical features. Whether you&#39;re a seasoned technophile or just someone looking for a bit of fun, the WonderVector5000 is sure to leave you amused and bemused in equal measure. Let&#39;s explore the incredible, albeit entirely fictitious, specifications, setup process, and troubleshooting tips for this marvel of modern nonsense.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">## Product overview</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">The WonderVector5000 is packed with features that defy logic and physics, each designed to sound impressive while maintaining a delightful air of absurdity:</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Quantum Flibberflabber Engine: The heart of the WonderVector5000, this engine operates on principles of quantum flibberflabber, a phenomenon as mysterious as it is meaningless. It&#39;s said to harness the power of improbability to function seamlessly across multiple dimensions.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Hyperbolic Singularity Matrix: This component compresses infinite possibilities into a singular hyperbolic state, allowing the device to predict outcomes with 0</span><span style="color:#e6db74">% a</span><span style="color:#e6db74">ccuracy, ensuring every use is a new adventure.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Aetherial Flux Capacitor: Drawing energy from the fictional aether, this flux capacitor provides unlimited power by tapping into the boundless reserves of imaginary energy fields.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Multi-Dimensional Holo-Interface: Interact with the WonderVector5000 through its holographic interface that projects controls and information in three-and-a-half dimensions, creating a user experience that&#39;s simultaneously futuristic and perplexing.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Neural Fandango Synchronizer: This advanced feature connects directly to the user&#39;s brain waves, converting your deepest thoughts into tangible actions—albeit with results that are whimsically unpredictable.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Chrono-Distortion Field: Manipulate time itself with the WonderVector5000&#39;s chrono-distortion field, allowing you to experience moments before they occur or revisit them in a state of temporal flux.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">## Use cases</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">While the WonderVector5000 is fundamentally a device of fiction and fun, let&#39;s imagine some scenarios where it could hypothetically be applied:</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Time Travel Adventures: Use the Chrono-Distortion Field to visit key moments in history or glimpse into the future. While actual temporal manipulation is impossible, the mere idea sparks endless storytelling possibilities.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Interdimensional Gaming: Engage with the Multi-Dimensional Holo-Interface for immersive, out-of-this-world gaming experiences. Imagine games that adapt to your thoughts via the Neural Fandango Synchronizer, creating a unique and ever-changing environment.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Infinite Creativity: Harness the Hyperbolic Singularity Matrix for brainstorming sessions. By compressing infinite possibilities into hyperbolic states, it could theoretically help unlock unprecedented creative ideas.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Energy Experiments: Explore the concept of limitless power with the Aetherial Flux Capacitor. Though purely fictional, the notion of drawing energy from the aether could inspire innovative thinking in energy research.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">## Getting started</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">Setting up your WonderVector5000 is both simple and absurdly intricate. Follow these steps to unleash the full potential of your new device:</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">1. Unpack the Device: Remove the WonderVector5000 from its anti-gravitational packaging, ensuring to handle with care to avoid disturbing the delicate balance of its components.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">2. Initiate the Quantum Flibberflabber Engine: Locate the translucent lever marked “QFE Start” and pull it gently. You should notice a slight shimmer in the air as the engine engages, indicating that quantum flibberflabber is in effect.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">3. Calibrate the Hyperbolic Singularity Matrix: Turn the dials labeled &#39;Infinity A&#39; and &#39;Infinity B&#39; until the matrix stabilizes. You&#39;ll know it&#39;s calibrated correctly when the display shows a single, stable “∞”.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">4. Engage the Aetherial Flux Capacitor: Insert the EtherKey into the designated slot and turn it clockwise. A faint humming sound should confirm that the aetherial flux capacitor is active.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">5. Activate the Multi-Dimensional Holo-Interface: Press the button resembling a floating question mark to activate the holo-interface. The controls should materialize before your eyes, slightly out of phase with reality.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">6. Synchronize the Neural Fandango Synchronizer: Place the neural headband on your forehead and think of the word “Wonder”. The device will sync with your thoughts, a process that should take just a few moments.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">7. Set the Chrono-Distortion Field: Use the temporal sliders to adjust the time settings. Recommended presets include “Past”, “Present”, and “Future”, though feel free to explore other, more abstract temporal states.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">## Troubleshooting</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">Even a device as fantastically designed as the WonderVector5000 can encounter problems. Here are some common issues and their solutions:</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Issue: The Quantum Flibberflabber Engine won&#39;t start.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">    - Solution: Ensure the anti-gravitational packaging has been completely removed. Check for any residual shards of improbability that might be obstructing the engine.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Issue: The Hyperbolic Singularity Matrix displays “∞∞”.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">    - Solution: This indicates a hyper-infinite loop. Reset the dials to zero and then adjust them slowly until the display shows a single, stable infinity symbol.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Issue: The Aetherial Flux Capacitor isn&#39;t engaging.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">    - Solution: Verify that the EtherKey is properly inserted and genuine. Counterfeit EtherKeys can often cause malfunctions. Replace with an authenticated EtherKey if necessary.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Issue: The Multi-Dimensional Holo-Interface shows garbled projections.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">    - Solution: Realign the temporal resonators by tapping the holographic screen three times in quick succession. This should stabilize the projections.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Issue: The Neural Fandango Synchronizer causes headaches.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">    - Solution: Ensure the headband is properly positioned and not too tight. Relax and focus on simple, calming thoughts to ease the synchronization process.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">- Issue: The Chrono-Distortion Field is stuck in the past.</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">    - Solution: Increase the temporal flux by 5%. If this fails, perform a hard reset by holding down the “Future” slider for ten seconds.&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>headers_to_split_on <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    (<span style="color:#e6db74">&#34;##&#34;</span>, <span style="color:#e6db74">&#34;Header 2&#34;</span>)
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>markdown_splitter <span style="color:#f92672">=</span> MarkdownHeaderTextSplitter(
</span></span><span style="display:flex;"><span>    headers_to_split_on<span style="color:#f92672">=</span>headers_to_split_on, strip_headers<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>md_header_splits <span style="color:#f92672">=</span> markdown_splitter<span style="color:#f92672">.</span>split_text(markdown_document)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(md_header_splits[:<span style="color:#ae81ff">1</span>])
</span></span></code></pre></div><p><strong>4.初始化embedding模型</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_openai <span style="color:#f92672">import</span> OpenAIEmbeddings
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialize a LangChain embedding object.</span>
</span></span><span style="display:flex;"><span>model_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;text-embedding-3-small&#34;</span>  
</span></span><span style="display:flex;"><span>embeddings <span style="color:#f92672">=</span> OpenAIEmbeddings(  
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">=</span>model_name,  
</span></span><span style="display:flex;"><span>    openai_api_key<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>environ<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;OPENAI_API_KEY&#34;</span>)  
</span></span><span style="display:flex;"><span>) 
</span></span></code></pre></div><p><strong>4.灌库。嵌入每个块并将嵌入内容插入到您的 Pinecone 索引中。</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_pinecone <span style="color:#f92672">import</span> PineconeVectorStore
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> time
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#定义一个命名空间。在索引中，向量存储在命名空间中，并且所有更新插入、查询和其他数据操作始终以一个命名空间为目标。</span>
</span></span><span style="display:flex;"><span>namespace <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;wondervector5000&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Embed each chunk and upsert the embeddings into your Pinecone index.</span>
</span></span><span style="display:flex;"><span>docsearch <span style="color:#f92672">=</span> PineconeVectorStore<span style="color:#f92672">.</span>from_documents(
</span></span><span style="display:flex;"><span>    documents<span style="color:#f92672">=</span>md_header_splits,
</span></span><span style="display:flex;"><span>    index_name<span style="color:#f92672">=</span>index_name,
</span></span><span style="display:flex;"><span>    embedding<span style="color:#f92672">=</span>embeddings, 
</span></span><span style="display:flex;"><span>    namespace<span style="color:#f92672">=</span>namespace  <span style="color:#75715e"># 在索引中，向量存储在命名空间中</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">.</span>sleep(<span style="color:#ae81ff">1</span>)
</span></span></code></pre></div><p><strong>5.（可选）查记录。使用 Pinecone 的<code>list</code>和<code>query</code>操作查看其中一条记录</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>index <span style="color:#f92672">=</span> pc<span style="color:#f92672">.</span>Index(index_name)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> ids <span style="color:#f92672">in</span> index<span style="color:#f92672">.</span>list(namespace<span style="color:#f92672">=</span>namespace):
</span></span><span style="display:flex;"><span>    query <span style="color:#f92672">=</span> index<span style="color:#f92672">.</span>query(
</span></span><span style="display:flex;"><span>        id<span style="color:#f92672">=</span>ids[<span style="color:#ae81ff">0</span>], 
</span></span><span style="display:flex;"><span>        namespace<span style="color:#f92672">=</span>namespace, 
</span></span><span style="display:flex;"><span>        top_k<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>        include_values<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>        include_metadata<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    print(query)
</span></span></code></pre></div><p><strong>6.使用LangChain创建一个对话对象</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.chains <span style="color:#f92672">import</span> RetrievalQA  
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_openai <span style="color:#f92672">import</span> ChatOpenAI
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 初始化一个从Pinecone检索信息的LangChain对象</span>
</span></span><span style="display:flex;"><span>knowledge <span style="color:#f92672">=</span> PineconeVectorStore<span style="color:#f92672">.</span>from_existing_index(
</span></span><span style="display:flex;"><span>    index_name<span style="color:#f92672">=</span>index_name,
</span></span><span style="display:flex;"><span>    namespace<span style="color:#f92672">=</span>namespace,
</span></span><span style="display:flex;"><span>    embedding<span style="color:#f92672">=</span>embeddings
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 初始化一个与LLM聊天的LangChain对象</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># without knowledge from Pinecone.</span>
</span></span><span style="display:flex;"><span>llm <span style="color:#f92672">=</span> ChatOpenAI(
</span></span><span style="display:flex;"><span>    openai_api_key<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>environ<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;OPENAI_API_KEY&#34;</span>),
</span></span><span style="display:flex;"><span>    model_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;gpt-3.5-turbo-1106&#34;</span>,
</span></span><span style="display:flex;"><span>    temperature<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>qa <span style="color:#f92672">=</span> RetrievalQA<span style="color:#f92672">.</span>from_chain_type(
</span></span><span style="display:flex;"><span>    llm<span style="color:#f92672">=</span>llm,
</span></span><span style="display:flex;"><span>    chain_type<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;stuff&#34;</span>,
</span></span><span style="display:flex;"><span>    retriever<span style="color:#f92672">=</span>knowledge<span style="color:#f92672">.</span>as_retriever()
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p><strong>7.对话使用。</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Define a few questions about the WonderVector5000.</span>
</span></span><span style="display:flex;"><span>query1 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;&#34;What are the first 3 steps for getting started 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">with the WonderVector5000?&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>query2 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;&#34;The Neural Fandango Synchronizer is giving me a 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">headache. What do I do?&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Send each query to the LLM twice, first with relevant knowledge from Pincone </span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># and then without any additional knowledge.</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Query 1</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Chat with knowledge:&#34;</span>)
</span></span><span style="display:flex;"><span>print(qa<span style="color:#f92672">.</span>invoke(query1)<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;result&#34;</span>))
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Chat without knowledge:&#34;</span>)
</span></span><span style="display:flex;"><span>print(llm<span style="color:#f92672">.</span>invoke(query1)<span style="color:#f92672">.</span>content)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Query 2</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Chat with knowledge:&#34;</span>)
</span></span><span style="display:flex;"><span>print(qa<span style="color:#f92672">.</span>invoke(query2)<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;result&#34;</span>))
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Chat without knowledge:&#34;</span>)
</span></span><span style="display:flex;"><span>print(llm<span style="color:#f92672">.</span>invoke(query2)<span style="color:#f92672">.</span>content)
</span></span></code></pre></div><p>8.（可选）如果不需要可以清理</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 清理</span>
</span></span><span style="display:flex;"><span>pc<span style="color:#f92672">.</span>delete_index(index_name)
</span></span></code></pre></div>

        </div>
        <div class="post-reward">
            <div style="padding: 0 0 0 0; margin: 0 0 0 0; width: 100%; font-size:16px; text-align: center;">
                <div id="QR" style="opacity: 0;">
                    <div id="wechat" style="display: inline-block">
                        <a class="fancybox" rel="group">
                            <img id="wechat_qr" src="https://Aliga123.github.io/img/wechat_pay.jpg" alt="wechat_pay"></a>
                        <p>微信</p>
                    </div>
                    <div id="alipay" style="display: inline-block">
                        <a class="fancybox" rel="group">
                            <img id="alipay_qr" src="https://Aliga123.github.io/img/alipay.jpg" alt="alipay"></a>
                        <p>支付宝</p>
                    </div>
                </div>
                <button id="rewardButton"
                        onclick="
                    var qr = document.getElementById('QR');
                    if (qr.style.opacity === '0') {
                        qr.style.opacity='1';
                    } else {
                        qr.style.opacity='0'
                    }"
                >
                    <span>🧧 鼓励</span>
                </button>
            </div>
        </div>

        <footer class="post-footer">
            
<nav class="paginav">
  <a class="prev" href="https://Aliga123.github.io/posts/ai-llm/prompt%E5%B7%A5%E7%A8%8B--cottot/">
    <span class="title">« 上一页</span>
    <br>
    <span>Prompt工程-CoT、ToT</span>
  </a>
  <a class="next" href="https://Aliga123.github.io/posts/ai-llm/semantic-kernel/">
    <span class="title">下一页 »</span>
    <br>
    <span>Semantic Kernel</span>
  </a>
</nav>

        </footer>
    </div>

<style>
    .comments_details summary::marker {
        font-size: 20px;
        content: '👉展开评论';
        color: var(--content);
    }
    .comments_details[open] summary::marker{
        font-size: 20px;
        content: '👇关闭评论';
        color: var(--content);
    }
</style>


<div>
    <details class="comments_details">
        <summary style="cursor: pointer; margin: 50px 0 20px 0;width: 130px;">
            <span style="font-size: 20px;color: var(--content);">...</span>
        </summary>
        <div id="tcomment"></div>
    </details>
    <script src="https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js">
    </script>
    <script>
        twikoo.init({
            envId:  null ,
        el: "#tcomment",
            lang: 'zh-CN',
            region:  null ,
        path: window.TWIKOO_MAGIC_PATH||window.location.pathname,
        })
    </script>
</div>
</article>
</main>

<footer class="footer">
    <span>
        Copyright
        &copy;
        2020-2024
        <a href="https://Aliga123.github.io/" style="color:#939393;">aliga&#39;s Blog</a>
        All Rights Reserved
    </span>
    <a href="https://beian.miit.gov.cn/" target="_blank" style="color:#939393;">填写自己的备案号</a>&nbsp;
    <span>
        <a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=null"
           style="display:inline-block;text-decoration:none;height:20px;color:#939393;">
            <img src="%e5%a1%ab%e8%87%aa%e5%b7%b1%e7%9a%84%e5%85%ac%e5%ae%89%e5%9b%be%e6%a0%87%e9%93%be%e6%8e%a5" style="float:left;margin: 0px 5px 0px 0px;"/>
            填自己的公网安备
        </a>
    </span>
    <span id="busuanzi_container">
        <span class="fa fa-user"></span> <span id="busuanzi_value_site_uv"></span>
        <span class="fa fa-eye"></span> <span id="busuanzi_value_site_pv"></span>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <span class="topInner">
        <svg class="topSvg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z"/>
        </svg>
        <span id="read_progress"></span>
    </span>
</a>

<script>
    document.addEventListener('scroll', function (e) {
        const readProgress = document.getElementById("read_progress");
        const scrollHeight = document.documentElement.scrollHeight;
        const clientHeight = document.documentElement.clientHeight;
        const scrollTop = document.documentElement.scrollTop || document.body.scrollTop;
        readProgress.innerText = ((scrollTop / (scrollHeight - clientHeight)).toFixed(2) * 100).toFixed(0);
    })
</script>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });
</script>
<script>
    let mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 200 || document.documentElement.scrollTop > 200) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };
</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        (function() {
            document.cookie = "change-themes" + "="+ escape ("false");
        })()

        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    });
</script>

<script>
    document.body.addEventListener('copy', function (e) {
        if (window.getSelection().toString() && window.getSelection().toString().length > 50) {
            let clipboardData = e.clipboardData || window.clipboardData;
            if (clipboardData) {
                e.preventDefault();
                let htmlData = window.getSelection().toString() +
                    '\r\n\n————————————————\r\n' +
                    '版权声明：本文为「'+"aliga's Blog"+'」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。' +
                '\r\n原文链接：' + location.href;
                let textData = window.getSelection().toString() +
                    '\r\n\n————————————————\r\n' +
                    '版权声明：本文为「'+"aliga's Blog"+'」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。' +
                '\r\n原文链接：' + location.href;
                clipboardData.setData('text/html', htmlData);
                clipboardData.setData('text/plain', textData);
            }
        }
    });
</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;
        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = '复制';

        function copyingDone() {
            copybutton.innerText = '已复制！';
            setTimeout(() => {
                copybutton.innerText = '复制';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                let text = codeblock.textContent +
                    '\r\n————————————————\r\n' +
                    '版权声明：本文为「'+"aliga's Blog"+'」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。' +
                '\r\n原文链接：' + location.href;
                navigator.clipboard.writeText(text);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) {}
            selection.removeRange(range);
        });

        let language = codeblock.className.replaceAll("language-", "")
        let macTool = document.createElement("div")
        let macTool1 = document.createElement("div")
        let macTool2 = document.createElement("div")
        let macTool3 = document.createElement("div")
        let languageType = document.createElement("div")
        languageType.innerText = language
        macTool.setAttribute('class', 'mac-tool')
        macTool1.setAttribute('class', 'mac bb1')
        macTool2.setAttribute('class', 'mac bb2')
        macTool3.setAttribute('class', 'mac bb3')
        languageType.setAttribute('class', 'language-type')
        macTool.appendChild(macTool1)
        macTool.appendChild(macTool2)
        macTool.appendChild(macTool3)
        macTool.appendChild(languageType)

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
            container.appendChild(macTool)
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        }
    });
</script>
</body>

</html>
